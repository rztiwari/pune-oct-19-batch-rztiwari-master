{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_IvCB72VOOd"
   },
   "source": [
    "# Loading data from the google drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21ytjCbNVi8-"
   },
   "source": [
    "Load the google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "-a5b7EmUVZuO",
    "outputId": "0db41077-47c1-47d8-bb15-dec058aba1c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# project_path = '/content/drive/My Drive/assignments/'\n",
    "# %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JFXj2zLAX5e6"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "PKFscDU7X52W",
    "outputId": "2ec7d34b-dc7d-4659-8565-80030a566d68"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import optimizers\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t26zeARCgM6i"
   },
   "source": [
    "Import h5py library to load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FkViJJDrafNl"
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F4ENXEy9z_zR"
   },
   "source": [
    "For colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXOnm-M7YCoN"
   },
   "outputs": [],
   "source": [
    "# dataset_file = project_path + 'SVHN_single_grey1-2.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9yRwb12Xk05b"
   },
   "source": [
    "# Data fetching and understand the train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "cjk0qjMLYzcg",
    "outputId": "61b246f6-c7df-4203-e351-f1701885fed2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "# f = h5py.File(dataset_file) # For google colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wpa1DgVQW5zQ"
   },
   "source": [
    "Load data from the local drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uwzhbNHP0rS_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiwar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:1: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(\"./SVHN_single_grey1-2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "biG-jun-k_1P"
   },
   "source": [
    "1. List the keys in the file.\n",
    "2. They hold the test and train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "GrIftpsmlFPS",
    "outputId": "5b3ecc58-ad29-4d53-b88a-880af8c4e669"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "QiuLba7wfn1e",
    "outputId": "23b93af1-6e8c-4f81-d962-c04ac1ec533d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_test = f['X_test'].value\n",
    "X_train = f['X_train'].value\n",
    "y_test = f['y_test'].value\n",
    "y_train = f['y_train'].value\n",
    "X_val = f['X_val'].value\n",
    "y_val = f['y_val'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "fSoYQU7KjAOA",
    "outputId": "a78c268e-f8cb-47fe-d958-c7774f36af6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test (18000, 32, 32)\n",
      "X_train (42000, 32, 32)\n",
      "X_val (60000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test\", X_test.shape)\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"X_val\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HXY-4mDDLj_c"
   },
   "outputs": [],
   "source": [
    "num_classes = 10 # As there can be 10 dijits 0-9 to be identified.\n",
    "X_train = X_train.reshape(42000, 1024) \n",
    "X_test = X_test.reshape(18000, 1024)      # Images are flattended out into a vector of 784 elements\n",
    "X_train = X_train.astype('float32')      # Change the data type to float from integer (0 - 255)\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255                           # Scale the data between 0 and 1\n",
    "X_test /= 255\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)   # Converting the target into categorical which is stored as numeric\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)     # Keras converst these into 1-hot coded vectors as these are lables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knqGxJp1jgCD"
   },
   "source": [
    "The file contains the train and test data set split in ratio in 30:70 ratio, i.e 70% for taining dataset and 30% for test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcqmwNy-lqlS"
   },
   "source": [
    "# Implement and apply a deep neural network classifier including (feedforward neural network, RELU, activations) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vUMknU73tIxZ"
   },
   "source": [
    "Tensorflow.Keras model object can be created with Sequential class\n",
    "\n",
    "At the outset, the model is empty per se. It is completed by adding additional layers and compilation\n",
    "\n",
    "Try different options with epochs and batch sizes to get an optimal model. To start with taking 50% model data as batch size with 100 epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "pjv-SPi5tNqf",
    "outputId": "64c9d96e-f81b-4066-aa47-66545fd48677"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_4 (None, 1024) ==> (None, 1024)\n",
      "dense_5 (None, 1024) ==> (None, 10)\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,059,850\n",
      "Trainable params: 1,059,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(1024,)))   #First hidden layer of 1024  neurons, each neuron takes input \n",
    "                                                               # vector of size 1024\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))            # Adding a softmax layer for output which contains as many \n",
    "                                                               # neurons as the number of classes (10) which is also the \n",
    "                                                               # the shape of each output vector ( one hot coded)\n",
    "\n",
    "                                                               # output layer also uses softmax. This normalizes the values \n",
    "                                                               # from the ten output nodes such that: \n",
    "                                                               #        all the values are between 0 and 1, and\n",
    "                                                               #        the sum of all ten values is 1.  \n",
    "                                                               # prediction is the lable of the node that gets highest fraction, is \n",
    "        \n",
    "        \n",
    "\n",
    "for l in model.layers:\n",
    "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
    "print()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rMqXkcBxleLC",
    "outputId": "d1664543-e397-4b71-8eb3-f2e07a2374bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 3.4776 - accuracy: 0.0962 - val_loss: 2.8860 - val_accuracy: 0.1028\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 2.8272 - accuracy: 0.1054 - val_loss: 2.8325 - val_accuracy: 0.1043\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.7817 - accuracy: 0.1017 - val_loss: 2.4636 - val_accuracy: 0.0970\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 2.4001 - accuracy: 0.1029 - val_loss: 2.3393 - val_accuracy: 0.1089\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 2.3634 - accuracy: 0.1027 - val_loss: 2.3954 - val_accuracy: 0.1008\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.3822 - accuracy: 0.1014 - val_loss: 2.3130 - val_accuracy: 0.1116\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 2.3120 - accuracy: 0.1191 - val_loss: 2.3214 - val_accuracy: 0.1077\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 2.3209 - accuracy: 0.1106 - val_loss: 2.3219 - val_accuracy: 0.0998\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 2.3139 - accuracy: 0.1091 - val_loss: 2.2977 - val_accuracy: 0.1421\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 2.2984 - accuracy: 0.1341 - val_loss: 2.3036 - val_accuracy: 0.1296\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 2.3040 - accuracy: 0.1278 - val_loss: 2.2964 - val_accuracy: 0.1189\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 2.2958 - accuracy: 0.1347 - val_loss: 2.2930 - val_accuracy: 0.1238\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 2.2914 - accuracy: 0.1278 - val_loss: 2.2909 - val_accuracy: 0.1399\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.2893 - accuracy: 0.1489 - val_loss: 2.2862 - val_accuracy: 0.1670\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 2.2846 - accuracy: 0.1703 - val_loss: 2.2830 - val_accuracy: 0.1641\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2817 - accuracy: 0.1640 - val_loss: 2.2772 - val_accuracy: 0.1882\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 2.2764 - accuracy: 0.1949 - val_loss: 2.2733 - val_accuracy: 0.1877\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2721 - accuracy: 0.1877 - val_loss: 2.2687 - val_accuracy: 0.1999\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 2.2665 - accuracy: 0.2043 - val_loss: 2.2630 - val_accuracy: 0.2080\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 2.2611 - accuracy: 0.2154 - val_loss: 2.2569 - val_accuracy: 0.2119\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.2541 - accuracy: 0.2223 - val_loss: 2.2501 - val_accuracy: 0.2313\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2.2486 - accuracy: 0.2276 - val_loss: 2.2419 - val_accuracy: 0.2462\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2.2392 - accuracy: 0.2549 - val_loss: 2.2328 - val_accuracy: 0.2642\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 2.2304 - accuracy: 0.2705 - val_loss: 2.2255 - val_accuracy: 0.2465\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 2.2217 - accuracy: 0.2594 - val_loss: 2.2150 - val_accuracy: 0.2817\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 2.2122 - accuracy: 0.2844 - val_loss: 2.2050 - val_accuracy: 0.2828\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2.2020 - accuracy: 0.2861 - val_loss: 2.1956 - val_accuracy: 0.2943\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 2.1919 - accuracy: 0.3025 - val_loss: 2.1839 - val_accuracy: 0.3050\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.1805 - accuracy: 0.3076 - val_loss: 2.1721 - val_accuracy: 0.3282\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 2.1678 - accuracy: 0.3273 - val_loss: 2.1605 - val_accuracy: 0.3248\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.1549 - accuracy: 0.3330 - val_loss: 2.1460 - val_accuracy: 0.3168\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2.1427 - accuracy: 0.3174 - val_loss: 2.1308 - val_accuracy: 0.3611\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 2.1275 - accuracy: 0.3641 - val_loss: 2.1175 - val_accuracy: 0.3681\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.1130 - accuracy: 0.3732 - val_loss: 2.1015 - val_accuracy: 0.3654\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 2.0980 - accuracy: 0.3580 - val_loss: 2.0876 - val_accuracy: 0.3619\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2.0829 - accuracy: 0.3662 - val_loss: 2.0710 - val_accuracy: 0.3926\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 2.0671 - accuracy: 0.3881 - val_loss: 2.0538 - val_accuracy: 0.4009\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.0499 - accuracy: 0.4019 - val_loss: 2.0375 - val_accuracy: 0.4126\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.0333 - accuracy: 0.4121 - val_loss: 2.0207 - val_accuracy: 0.4373\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 2.0164 - accuracy: 0.4311 - val_loss: 2.0041 - val_accuracy: 0.4191\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.9992 - accuracy: 0.4187 - val_loss: 1.9865 - val_accuracy: 0.4386\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.9828 - accuracy: 0.4398 - val_loss: 1.9690 - val_accuracy: 0.4454\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.9640 - accuracy: 0.4466 - val_loss: 1.9531 - val_accuracy: 0.4587\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.9475 - accuracy: 0.4628 - val_loss: 1.9338 - val_accuracy: 0.4701\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.9290 - accuracy: 0.4677 - val_loss: 1.9152 - val_accuracy: 0.4674\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1.9115 - accuracy: 0.4670 - val_loss: 1.8986 - val_accuracy: 0.4661\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.8930 - accuracy: 0.4760 - val_loss: 1.8794 - val_accuracy: 0.4861\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.8757 - accuracy: 0.4807 - val_loss: 1.8640 - val_accuracy: 0.4793\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.8581 - accuracy: 0.4836 - val_loss: 1.8435 - val_accuracy: 0.4976\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.8403 - accuracy: 0.4909 - val_loss: 1.8295 - val_accuracy: 0.4981\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.8236 - accuracy: 0.4961 - val_loss: 1.8072 - val_accuracy: 0.5132\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.8044 - accuracy: 0.5061 - val_loss: 1.7923 - val_accuracy: 0.5086\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.7886 - accuracy: 0.5056 - val_loss: 1.7753 - val_accuracy: 0.5072\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.7741 - accuracy: 0.5005 - val_loss: 1.7587 - val_accuracy: 0.5132\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.7570 - accuracy: 0.5127 - val_loss: 1.7431 - val_accuracy: 0.5232\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 1.7396 - accuracy: 0.5185 - val_loss: 1.7220 - val_accuracy: 0.5339\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.7214 - accuracy: 0.5235 - val_loss: 1.7086 - val_accuracy: 0.5253\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 1.7064 - accuracy: 0.5264 - val_loss: 1.6920 - val_accuracy: 0.5447\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 1.6904 - accuracy: 0.5431 - val_loss: 1.6756 - val_accuracy: 0.5495\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.6738 - accuracy: 0.5445 - val_loss: 1.6587 - val_accuracy: 0.5521\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.6576 - accuracy: 0.5531 - val_loss: 1.6454 - val_accuracy: 0.5618\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.6430 - accuracy: 0.5589 - val_loss: 1.6322 - val_accuracy: 0.5449\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.6307 - accuracy: 0.5431 - val_loss: 1.6153 - val_accuracy: 0.5702\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 1.6150 - accuracy: 0.5628 - val_loss: 1.6031 - val_accuracy: 0.5657\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.6017 - accuracy: 0.5615 - val_loss: 1.5960 - val_accuracy: 0.5568\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.5919 - accuracy: 0.5604 - val_loss: 1.5775 - val_accuracy: 0.5753\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.5768 - accuracy: 0.5676 - val_loss: 1.5624 - val_accuracy: 0.5695\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.5614 - accuracy: 0.5710 - val_loss: 1.5490 - val_accuracy: 0.5822\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.5472 - accuracy: 0.5817 - val_loss: 1.5374 - val_accuracy: 0.5792\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.5368 - accuracy: 0.5786 - val_loss: 1.5247 - val_accuracy: 0.5899\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.5240 - accuracy: 0.5902 - val_loss: 1.5109 - val_accuracy: 0.5923\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.5113 - accuracy: 0.5935 - val_loss: 1.5023 - val_accuracy: 0.5894\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.5002 - accuracy: 0.5929 - val_loss: 1.4900 - val_accuracy: 0.5938\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1.4896 - accuracy: 0.5938 - val_loss: 1.4764 - val_accuracy: 0.5978\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.4764 - accuracy: 0.5981 - val_loss: 1.4719 - val_accuracy: 0.5997\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.4691 - accuracy: 0.6012 - val_loss: 1.4560 - val_accuracy: 0.6015\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.4567 - accuracy: 0.6076 - val_loss: 1.4525 - val_accuracy: 0.6044\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.4478 - accuracy: 0.6065 - val_loss: 1.4337 - val_accuracy: 0.6070\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.4357 - accuracy: 0.6078 - val_loss: 1.4275 - val_accuracy: 0.6144\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.4268 - accuracy: 0.6160 - val_loss: 1.4213 - val_accuracy: 0.6094\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.4181 - accuracy: 0.6132 - val_loss: 1.4151 - val_accuracy: 0.6134\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.4120 - accuracy: 0.6148 - val_loss: 1.4010 - val_accuracy: 0.6055\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.4002 - accuracy: 0.6141 - val_loss: 1.3921 - val_accuracy: 0.6189\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.3908 - accuracy: 0.6205 - val_loss: 1.3804 - val_accuracy: 0.6188\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.3801 - accuracy: 0.6236 - val_loss: 1.3708 - val_accuracy: 0.6275\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.3718 - accuracy: 0.6268 - val_loss: 1.3653 - val_accuracy: 0.6244\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.3632 - accuracy: 0.6252 - val_loss: 1.3559 - val_accuracy: 0.6270\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.3562 - accuracy: 0.6305 - val_loss: 1.3510 - val_accuracy: 0.6291\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.3486 - accuracy: 0.6294 - val_loss: 1.3429 - val_accuracy: 0.6294\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1.3428 - accuracy: 0.6327 - val_loss: 1.3322 - val_accuracy: 0.6350\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.3321 - accuracy: 0.6328 - val_loss: 1.3274 - val_accuracy: 0.6333\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.3255 - accuracy: 0.6378 - val_loss: 1.3192 - val_accuracy: 0.6317\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.3168 - accuracy: 0.6385 - val_loss: 1.3078 - val_accuracy: 0.6396\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.3080 - accuracy: 0.6405 - val_loss: 1.3034 - val_accuracy: 0.6372\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.3011 - accuracy: 0.6419 - val_loss: 1.2959 - val_accuracy: 0.6466\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 1.2946 - accuracy: 0.6469 - val_loss: 1.2878 - val_accuracy: 0.6469\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.2886 - accuracy: 0.6508 - val_loss: 1.2836 - val_accuracy: 0.6441\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.2815 - accuracy: 0.6456 - val_loss: 1.2765 - val_accuracy: 0.6464\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.2757 - accuracy: 0.6492 - val_loss: 1.2732 - val_accuracy: 0.6464\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 1.2685 - accuracy: 0.6500 - val_loss: 1.2636 - val_accuracy: 0.6532\n",
      "\n",
      "Test loss: 1.264\n",
      "Test accuracy: 0.653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa1fa4c51d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 20000\n",
    "epochs = 100\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AdwXGn9Pv750"
   },
   "source": [
    "Observations on  the above model:\n",
    "1. The model has been created without BatchNormalizations and early stoppings\n",
    "2. It has been observed that there is a steady fall in loss and increase in accuracy.\n",
    "3. The steady fall in  loss and increased accuracy for 100 epochs might mean that the global minima might not have appeared. This is evident from the graph above.\n",
    "\n",
    "Let's try with higher epocs and early stopping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XtyMpHNF-_Jm"
   },
   "source": [
    "## Apply higher epochs with early stoppings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "wspTG-ZfxSeq",
    "outputId": "0e1d170e-dea0-4f46-f92b-398b2168158b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_6 (None, 1024) ==> (None, 1024)\n",
      "dense_7 (None, 1024) ==> (None, 10)\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,059,850\n",
      "Trainable params: 1,059,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(1024,)))   #First hidden layer of 1024  neurons, each neuron takes input \n",
    "                                                               # vector of size 1024\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))            # Adding a softmax layer for output which contains as many \n",
    "                                                               # neurons as the number of classes (10) which is also the \n",
    "                                                               # the shape of each output vector ( one hot coded)\n",
    "\n",
    "                                                               # output layer also uses softmax. This normalizes the values \n",
    "                                                               # from the ten output nodes such that: \n",
    "                                                               #        all the values are between 0 and 1, and\n",
    "                                                               #        the sum of all ten values is 1.  \n",
    "                                                               # prediction is the lable of the node that gets highest fraction, is \n",
    "        \n",
    "        \n",
    "\n",
    "for l in model.layers:\n",
    "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
    "print()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6au9Bi3WxZMQ",
    "outputId": "b6555eda-031a-4133-852d-7c84c88f6c7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 2.9605 - accuracy: 0.1010 - val_loss: 3.2182 - val_accuracy: 0.1062\n",
      "Epoch 2/400\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 2.8927 - accuracy: 0.1091 - val_loss: 2.5329 - val_accuracy: 0.1074\n",
      "Epoch 3/400\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 2.5894 - accuracy: 0.1004 - val_loss: 2.4065 - val_accuracy: 0.1052\n",
      "Epoch 4/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.3869 - accuracy: 0.1038 - val_loss: 2.3675 - val_accuracy: 0.1040\n",
      "Epoch 5/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.3723 - accuracy: 0.1007 - val_loss: 2.3633 - val_accuracy: 0.1034\n",
      "Epoch 6/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 2.3474 - accuracy: 0.1036 - val_loss: 2.3094 - val_accuracy: 0.1059\n",
      "Epoch 7/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 2.3091 - accuracy: 0.1095 - val_loss: 2.3223 - val_accuracy: 0.1119\n",
      "Epoch 8/400\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 2.3191 - accuracy: 0.1105 - val_loss: 2.3038 - val_accuracy: 0.1198\n",
      "Epoch 9/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.3034 - accuracy: 0.1231 - val_loss: 2.3005 - val_accuracy: 0.1331\n",
      "Epoch 10/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.3003 - accuracy: 0.1290 - val_loss: 2.3001 - val_accuracy: 0.1132\n",
      "Epoch 11/400\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 2.2955 - accuracy: 0.1187 - val_loss: 2.2885 - val_accuracy: 0.1361\n",
      "Epoch 12/400\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 2.2891 - accuracy: 0.1372 - val_loss: 2.2901 - val_accuracy: 0.1257\n",
      "Epoch 13/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2862 - accuracy: 0.1345 - val_loss: 2.2838 - val_accuracy: 0.1357\n",
      "Epoch 14/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2.2824 - accuracy: 0.1420 - val_loss: 2.2803 - val_accuracy: 0.1503\n",
      "Epoch 15/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2778 - accuracy: 0.1515 - val_loss: 2.2759 - val_accuracy: 0.1647\n",
      "Epoch 16/400\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.2741 - accuracy: 0.1743 - val_loss: 2.2708 - val_accuracy: 0.1707\n",
      "Epoch 17/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 2.2698 - accuracy: 0.1660 - val_loss: 2.2665 - val_accuracy: 0.1717\n",
      "Epoch 18/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2.2641 - accuracy: 0.1875 - val_loss: 2.2622 - val_accuracy: 0.1788\n",
      "Epoch 19/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 2.2588 - accuracy: 0.1864 - val_loss: 2.2544 - val_accuracy: 0.2087\n",
      "Epoch 20/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2522 - accuracy: 0.2104 - val_loss: 2.2483 - val_accuracy: 0.2097\n",
      "Epoch 21/400\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.2468 - accuracy: 0.2146 - val_loss: 2.2432 - val_accuracy: 0.2063\n",
      "Epoch 22/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2398 - accuracy: 0.2222 - val_loss: 2.2350 - val_accuracy: 0.2390\n",
      "Epoch 23/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2324 - accuracy: 0.2433 - val_loss: 2.2287 - val_accuracy: 0.2349\n",
      "Epoch 24/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2251 - accuracy: 0.2384 - val_loss: 2.2198 - val_accuracy: 0.2419\n",
      "Epoch 25/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2177 - accuracy: 0.2459 - val_loss: 2.2146 - val_accuracy: 0.2249\n",
      "Epoch 26/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 2.2105 - accuracy: 0.2354 - val_loss: 2.2027 - val_accuracy: 0.2597\n",
      "Epoch 27/400\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 2.2015 - accuracy: 0.2703 - val_loss: 2.1931 - val_accuracy: 0.2913\n",
      "Epoch 28/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.1896 - accuracy: 0.2932 - val_loss: 2.1830 - val_accuracy: 0.3109\n",
      "Epoch 29/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2.1806 - accuracy: 0.3100 - val_loss: 2.1740 - val_accuracy: 0.2944\n",
      "Epoch 30/400\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 2.1696 - accuracy: 0.2975 - val_loss: 2.1603 - val_accuracy: 0.3348\n",
      "Epoch 31/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 2.1572 - accuracy: 0.3347 - val_loss: 2.1511 - val_accuracy: 0.3184\n",
      "Epoch 32/400\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.1452 - accuracy: 0.3323 - val_loss: 2.1380 - val_accuracy: 0.3278\n",
      "Epoch 33/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.1337 - accuracy: 0.3350 - val_loss: 2.1249 - val_accuracy: 0.3374\n",
      "Epoch 34/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2.1201 - accuracy: 0.3487 - val_loss: 2.1097 - val_accuracy: 0.3696\n",
      "Epoch 35/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.1064 - accuracy: 0.3684 - val_loss: 2.0955 - val_accuracy: 0.3753\n",
      "Epoch 36/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.0903 - accuracy: 0.3797 - val_loss: 2.0803 - val_accuracy: 0.3996\n",
      "Epoch 37/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.0752 - accuracy: 0.4071 - val_loss: 2.0656 - val_accuracy: 0.3865\n",
      "Epoch 38/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2.0612 - accuracy: 0.3891 - val_loss: 2.0492 - val_accuracy: 0.4044\n",
      "Epoch 39/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.0437 - accuracy: 0.4149 - val_loss: 2.0352 - val_accuracy: 0.4063\n",
      "Epoch 40/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 2.0281 - accuracy: 0.4154 - val_loss: 2.0172 - val_accuracy: 0.4267\n",
      "Epoch 41/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2.0123 - accuracy: 0.4251 - val_loss: 2.0019 - val_accuracy: 0.4062\n",
      "Epoch 42/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.9954 - accuracy: 0.4214 - val_loss: 1.9836 - val_accuracy: 0.4444\n",
      "Epoch 43/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.9770 - accuracy: 0.4551 - val_loss: 1.9624 - val_accuracy: 0.4517\n",
      "Epoch 44/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 1.9573 - accuracy: 0.4526 - val_loss: 1.9475 - val_accuracy: 0.4529\n",
      "Epoch 45/400\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1.9401 - accuracy: 0.4660 - val_loss: 1.9284 - val_accuracy: 0.4492\n",
      "Epoch 46/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.9240 - accuracy: 0.4533 - val_loss: 1.9136 - val_accuracy: 0.4694\n",
      "Epoch 47/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 1.9051 - accuracy: 0.4798 - val_loss: 1.8888 - val_accuracy: 0.4755\n",
      "Epoch 48/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.8834 - accuracy: 0.4742 - val_loss: 1.8702 - val_accuracy: 0.5022\n",
      "Epoch 49/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 1.8631 - accuracy: 0.5123 - val_loss: 1.8540 - val_accuracy: 0.4922\n",
      "Epoch 50/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.8467 - accuracy: 0.4956 - val_loss: 1.8350 - val_accuracy: 0.4891\n",
      "Epoch 51/400\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.8283 - accuracy: 0.4954 - val_loss: 1.8173 - val_accuracy: 0.5076\n",
      "Epoch 52/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.8089 - accuracy: 0.5205 - val_loss: 1.7941 - val_accuracy: 0.5218\n",
      "Epoch 53/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.7888 - accuracy: 0.5207 - val_loss: 1.7765 - val_accuracy: 0.5113\n",
      "Epoch 54/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 1.7710 - accuracy: 0.5154 - val_loss: 1.7609 - val_accuracy: 0.5273\n",
      "Epoch 55/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.7514 - accuracy: 0.5367 - val_loss: 1.7375 - val_accuracy: 0.5435\n",
      "Epoch 56/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.7329 - accuracy: 0.5467 - val_loss: 1.7196 - val_accuracy: 0.5400\n",
      "Epoch 57/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.7129 - accuracy: 0.5450 - val_loss: 1.7051 - val_accuracy: 0.5383\n",
      "Epoch 58/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 1.6964 - accuracy: 0.5461 - val_loss: 1.6878 - val_accuracy: 0.5237\n",
      "Epoch 59/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 1.6800 - accuracy: 0.5428 - val_loss: 1.6649 - val_accuracy: 0.5644\n",
      "Epoch 60/400\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.6588 - accuracy: 0.5693 - val_loss: 1.6503 - val_accuracy: 0.5589\n",
      "Epoch 61/400\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1.6436 - accuracy: 0.5654 - val_loss: 1.6282 - val_accuracy: 0.5727\n",
      "Epoch 62/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.6231 - accuracy: 0.5768 - val_loss: 1.6109 - val_accuracy: 0.5702\n",
      "Epoch 63/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 1.6066 - accuracy: 0.5715 - val_loss: 1.5982 - val_accuracy: 0.5808\n",
      "Epoch 64/400\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 1.5917 - accuracy: 0.5822 - val_loss: 1.5783 - val_accuracy: 0.5816\n",
      "Epoch 65/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.5731 - accuracy: 0.5892 - val_loss: 1.5664 - val_accuracy: 0.5759\n",
      "Epoch 66/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.5600 - accuracy: 0.5832 - val_loss: 1.5555 - val_accuracy: 0.5776\n",
      "Epoch 67/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.5459 - accuracy: 0.5904 - val_loss: 1.5312 - val_accuracy: 0.5940\n",
      "Epoch 68/400\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 1.5286 - accuracy: 0.5943 - val_loss: 1.5181 - val_accuracy: 0.5988\n",
      "Epoch 69/400\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.5165 - accuracy: 0.6006 - val_loss: 1.5134 - val_accuracy: 0.5808\n",
      "Epoch 70/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.5047 - accuracy: 0.5872 - val_loss: 1.4949 - val_accuracy: 0.5974\n",
      "Epoch 71/400\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.4907 - accuracy: 0.6079 - val_loss: 1.4774 - val_accuracy: 0.6001\n",
      "Epoch 72/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.4735 - accuracy: 0.6052 - val_loss: 1.4717 - val_accuracy: 0.6061\n",
      "Epoch 73/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.4620 - accuracy: 0.6140 - val_loss: 1.4504 - val_accuracy: 0.6006\n",
      "Epoch 74/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.4484 - accuracy: 0.6100 - val_loss: 1.4410 - val_accuracy: 0.6193\n",
      "Epoch 75/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.4368 - accuracy: 0.6205 - val_loss: 1.4304 - val_accuracy: 0.6046\n",
      "Epoch 76/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.4246 - accuracy: 0.6140 - val_loss: 1.4168 - val_accuracy: 0.6138\n",
      "Epoch 77/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.4137 - accuracy: 0.6187 - val_loss: 1.3988 - val_accuracy: 0.6262\n",
      "Epoch 78/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.3981 - accuracy: 0.6285 - val_loss: 1.3898 - val_accuracy: 0.6254\n",
      "Epoch 79/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.3869 - accuracy: 0.6273 - val_loss: 1.3822 - val_accuracy: 0.6286\n",
      "Epoch 80/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.3768 - accuracy: 0.6322 - val_loss: 1.3702 - val_accuracy: 0.6246\n",
      "Epoch 81/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.3656 - accuracy: 0.6326 - val_loss: 1.3618 - val_accuracy: 0.6315\n",
      "Epoch 82/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 1.3584 - accuracy: 0.6364 - val_loss: 1.3517 - val_accuracy: 0.6314\n",
      "Epoch 83/400\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1.3489 - accuracy: 0.6367 - val_loss: 1.3506 - val_accuracy: 0.6270\n",
      "Epoch 84/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.3402 - accuracy: 0.6355 - val_loss: 1.3348 - val_accuracy: 0.6297\n",
      "Epoch 85/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.3307 - accuracy: 0.6402 - val_loss: 1.3285 - val_accuracy: 0.6348\n",
      "Epoch 86/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.3223 - accuracy: 0.6384 - val_loss: 1.3188 - val_accuracy: 0.6366\n",
      "Epoch 87/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 1.3124 - accuracy: 0.6423 - val_loss: 1.3068 - val_accuracy: 0.6371\n",
      "Epoch 88/400\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.3034 - accuracy: 0.6469 - val_loss: 1.2958 - val_accuracy: 0.6442\n",
      "Epoch 89/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.2943 - accuracy: 0.6456 - val_loss: 1.2956 - val_accuracy: 0.6428\n",
      "Epoch 90/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.2884 - accuracy: 0.6507 - val_loss: 1.2825 - val_accuracy: 0.6421\n",
      "Epoch 91/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 1.2794 - accuracy: 0.6471 - val_loss: 1.2710 - val_accuracy: 0.6523\n",
      "Epoch 92/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.2689 - accuracy: 0.6562 - val_loss: 1.2643 - val_accuracy: 0.6542\n",
      "Epoch 93/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.2590 - accuracy: 0.6590 - val_loss: 1.2576 - val_accuracy: 0.6493\n",
      "Epoch 94/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.2543 - accuracy: 0.6557 - val_loss: 1.2517 - val_accuracy: 0.6553\n",
      "Epoch 95/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.2468 - accuracy: 0.6598 - val_loss: 1.2480 - val_accuracy: 0.6543\n",
      "Epoch 96/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.2425 - accuracy: 0.6597 - val_loss: 1.2397 - val_accuracy: 0.6563\n",
      "Epoch 97/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.2360 - accuracy: 0.6610 - val_loss: 1.2286 - val_accuracy: 0.6578\n",
      "Epoch 98/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.2257 - accuracy: 0.6621 - val_loss: 1.2275 - val_accuracy: 0.6609\n",
      "Epoch 99/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.2206 - accuracy: 0.6676 - val_loss: 1.2268 - val_accuracy: 0.6514\n",
      "Epoch 100/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.2161 - accuracy: 0.6610 - val_loss: 1.2178 - val_accuracy: 0.6612\n",
      "Epoch 101/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.2099 - accuracy: 0.6684 - val_loss: 1.2110 - val_accuracy: 0.6602\n",
      "Epoch 102/400\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 1.2041 - accuracy: 0.6667 - val_loss: 1.2055 - val_accuracy: 0.6616\n",
      "Epoch 103/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.1983 - accuracy: 0.6683 - val_loss: 1.1984 - val_accuracy: 0.6654\n",
      "Epoch 104/400\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 1.1911 - accuracy: 0.6681 - val_loss: 1.1950 - val_accuracy: 0.6656\n",
      "Epoch 105/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.1861 - accuracy: 0.6732 - val_loss: 1.1841 - val_accuracy: 0.6706\n",
      "Epoch 106/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.1796 - accuracy: 0.6750 - val_loss: 1.1795 - val_accuracy: 0.6694\n",
      "Epoch 107/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.1751 - accuracy: 0.6746 - val_loss: 1.1759 - val_accuracy: 0.6738\n",
      "Epoch 108/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.1704 - accuracy: 0.6749 - val_loss: 1.1719 - val_accuracy: 0.6719\n",
      "Epoch 109/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 1.1622 - accuracy: 0.6795 - val_loss: 1.1622 - val_accuracy: 0.6746\n",
      "Epoch 110/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.1559 - accuracy: 0.6817 - val_loss: 1.1566 - val_accuracy: 0.6779\n",
      "Epoch 111/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.1505 - accuracy: 0.6817 - val_loss: 1.1611 - val_accuracy: 0.6719\n",
      "Epoch 112/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.1498 - accuracy: 0.6795 - val_loss: 1.1506 - val_accuracy: 0.6771\n",
      "Epoch 113/400\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.1432 - accuracy: 0.6831 - val_loss: 1.1507 - val_accuracy: 0.6730\n",
      "Epoch 114/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.1417 - accuracy: 0.6771 - val_loss: 1.1454 - val_accuracy: 0.6787\n",
      "Epoch 115/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.1379 - accuracy: 0.6822 - val_loss: 1.1445 - val_accuracy: 0.6756\n",
      "Epoch 116/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.1314 - accuracy: 0.6845 - val_loss: 1.1370 - val_accuracy: 0.6767\n",
      "Epoch 117/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.1298 - accuracy: 0.6790 - val_loss: 1.1368 - val_accuracy: 0.6747\n",
      "Epoch 118/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 1.1252 - accuracy: 0.6855 - val_loss: 1.1316 - val_accuracy: 0.6782\n",
      "Epoch 119/400\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1.1205 - accuracy: 0.6819 - val_loss: 1.1299 - val_accuracy: 0.6794\n",
      "Epoch 120/400\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.1181 - accuracy: 0.6856 - val_loss: 1.1235 - val_accuracy: 0.6802\n",
      "Epoch 121/400\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 1.1117 - accuracy: 0.6881 - val_loss: 1.1177 - val_accuracy: 0.6825\n",
      "Epoch 122/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.1068 - accuracy: 0.6903 - val_loss: 1.1107 - val_accuracy: 0.6860\n",
      "Epoch 123/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.1022 - accuracy: 0.6905 - val_loss: 1.1058 - val_accuracy: 0.6881\n",
      "Epoch 124/400\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1.0956 - accuracy: 0.6940 - val_loss: 1.1056 - val_accuracy: 0.6841\n",
      "Epoch 125/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 1.0939 - accuracy: 0.6899 - val_loss: 1.1032 - val_accuracy: 0.6899\n",
      "Epoch 126/400\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.0892 - accuracy: 0.6942 - val_loss: 1.0980 - val_accuracy: 0.6868\n",
      "Epoch 127/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.0850 - accuracy: 0.6964 - val_loss: 1.0981 - val_accuracy: 0.6861\n",
      "Epoch 128/400\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.0835 - accuracy: 0.6940 - val_loss: 1.0960 - val_accuracy: 0.6860\n",
      "Epoch 129/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.0815 - accuracy: 0.6950 - val_loss: 1.0894 - val_accuracy: 0.6927\n",
      "Epoch 130/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.0778 - accuracy: 0.6950 - val_loss: 1.0847 - val_accuracy: 0.6873\n",
      "Epoch 131/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.0749 - accuracy: 0.6954 - val_loss: 1.0804 - val_accuracy: 0.6937\n",
      "Epoch 132/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.0682 - accuracy: 0.6976 - val_loss: 1.0854 - val_accuracy: 0.6919\n",
      "Epoch 133/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.0657 - accuracy: 0.6985 - val_loss: 1.0800 - val_accuracy: 0.6893\n",
      "Epoch 134/400\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1.0658 - accuracy: 0.6955 - val_loss: 1.0763 - val_accuracy: 0.6929\n",
      "Epoch 135/400\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.0610 - accuracy: 0.7009 - val_loss: 1.0739 - val_accuracy: 0.6939\n",
      "Epoch 136/400\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.0586 - accuracy: 0.6986 - val_loss: 1.0680 - val_accuracy: 0.6948\n",
      "Epoch 137/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 1.0511 - accuracy: 0.7005 - val_loss: 1.0593 - val_accuracy: 0.6992\n",
      "Epoch 138/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.0475 - accuracy: 0.7042 - val_loss: 1.0795 - val_accuracy: 0.6907\n",
      "Epoch 139/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0553 - accuracy: 0.6995 - val_loss: 1.0555 - val_accuracy: 0.6985\n",
      "Epoch 140/400\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.0474 - accuracy: 0.7039 - val_loss: 1.0594 - val_accuracy: 0.6970\n",
      "Epoch 141/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0413 - accuracy: 0.7038 - val_loss: 1.0560 - val_accuracy: 0.6974\n",
      "Epoch 142/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0389 - accuracy: 0.7052 - val_loss: 1.0454 - val_accuracy: 0.7017\n",
      "Epoch 143/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0307 - accuracy: 0.7059 - val_loss: 1.0601 - val_accuracy: 0.6914\n",
      "Epoch 144/400\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1.0357 - accuracy: 0.7033 - val_loss: 1.0436 - val_accuracy: 0.6992\n",
      "Epoch 145/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.0330 - accuracy: 0.7048 - val_loss: 1.0633 - val_accuracy: 0.6920\n",
      "Epoch 146/400\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 1.0337 - accuracy: 0.7040 - val_loss: 1.0389 - val_accuracy: 0.7029\n",
      "Epoch 147/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 1.0246 - accuracy: 0.7088 - val_loss: 1.0388 - val_accuracy: 0.7007\n",
      "Epoch 148/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.0225 - accuracy: 0.7077 - val_loss: 1.0505 - val_accuracy: 0.6983\n",
      "Epoch 149/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.0244 - accuracy: 0.7091 - val_loss: 1.0294 - val_accuracy: 0.7057\n",
      "Epoch 150/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.0137 - accuracy: 0.7120 - val_loss: 1.0303 - val_accuracy: 0.7006\n",
      "Epoch 151/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.0133 - accuracy: 0.7088 - val_loss: 1.0301 - val_accuracy: 0.7039\n",
      "Epoch 152/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 1.0104 - accuracy: 0.7101 - val_loss: 1.0198 - val_accuracy: 0.7096\n",
      "Epoch 153/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.0048 - accuracy: 0.7166 - val_loss: 1.0206 - val_accuracy: 0.7053\n",
      "Epoch 154/400\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1.0013 - accuracy: 0.7125 - val_loss: 1.0169 - val_accuracy: 0.7113\n",
      "Epoch 155/400\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.9960 - accuracy: 0.7159 - val_loss: 1.0256 - val_accuracy: 0.7061\n",
      "Epoch 156/400\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 1.0005 - accuracy: 0.7162 - val_loss: 1.0225 - val_accuracy: 0.7047\n",
      "Epoch 157/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9995 - accuracy: 0.7125 - val_loss: 1.0126 - val_accuracy: 0.7074\n",
      "Epoch 158/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9950 - accuracy: 0.7148 - val_loss: 1.0129 - val_accuracy: 0.7083\n",
      "Epoch 159/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.9917 - accuracy: 0.7164 - val_loss: 1.0110 - val_accuracy: 0.7136\n",
      "Epoch 160/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.9869 - accuracy: 0.7181 - val_loss: 1.0022 - val_accuracy: 0.7096\n",
      "Epoch 161/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9847 - accuracy: 0.7160 - val_loss: 1.0080 - val_accuracy: 0.7083\n",
      "Epoch 162/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.9844 - accuracy: 0.7194 - val_loss: 1.0045 - val_accuracy: 0.7101\n",
      "Epoch 163/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9791 - accuracy: 0.7196 - val_loss: 1.0017 - val_accuracy: 0.7103\n",
      "Epoch 164/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.9768 - accuracy: 0.7195 - val_loss: 0.9952 - val_accuracy: 0.7169\n",
      "Epoch 165/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9741 - accuracy: 0.7220 - val_loss: 0.9990 - val_accuracy: 0.7116\n",
      "Epoch 166/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.9719 - accuracy: 0.7230 - val_loss: 0.9999 - val_accuracy: 0.7096\n",
      "Epoch 167/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.9715 - accuracy: 0.7199 - val_loss: 0.9962 - val_accuracy: 0.7157\n",
      "Epoch 168/400\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.9686 - accuracy: 0.7228 - val_loss: 0.9847 - val_accuracy: 0.7143\n",
      "Epoch 169/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.9656 - accuracy: 0.7219 - val_loss: 0.9848 - val_accuracy: 0.7163\n",
      "Epoch 170/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.9607 - accuracy: 0.7250 - val_loss: 0.9829 - val_accuracy: 0.7194\n",
      "Epoch 171/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.9586 - accuracy: 0.7278 - val_loss: 0.9804 - val_accuracy: 0.7166\n",
      "Epoch 172/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9558 - accuracy: 0.7271 - val_loss: 0.9907 - val_accuracy: 0.7149\n",
      "Epoch 173/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.9599 - accuracy: 0.7238 - val_loss: 0.9869 - val_accuracy: 0.7134\n",
      "Epoch 174/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.9582 - accuracy: 0.7259 - val_loss: 0.9738 - val_accuracy: 0.7193\n",
      "Epoch 175/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.9506 - accuracy: 0.7278 - val_loss: 0.9766 - val_accuracy: 0.7172\n",
      "Epoch 176/400\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.9501 - accuracy: 0.7271 - val_loss: 0.9757 - val_accuracy: 0.7192\n",
      "Epoch 177/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.9493 - accuracy: 0.7271 - val_loss: 0.9673 - val_accuracy: 0.7209\n",
      "Epoch 178/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.9426 - accuracy: 0.7310 - val_loss: 0.9700 - val_accuracy: 0.7198\n",
      "Epoch 179/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.9443 - accuracy: 0.7274 - val_loss: 0.9668 - val_accuracy: 0.7204\n",
      "Epoch 180/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.9402 - accuracy: 0.7326 - val_loss: 0.9664 - val_accuracy: 0.7217\n",
      "Epoch 181/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.9367 - accuracy: 0.7319 - val_loss: 0.9615 - val_accuracy: 0.7224\n",
      "Epoch 182/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.9337 - accuracy: 0.7329 - val_loss: 0.9656 - val_accuracy: 0.7185\n",
      "Epoch 183/400\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.9345 - accuracy: 0.7306 - val_loss: 0.9564 - val_accuracy: 0.7254\n",
      "Epoch 184/400\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.9328 - accuracy: 0.7347 - val_loss: 0.9580 - val_accuracy: 0.7251\n",
      "Epoch 185/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.9261 - accuracy: 0.7351 - val_loss: 0.9554 - val_accuracy: 0.7239\n",
      "Epoch 186/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.9258 - accuracy: 0.7338 - val_loss: 0.9532 - val_accuracy: 0.7252\n",
      "Epoch 187/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.9244 - accuracy: 0.7346 - val_loss: 0.9461 - val_accuracy: 0.7277\n",
      "Epoch 188/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9191 - accuracy: 0.7364 - val_loss: 0.9490 - val_accuracy: 0.7273\n",
      "Epoch 189/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.9184 - accuracy: 0.7380 - val_loss: 0.9510 - val_accuracy: 0.7253\n",
      "Epoch 190/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.9174 - accuracy: 0.7371 - val_loss: 0.9458 - val_accuracy: 0.7267\n",
      "Epoch 191/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9152 - accuracy: 0.7370 - val_loss: 0.9395 - val_accuracy: 0.7276\n",
      "Epoch 192/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.9125 - accuracy: 0.7397 - val_loss: 0.9392 - val_accuracy: 0.7287\n",
      "Epoch 193/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.9094 - accuracy: 0.7401 - val_loss: 0.9476 - val_accuracy: 0.7280\n",
      "Epoch 194/400\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.9110 - accuracy: 0.7412 - val_loss: 0.9391 - val_accuracy: 0.7273\n",
      "Epoch 195/400\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.9091 - accuracy: 0.7385 - val_loss: 0.9363 - val_accuracy: 0.7298\n",
      "Epoch 196/400\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.9042 - accuracy: 0.7403 - val_loss: 0.9325 - val_accuracy: 0.7315\n",
      "Epoch 197/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9028 - accuracy: 0.7399 - val_loss: 0.9419 - val_accuracy: 0.7263\n",
      "Epoch 198/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.9054 - accuracy: 0.7390 - val_loss: 0.9298 - val_accuracy: 0.7319\n",
      "Epoch 199/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9008 - accuracy: 0.7409 - val_loss: 0.9438 - val_accuracy: 0.7226\n",
      "Epoch 200/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.9027 - accuracy: 0.7386 - val_loss: 0.9268 - val_accuracy: 0.7323\n",
      "Epoch 201/400\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.8970 - accuracy: 0.7414 - val_loss: 0.9253 - val_accuracy: 0.7318\n",
      "Epoch 202/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.8932 - accuracy: 0.7431 - val_loss: 0.9235 - val_accuracy: 0.7326\n",
      "Epoch 203/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.8902 - accuracy: 0.7434 - val_loss: 0.9222 - val_accuracy: 0.7321\n",
      "Epoch 204/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.8882 - accuracy: 0.7462 - val_loss: 0.9201 - val_accuracy: 0.7343\n",
      "Epoch 205/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.8844 - accuracy: 0.7465 - val_loss: 0.9184 - val_accuracy: 0.7336\n",
      "Epoch 206/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.8837 - accuracy: 0.7467 - val_loss: 0.9224 - val_accuracy: 0.7318\n",
      "Epoch 207/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8874 - accuracy: 0.7431 - val_loss: 0.9214 - val_accuracy: 0.7294\n",
      "Epoch 208/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.8842 - accuracy: 0.7466 - val_loss: 0.9138 - val_accuracy: 0.7368\n",
      "Epoch 209/400\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.8776 - accuracy: 0.7476 - val_loss: 0.9114 - val_accuracy: 0.7366\n",
      "Epoch 210/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.8750 - accuracy: 0.7497 - val_loss: 0.9073 - val_accuracy: 0.7387\n",
      "Epoch 211/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.8737 - accuracy: 0.7488 - val_loss: 0.9090 - val_accuracy: 0.7354\n",
      "Epoch 212/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8731 - accuracy: 0.7499 - val_loss: 0.9033 - val_accuracy: 0.7384\n",
      "Epoch 213/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8704 - accuracy: 0.7486 - val_loss: 0.9003 - val_accuracy: 0.7393\n",
      "Epoch 214/400\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.8667 - accuracy: 0.7506 - val_loss: 0.9001 - val_accuracy: 0.7392\n",
      "Epoch 215/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.8639 - accuracy: 0.7523 - val_loss: 0.9001 - val_accuracy: 0.7388\n",
      "Epoch 216/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.8624 - accuracy: 0.7537 - val_loss: 0.9047 - val_accuracy: 0.7358\n",
      "Epoch 217/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.8641 - accuracy: 0.7500 - val_loss: 0.8969 - val_accuracy: 0.7417\n",
      "Epoch 218/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.8601 - accuracy: 0.7513 - val_loss: 0.8988 - val_accuracy: 0.7408\n",
      "Epoch 219/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.8594 - accuracy: 0.7531 - val_loss: 0.8929 - val_accuracy: 0.7407\n",
      "Epoch 220/400\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.8574 - accuracy: 0.7543 - val_loss: 0.8944 - val_accuracy: 0.7393\n",
      "Epoch 221/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.8553 - accuracy: 0.7543 - val_loss: 0.8903 - val_accuracy: 0.7433\n",
      "Epoch 222/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.8524 - accuracy: 0.7555 - val_loss: 0.8889 - val_accuracy: 0.7432\n",
      "Epoch 223/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.8491 - accuracy: 0.7568 - val_loss: 0.8900 - val_accuracy: 0.7417\n",
      "Epoch 224/400\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.8497 - accuracy: 0.7562 - val_loss: 0.8855 - val_accuracy: 0.7424\n",
      "Epoch 225/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.8465 - accuracy: 0.7575 - val_loss: 0.8865 - val_accuracy: 0.7438\n",
      "Epoch 226/400\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.8471 - accuracy: 0.7561 - val_loss: 0.8838 - val_accuracy: 0.7469\n",
      "Epoch 227/400\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.8435 - accuracy: 0.7580 - val_loss: 0.8892 - val_accuracy: 0.7416\n",
      "Epoch 228/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.8447 - accuracy: 0.7581 - val_loss: 0.8818 - val_accuracy: 0.7429\n",
      "Epoch 229/400\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.8442 - accuracy: 0.7575 - val_loss: 0.8841 - val_accuracy: 0.7431\n",
      "Epoch 230/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.8423 - accuracy: 0.7560 - val_loss: 0.8791 - val_accuracy: 0.7432\n",
      "Epoch 231/400\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.8394 - accuracy: 0.7576 - val_loss: 0.8811 - val_accuracy: 0.7458\n",
      "Epoch 232/400\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.8368 - accuracy: 0.7597 - val_loss: 0.8789 - val_accuracy: 0.7444\n",
      "Epoch 233/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.8341 - accuracy: 0.7610 - val_loss: 0.8725 - val_accuracy: 0.7485\n",
      "Epoch 234/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.8321 - accuracy: 0.7613 - val_loss: 0.8723 - val_accuracy: 0.7481\n",
      "Epoch 235/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.8304 - accuracy: 0.7604 - val_loss: 0.8673 - val_accuracy: 0.7497\n",
      "Epoch 236/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.8258 - accuracy: 0.7621 - val_loss: 0.8739 - val_accuracy: 0.7449\n",
      "Epoch 237/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.8281 - accuracy: 0.7622 - val_loss: 0.8708 - val_accuracy: 0.7478\n",
      "Epoch 238/400\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.8271 - accuracy: 0.7621 - val_loss: 0.8672 - val_accuracy: 0.7491\n",
      "Epoch 239/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.8240 - accuracy: 0.7638 - val_loss: 0.8706 - val_accuracy: 0.7461\n",
      "Epoch 240/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.8234 - accuracy: 0.7633 - val_loss: 0.8633 - val_accuracy: 0.7521\n",
      "Epoch 241/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.8210 - accuracy: 0.7646 - val_loss: 0.8593 - val_accuracy: 0.7519\n",
      "Epoch 242/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.8169 - accuracy: 0.7660 - val_loss: 0.8637 - val_accuracy: 0.7505\n",
      "Epoch 243/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.8172 - accuracy: 0.7643 - val_loss: 0.8580 - val_accuracy: 0.7521\n",
      "Epoch 244/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.8129 - accuracy: 0.7657 - val_loss: 0.8560 - val_accuracy: 0.7536\n",
      "Epoch 245/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.8124 - accuracy: 0.7659 - val_loss: 0.8572 - val_accuracy: 0.7537\n",
      "Epoch 246/400\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.8107 - accuracy: 0.7662 - val_loss: 0.8592 - val_accuracy: 0.7509\n",
      "Epoch 247/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.8119 - accuracy: 0.7655 - val_loss: 0.8579 - val_accuracy: 0.7528\n",
      "Epoch 248/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.8109 - accuracy: 0.7653 - val_loss: 0.8547 - val_accuracy: 0.7522\n",
      "Epoch 249/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.8075 - accuracy: 0.7692 - val_loss: 0.8531 - val_accuracy: 0.7543\n",
      "Epoch 250/400\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.8055 - accuracy: 0.7677 - val_loss: 0.8509 - val_accuracy: 0.7534\n",
      "Epoch 251/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.8037 - accuracy: 0.7681 - val_loss: 0.8566 - val_accuracy: 0.7526\n",
      "Epoch 252/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.8022 - accuracy: 0.7689 - val_loss: 0.8436 - val_accuracy: 0.7580\n",
      "Epoch 253/400\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.8001 - accuracy: 0.7697 - val_loss: 0.8462 - val_accuracy: 0.7566\n",
      "Epoch 254/400\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.7991 - accuracy: 0.7698 - val_loss: 0.8451 - val_accuracy: 0.7565\n",
      "Epoch 255/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.7960 - accuracy: 0.7701 - val_loss: 0.8424 - val_accuracy: 0.7563\n",
      "Epoch 256/400\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.7947 - accuracy: 0.7719 - val_loss: 0.8475 - val_accuracy: 0.7554\n",
      "Epoch 257/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.7984 - accuracy: 0.7694 - val_loss: 0.8447 - val_accuracy: 0.7553\n",
      "Epoch 258/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.7985 - accuracy: 0.7686 - val_loss: 0.8394 - val_accuracy: 0.7584\n",
      "Epoch 259/400\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7893 - accuracy: 0.7727 - val_loss: 0.8382 - val_accuracy: 0.7592\n",
      "Epoch 260/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.7892 - accuracy: 0.7709 - val_loss: 0.8370 - val_accuracy: 0.7596\n",
      "Epoch 261/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.7880 - accuracy: 0.7727 - val_loss: 0.8338 - val_accuracy: 0.7591\n",
      "Epoch 262/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.7848 - accuracy: 0.7736 - val_loss: 0.8311 - val_accuracy: 0.7599\n",
      "Epoch 263/400\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.7847 - accuracy: 0.7736 - val_loss: 0.8425 - val_accuracy: 0.7566\n",
      "Epoch 264/400\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.7886 - accuracy: 0.7716 - val_loss: 0.8394 - val_accuracy: 0.7573\n",
      "Epoch 265/400\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.7835 - accuracy: 0.7745 - val_loss: 0.8345 - val_accuracy: 0.7588\n",
      "Epoch 266/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.7845 - accuracy: 0.7738 - val_loss: 0.8264 - val_accuracy: 0.7639\n",
      "Epoch 267/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.7785 - accuracy: 0.7752 - val_loss: 0.8373 - val_accuracy: 0.7559\n",
      "Epoch 268/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.7813 - accuracy: 0.7747 - val_loss: 0.8334 - val_accuracy: 0.7593\n",
      "Epoch 269/400\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.7767 - accuracy: 0.7757 - val_loss: 0.8258 - val_accuracy: 0.7627\n",
      "Epoch 270/400\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7742 - accuracy: 0.7753 - val_loss: 0.8231 - val_accuracy: 0.7634\n",
      "Epoch 271/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.7707 - accuracy: 0.7777 - val_loss: 0.8229 - val_accuracy: 0.7625\n",
      "Epoch 272/400\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7694 - accuracy: 0.7789 - val_loss: 0.8270 - val_accuracy: 0.7602\n",
      "Epoch 273/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.7704 - accuracy: 0.7768 - val_loss: 0.8334 - val_accuracy: 0.7586\n",
      "Epoch 274/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.7732 - accuracy: 0.7774 - val_loss: 0.8247 - val_accuracy: 0.7619\n",
      "Epoch 275/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.7736 - accuracy: 0.7775 - val_loss: 0.8259 - val_accuracy: 0.7606\n",
      "Epoch 276/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7715 - accuracy: 0.7754 - val_loss: 0.8274 - val_accuracy: 0.7593\n",
      "Epoch 00276: early stopping\n",
      "\n",
      "Test loss: 0.827\n",
      "Test accuracy: 0.759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa250561518>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 20000\n",
    "epochs = 400   # Setting up higher epoch in persuit of finding global moinima,\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)   # Set up early stopping to avoid wastage of computing power\n",
    "                                                                            # Kept patience level to 5 to check for considerable time to get out of local minima if possible\n",
    "    \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [es],\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S1XyqmHdznkd"
   },
   "source": [
    "Observations\n",
    "1. With higher epochs we were able to find better global minima\n",
    "2. The early stop made sure to avoid trying more time and wasting power. With the test run the early stopping was made at about 280 epochs.\n",
    "3. The test accuracy is at about 76%\n",
    "\n",
    "Trying with Batch Normalization technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C0z5hobt69i0"
   },
   "source": [
    "# Implement batch normalization for training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "HCdj6ZFA0pww",
    "outputId": "1ee125db-6c1c-4a49-f018-4ee9c088dab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization (None, 1024) ==> (None, 1024)\n",
      "dense_8 (None, 1024) ==> (None, 1024)\n",
      "dense_9 (None, 1024) ==> (None, 10)\n",
      "\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,063,946\n",
      "Trainable params: 1,061,898\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(1024,))) # Set the batch normalization with input shape 32 x 32\n",
    "model.add(Dense(1024, activation='relu', input_shape=(1024,)))   #First hidden layer of 1024  neurons, each neuron takes input \n",
    "                                                               # vector of size 1024\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))            # Adding a softmax layer for output which contains as many \n",
    "                                                               # neurons as the number of classes (10) which is also the \n",
    "                                                               # the shape of each output vector ( one hot coded)\n",
    "\n",
    "                                                               # output layer also uses softmax. This normalizes the values \n",
    "                                                               # from the ten output nodes such that: \n",
    "                                                               #        all the values are between 0 and 1, and\n",
    "                                                               #        the sum of all ten values is 1.  \n",
    "                                                               # prediction is the lable of the node that gets highest fraction, is \n",
    "        \n",
    "        \n",
    "\n",
    "for l in model.layers:\n",
    "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
    "print()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kRXXFD-q09Uj",
    "outputId": "872233ca-fb1b-47f1-f075-388d8cb62f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 3.1868 - accuracy: 0.1114 - val_loss: 3.3515 - val_accuracy: 0.0988\n",
      "Epoch 2/400\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 3.6821 - accuracy: 0.1485 - val_loss: 2.6308 - val_accuracy: 0.0988\n",
      "Epoch 3/400\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 3.1319 - accuracy: 0.1785 - val_loss: 2.5903 - val_accuracy: 0.0965\n",
      "Epoch 4/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 2.5242 - accuracy: 0.2447 - val_loss: 2.4133 - val_accuracy: 0.1003\n",
      "Epoch 5/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 2.3925 - accuracy: 0.2745 - val_loss: 2.3579 - val_accuracy: 0.1333\n",
      "Epoch 6/400\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 2.0960 - accuracy: 0.3466 - val_loss: 2.2913 - val_accuracy: 0.1493\n",
      "Epoch 7/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 1.9699 - accuracy: 0.3805 - val_loss: 2.2801 - val_accuracy: 0.1719\n",
      "Epoch 8/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 1.8231 - accuracy: 0.4371 - val_loss: 2.2401 - val_accuracy: 0.2055\n",
      "Epoch 9/400\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 1.7319 - accuracy: 0.4440 - val_loss: 2.1820 - val_accuracy: 0.2276\n",
      "Epoch 10/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 1.6387 - accuracy: 0.4904 - val_loss: 2.1359 - val_accuracy: 0.2780\n",
      "Epoch 11/400\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 1.5378 - accuracy: 0.5307 - val_loss: 2.1023 - val_accuracy: 0.3632\n",
      "Epoch 12/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.4693 - accuracy: 0.5640 - val_loss: 2.0627 - val_accuracy: 0.3977\n",
      "Epoch 13/400\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 1.4127 - accuracy: 0.5857 - val_loss: 2.0124 - val_accuracy: 0.5137\n",
      "Epoch 14/400\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.3503 - accuracy: 0.6151 - val_loss: 1.9872 - val_accuracy: 0.5181\n",
      "Epoch 15/400\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 1.3072 - accuracy: 0.6281 - val_loss: 1.9464 - val_accuracy: 0.5806\n",
      "Epoch 16/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 1.2581 - accuracy: 0.6503 - val_loss: 1.9133 - val_accuracy: 0.5684\n",
      "Epoch 17/400\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 1.2185 - accuracy: 0.6636 - val_loss: 1.8816 - val_accuracy: 0.5969\n",
      "Epoch 18/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.1838 - accuracy: 0.6704 - val_loss: 1.8469 - val_accuracy: 0.6249\n",
      "Epoch 19/400\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 1.1530 - accuracy: 0.6820 - val_loss: 1.8264 - val_accuracy: 0.6239\n",
      "Epoch 20/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 1.1223 - accuracy: 0.6905 - val_loss: 1.7925 - val_accuracy: 0.6483\n",
      "Epoch 21/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 1.0942 - accuracy: 0.6983 - val_loss: 1.7626 - val_accuracy: 0.6669\n",
      "Epoch 22/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 1.0701 - accuracy: 0.7074 - val_loss: 1.7370 - val_accuracy: 0.6750\n",
      "Epoch 23/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 1.0464 - accuracy: 0.7145 - val_loss: 1.7138 - val_accuracy: 0.6692\n",
      "Epoch 24/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 1.0252 - accuracy: 0.7181 - val_loss: 1.6876 - val_accuracy: 0.6765\n",
      "Epoch 25/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 1.0044 - accuracy: 0.7253 - val_loss: 1.6659 - val_accuracy: 0.6858\n",
      "Epoch 26/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.9879 - accuracy: 0.7304 - val_loss: 1.6399 - val_accuracy: 0.6929\n",
      "Epoch 27/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.9707 - accuracy: 0.7337 - val_loss: 1.6194 - val_accuracy: 0.6893\n",
      "Epoch 28/400\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.9534 - accuracy: 0.7390 - val_loss: 1.5930 - val_accuracy: 0.7084\n",
      "Epoch 29/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.9345 - accuracy: 0.7451 - val_loss: 1.5714 - val_accuracy: 0.7098\n",
      "Epoch 30/400\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.9195 - accuracy: 0.7501 - val_loss: 1.5526 - val_accuracy: 0.7138\n",
      "Epoch 31/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.9052 - accuracy: 0.7530 - val_loss: 1.5311 - val_accuracy: 0.7191\n",
      "Epoch 32/400\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.8915 - accuracy: 0.7570 - val_loss: 1.5116 - val_accuracy: 0.7251\n",
      "Epoch 33/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8779 - accuracy: 0.7597 - val_loss: 1.4894 - val_accuracy: 0.7287\n",
      "Epoch 34/400\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.8667 - accuracy: 0.7632 - val_loss: 1.4755 - val_accuracy: 0.7248\n",
      "Epoch 35/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.8554 - accuracy: 0.7646 - val_loss: 1.4507 - val_accuracy: 0.7297\n",
      "Epoch 36/400\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.8435 - accuracy: 0.7686 - val_loss: 1.4328 - val_accuracy: 0.7387\n",
      "Epoch 37/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.8309 - accuracy: 0.7725 - val_loss: 1.4133 - val_accuracy: 0.7369\n",
      "Epoch 38/400\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.8205 - accuracy: 0.7741 - val_loss: 1.3944 - val_accuracy: 0.7443\n",
      "Epoch 39/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.8098 - accuracy: 0.7768 - val_loss: 1.3769 - val_accuracy: 0.7469\n",
      "Epoch 40/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.7990 - accuracy: 0.7811 - val_loss: 1.3594 - val_accuracy: 0.7461\n",
      "Epoch 41/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.7914 - accuracy: 0.7830 - val_loss: 1.3453 - val_accuracy: 0.7488\n",
      "Epoch 42/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7799 - accuracy: 0.7867 - val_loss: 1.3231 - val_accuracy: 0.7531\n",
      "Epoch 43/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.7697 - accuracy: 0.7892 - val_loss: 1.3099 - val_accuracy: 0.7521\n",
      "Epoch 44/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7630 - accuracy: 0.7898 - val_loss: 1.2940 - val_accuracy: 0.7536\n",
      "Epoch 45/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.7531 - accuracy: 0.7948 - val_loss: 1.2755 - val_accuracy: 0.7604\n",
      "Epoch 46/400\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.7445 - accuracy: 0.7972 - val_loss: 1.2554 - val_accuracy: 0.7639\n",
      "Epoch 47/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.7348 - accuracy: 0.7996 - val_loss: 1.2411 - val_accuracy: 0.7669\n",
      "Epoch 48/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.7271 - accuracy: 0.8017 - val_loss: 1.2263 - val_accuracy: 0.7636\n",
      "Epoch 49/400\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.7200 - accuracy: 0.8032 - val_loss: 1.2108 - val_accuracy: 0.7697\n",
      "Epoch 50/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.7095 - accuracy: 0.8080 - val_loss: 1.1935 - val_accuracy: 0.7721\n",
      "Epoch 51/400\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.7039 - accuracy: 0.8081 - val_loss: 1.1770 - val_accuracy: 0.7743\n",
      "Epoch 52/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.6969 - accuracy: 0.8099 - val_loss: 1.1722 - val_accuracy: 0.7639\n",
      "Epoch 53/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.6927 - accuracy: 0.8105 - val_loss: 1.1496 - val_accuracy: 0.7774\n",
      "Epoch 54/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.6845 - accuracy: 0.8137 - val_loss: 1.1360 - val_accuracy: 0.7763\n",
      "Epoch 55/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.6769 - accuracy: 0.8159 - val_loss: 1.1189 - val_accuracy: 0.7835\n",
      "Epoch 56/400\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.6685 - accuracy: 0.8168 - val_loss: 1.1056 - val_accuracy: 0.7808\n",
      "Epoch 57/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.6631 - accuracy: 0.8204 - val_loss: 1.0890 - val_accuracy: 0.7853\n",
      "Epoch 58/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.6556 - accuracy: 0.8220 - val_loss: 1.0782 - val_accuracy: 0.7833\n",
      "Epoch 59/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.6534 - accuracy: 0.8210 - val_loss: 1.0665 - val_accuracy: 0.7836\n",
      "Epoch 60/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.6462 - accuracy: 0.8223 - val_loss: 1.0487 - val_accuracy: 0.7895\n",
      "Epoch 61/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.6374 - accuracy: 0.8280 - val_loss: 1.0411 - val_accuracy: 0.7892\n",
      "Epoch 62/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.6312 - accuracy: 0.8285 - val_loss: 1.0207 - val_accuracy: 0.7961\n",
      "Epoch 63/400\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.6246 - accuracy: 0.8309 - val_loss: 1.0110 - val_accuracy: 0.7911\n",
      "Epoch 64/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.6186 - accuracy: 0.8327 - val_loss: 1.0019 - val_accuracy: 0.7961\n",
      "Epoch 65/400\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.6126 - accuracy: 0.8323 - val_loss: 0.9839 - val_accuracy: 0.7978\n",
      "Epoch 66/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.6062 - accuracy: 0.8360 - val_loss: 0.9726 - val_accuracy: 0.8023\n",
      "Epoch 67/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.6005 - accuracy: 0.8374 - val_loss: 0.9654 - val_accuracy: 0.8001\n",
      "Epoch 68/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.5953 - accuracy: 0.8402 - val_loss: 0.9465 - val_accuracy: 0.8032\n",
      "Epoch 69/400\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.5898 - accuracy: 0.8410 - val_loss: 0.9375 - val_accuracy: 0.8010\n",
      "Epoch 70/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.5844 - accuracy: 0.8421 - val_loss: 0.9264 - val_accuracy: 0.8058\n",
      "Epoch 71/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.5796 - accuracy: 0.8423 - val_loss: 0.9152 - val_accuracy: 0.8075\n",
      "Epoch 72/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.5742 - accuracy: 0.8456 - val_loss: 0.9085 - val_accuracy: 0.8022\n",
      "Epoch 73/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.5721 - accuracy: 0.8451 - val_loss: 0.8942 - val_accuracy: 0.8091\n",
      "Epoch 74/400\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.5634 - accuracy: 0.8479 - val_loss: 0.8831 - val_accuracy: 0.8091\n",
      "Epoch 75/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.5592 - accuracy: 0.8494 - val_loss: 0.8733 - val_accuracy: 0.8094\n",
      "Epoch 76/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.5532 - accuracy: 0.8514 - val_loss: 0.8653 - val_accuracy: 0.8111\n",
      "Epoch 77/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.5501 - accuracy: 0.8515 - val_loss: 0.8488 - val_accuracy: 0.8152\n",
      "Epoch 78/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.5440 - accuracy: 0.8544 - val_loss: 0.8414 - val_accuracy: 0.8147\n",
      "Epoch 79/400\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.5413 - accuracy: 0.8551 - val_loss: 0.8421 - val_accuracy: 0.8126\n",
      "Epoch 80/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.5397 - accuracy: 0.8530 - val_loss: 0.8260 - val_accuracy: 0.8145\n",
      "Epoch 81/400\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.5339 - accuracy: 0.8552 - val_loss: 0.8169 - val_accuracy: 0.8186\n",
      "Epoch 82/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.5263 - accuracy: 0.8591 - val_loss: 0.8058 - val_accuracy: 0.8186\n",
      "Epoch 83/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.5226 - accuracy: 0.8603 - val_loss: 0.7959 - val_accuracy: 0.8214\n",
      "Epoch 84/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.5182 - accuracy: 0.8614 - val_loss: 0.7883 - val_accuracy: 0.8206\n",
      "Epoch 85/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.5150 - accuracy: 0.8617 - val_loss: 0.7858 - val_accuracy: 0.8182\n",
      "Epoch 86/400\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.5127 - accuracy: 0.8603 - val_loss: 0.7711 - val_accuracy: 0.8246\n",
      "Epoch 87/400\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.5058 - accuracy: 0.8649 - val_loss: 0.7640 - val_accuracy: 0.8276\n",
      "Epoch 88/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.5017 - accuracy: 0.8665 - val_loss: 0.7550 - val_accuracy: 0.8279\n",
      "Epoch 89/400\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.4971 - accuracy: 0.8690 - val_loss: 0.7496 - val_accuracy: 0.8248\n",
      "Epoch 90/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.4947 - accuracy: 0.8676 - val_loss: 0.7443 - val_accuracy: 0.8262\n",
      "Epoch 91/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.4918 - accuracy: 0.8688 - val_loss: 0.7402 - val_accuracy: 0.8267\n",
      "Epoch 92/400\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.4886 - accuracy: 0.8701 - val_loss: 0.7285 - val_accuracy: 0.8301\n",
      "Epoch 93/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.4877 - accuracy: 0.8696 - val_loss: 0.7242 - val_accuracy: 0.8266\n",
      "Epoch 94/400\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.4818 - accuracy: 0.8712 - val_loss: 0.7173 - val_accuracy: 0.8264\n",
      "Epoch 95/400\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.4785 - accuracy: 0.8723 - val_loss: 0.7086 - val_accuracy: 0.8298\n",
      "Epoch 96/400\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.4751 - accuracy: 0.8733 - val_loss: 0.7022 - val_accuracy: 0.8299\n",
      "Epoch 97/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.4679 - accuracy: 0.8753 - val_loss: 0.7019 - val_accuracy: 0.8297\n",
      "Epoch 98/400\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.4671 - accuracy: 0.8761 - val_loss: 0.6913 - val_accuracy: 0.8313\n",
      "Epoch 99/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.4639 - accuracy: 0.8771 - val_loss: 0.6855 - val_accuracy: 0.8322\n",
      "Epoch 100/400\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.4602 - accuracy: 0.8785 - val_loss: 0.6851 - val_accuracy: 0.8286\n",
      "Epoch 101/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.4619 - accuracy: 0.8749 - val_loss: 0.6708 - val_accuracy: 0.8363\n",
      "Epoch 102/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.4543 - accuracy: 0.8797 - val_loss: 0.6725 - val_accuracy: 0.8326\n",
      "Epoch 103/400\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.4550 - accuracy: 0.8781 - val_loss: 0.6662 - val_accuracy: 0.8329\n",
      "Epoch 104/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.4507 - accuracy: 0.8790 - val_loss: 0.6636 - val_accuracy: 0.8338\n",
      "Epoch 105/400\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.4478 - accuracy: 0.8802 - val_loss: 0.6599 - val_accuracy: 0.8324\n",
      "Epoch 106/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.4439 - accuracy: 0.8825 - val_loss: 0.6551 - val_accuracy: 0.8336\n",
      "Epoch 107/400\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.4436 - accuracy: 0.8803 - val_loss: 0.6540 - val_accuracy: 0.8343\n",
      "Epoch 108/400\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.4444 - accuracy: 0.8802 - val_loss: 0.6452 - val_accuracy: 0.8352\n",
      "Epoch 109/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.4440 - accuracy: 0.8805 - val_loss: 0.6441 - val_accuracy: 0.8326\n",
      "Epoch 110/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.4399 - accuracy: 0.8807 - val_loss: 0.6510 - val_accuracy: 0.8276\n",
      "Epoch 111/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.4401 - accuracy: 0.8798 - val_loss: 0.6324 - val_accuracy: 0.8378\n",
      "Epoch 112/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.4363 - accuracy: 0.8820 - val_loss: 0.6405 - val_accuracy: 0.8302\n",
      "Epoch 113/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.4410 - accuracy: 0.8782 - val_loss: 0.6348 - val_accuracy: 0.8337\n",
      "Epoch 114/400\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.4309 - accuracy: 0.8843 - val_loss: 0.6300 - val_accuracy: 0.8358\n",
      "Epoch 115/400\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.4257 - accuracy: 0.8850 - val_loss: 0.6253 - val_accuracy: 0.8332\n",
      "Epoch 116/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.4246 - accuracy: 0.8850 - val_loss: 0.6125 - val_accuracy: 0.8401\n",
      "Epoch 117/400\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.4172 - accuracy: 0.8874 - val_loss: 0.6112 - val_accuracy: 0.8408\n",
      "Epoch 118/400\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.4133 - accuracy: 0.8891 - val_loss: 0.6021 - val_accuracy: 0.8435\n",
      "Epoch 119/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.4076 - accuracy: 0.8916 - val_loss: 0.6022 - val_accuracy: 0.8408\n",
      "Epoch 120/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.4074 - accuracy: 0.8921 - val_loss: 0.6010 - val_accuracy: 0.8415\n",
      "Epoch 121/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.4024 - accuracy: 0.8945 - val_loss: 0.5916 - val_accuracy: 0.8432\n",
      "Epoch 122/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.3977 - accuracy: 0.8963 - val_loss: 0.5942 - val_accuracy: 0.8429\n",
      "Epoch 123/400\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.3974 - accuracy: 0.8957 - val_loss: 0.5958 - val_accuracy: 0.8425\n",
      "Epoch 124/400\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.3962 - accuracy: 0.8951 - val_loss: 0.5864 - val_accuracy: 0.8446\n",
      "Epoch 125/400\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.3901 - accuracy: 0.8975 - val_loss: 0.5835 - val_accuracy: 0.8433\n",
      "Epoch 126/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.3889 - accuracy: 0.8974 - val_loss: 0.5800 - val_accuracy: 0.8467\n",
      "Epoch 127/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.3874 - accuracy: 0.8981 - val_loss: 0.5807 - val_accuracy: 0.8451\n",
      "Epoch 128/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.3853 - accuracy: 0.8978 - val_loss: 0.5765 - val_accuracy: 0.8433\n",
      "Epoch 129/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.3825 - accuracy: 0.8995 - val_loss: 0.5726 - val_accuracy: 0.8468\n",
      "Epoch 130/400\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.3792 - accuracy: 0.9010 - val_loss: 0.5759 - val_accuracy: 0.8473\n",
      "Epoch 131/400\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.3823 - accuracy: 0.8979 - val_loss: 0.5793 - val_accuracy: 0.8411\n",
      "Epoch 132/400\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.3802 - accuracy: 0.8987 - val_loss: 0.5758 - val_accuracy: 0.8396\n",
      "Epoch 133/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.3778 - accuracy: 0.8997 - val_loss: 0.5641 - val_accuracy: 0.8496\n",
      "Epoch 134/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.3731 - accuracy: 0.9010 - val_loss: 0.5592 - val_accuracy: 0.8497\n",
      "Epoch 135/400\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.3670 - accuracy: 0.9036 - val_loss: 0.5609 - val_accuracy: 0.8478\n",
      "Epoch 136/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.3660 - accuracy: 0.9043 - val_loss: 0.5621 - val_accuracy: 0.8489\n",
      "Epoch 137/400\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.3653 - accuracy: 0.9041 - val_loss: 0.5539 - val_accuracy: 0.8492\n",
      "Epoch 138/400\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.3583 - accuracy: 0.9075 - val_loss: 0.5527 - val_accuracy: 0.8508\n",
      "Epoch 139/400\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.3572 - accuracy: 0.9070 - val_loss: 0.5547 - val_accuracy: 0.8487\n",
      "Epoch 140/400\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.3558 - accuracy: 0.9074 - val_loss: 0.5547 - val_accuracy: 0.8481\n",
      "Epoch 141/400\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.3555 - accuracy: 0.9071 - val_loss: 0.5479 - val_accuracy: 0.8511\n",
      "Epoch 142/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.3530 - accuracy: 0.9072 - val_loss: 0.5451 - val_accuracy: 0.8523\n",
      "Epoch 143/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.3490 - accuracy: 0.9104 - val_loss: 0.5487 - val_accuracy: 0.8498\n",
      "Epoch 144/400\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.3493 - accuracy: 0.9098 - val_loss: 0.5484 - val_accuracy: 0.8501\n",
      "Epoch 145/400\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.3479 - accuracy: 0.9098 - val_loss: 0.5443 - val_accuracy: 0.8513\n",
      "Epoch 146/400\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.3445 - accuracy: 0.9092 - val_loss: 0.5446 - val_accuracy: 0.8510\n",
      "Epoch 147/400\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.3430 - accuracy: 0.9103 - val_loss: 0.5412 - val_accuracy: 0.8528\n",
      "Epoch 148/400\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.3389 - accuracy: 0.9128 - val_loss: 0.5377 - val_accuracy: 0.8508\n",
      "Epoch 149/400\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.3396 - accuracy: 0.9126 - val_loss: 0.5520 - val_accuracy: 0.8458\n",
      "Epoch 150/400\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.3429 - accuracy: 0.9092 - val_loss: 0.5428 - val_accuracy: 0.8514\n",
      "Epoch 151/400\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3375 - accuracy: 0.9118 - val_loss: 0.5372 - val_accuracy: 0.8523\n",
      "Epoch 152/400\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.3341 - accuracy: 0.9126 - val_loss: 0.5335 - val_accuracy: 0.8526\n",
      "Epoch 153/400\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.3319 - accuracy: 0.9140 - val_loss: 0.5379 - val_accuracy: 0.8532\n",
      "Epoch 154/400\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.3305 - accuracy: 0.9140 - val_loss: 0.5419 - val_accuracy: 0.8497\n",
      "Epoch 155/400\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.3321 - accuracy: 0.9128 - val_loss: 0.5388 - val_accuracy: 0.8499\n",
      "Epoch 156/400\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.3321 - accuracy: 0.9121 - val_loss: 0.5475 - val_accuracy: 0.8471\n",
      "Epoch 157/400\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.3329 - accuracy: 0.9121 - val_loss: 0.5549 - val_accuracy: 0.8462\n",
      "Epoch 00157: early stopping\n",
      "\n",
      "Test loss: 0.555\n",
      "Test accuracy: 0.846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa20012a0f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 20000\n",
    "epochs = 400   # Setting up higher epoch in persuit of finding global moinima,\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)   # Set up early stopping to avoid wastage of computing power\n",
    "                                                                            # Kept patience level to 5 to check for considerable time to get out of local minima if possible\n",
    "    \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [es],\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DBVAprdD1R15"
   },
   "source": [
    "Observations\n",
    "1. The BatchNormalization performs much better compared without normalization.\n",
    "2. The loss functions is pretty step as compared to without normalization. \n",
    "3. The accuracy reaches to highest level pity soon.\n",
    "\n",
    "The batch normalization is much better with accuracy close to 85%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f-HH1TjqAniu"
   },
   "source": [
    "## Try different batch size options to get the optimal batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uCYui2GABSLd"
   },
   "source": [
    "Take the full data as batch size with higher epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "D3KAGxvjybVP",
    "outputId": "19f3f44c-8091-4e81-a770-5fa426565517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_2 (None, 1024) ==> (None, 1024)\n",
      "dense_12 (None, 1024) ==> (None, 1024)\n",
      "dense_13 (None, 1024) ==> (None, 10)\n",
      "\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,063,946\n",
      "Trainable params: 1,061,898\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(1024,))) # Set the batch normalization with input shape 32 x 32\n",
    "model.add(Dense(1024, activation='relu', input_shape=(1024,)))   #First hidden layer of 1024  neurons, each neuron takes input \n",
    "                                                               # vector of size 1024\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))            # Adding a softmax layer for output which contains as many \n",
    "                                                               # neurons as the number of classes (10) which is also the \n",
    "                                                               # the shape of each output vector ( one hot coded)\n",
    "\n",
    "                                                               # output layer also uses softmax. This normalizes the values \n",
    "                                                               # from the ten output nodes such that: \n",
    "                                                               #        all the values are between 0 and 1, and\n",
    "                                                               #        the sum of all ten values is 1.  \n",
    "                                                               # prediction is the lable of the node that gets highest fraction, is \n",
    "        \n",
    "        \n",
    "\n",
    "for l in model.layers:\n",
    "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
    "print()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8K2wLAgIzE0D",
    "outputId": "cd25fe06-ce23-47b2-9ac1-893d18c510da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 2.7888 - accuracy: 0.1055 - val_loss: 3.4234 - val_accuracy: 0.1004\n",
      "Epoch 2/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.6994 - accuracy: 0.1286 - val_loss: 3.5508 - val_accuracy: 0.1084\n",
      "Epoch 3/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 4.0634 - accuracy: 0.1544 - val_loss: 3.2868 - val_accuracy: 0.1001\n",
      "Epoch 4/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.6634 - accuracy: 0.1746 - val_loss: 3.0254 - val_accuracy: 0.0955\n",
      "Epoch 5/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.2861 - accuracy: 0.1910 - val_loss: 2.3583 - val_accuracy: 0.1397\n",
      "Epoch 6/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 2.6776 - accuracy: 0.2312 - val_loss: 2.5116 - val_accuracy: 0.1088\n",
      "Epoch 7/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 2.3323 - accuracy: 0.2580 - val_loss: 2.5289 - val_accuracy: 0.1469\n",
      "Epoch 8/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 2.4370 - accuracy: 0.2808 - val_loss: 2.4568 - val_accuracy: 0.1655\n",
      "Epoch 9/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 2.2551 - accuracy: 0.3331 - val_loss: 2.3242 - val_accuracy: 0.1234\n",
      "Epoch 10/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 2.0174 - accuracy: 0.3508 - val_loss: 2.3349 - val_accuracy: 0.1011\n",
      "Epoch 11/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.9890 - accuracy: 0.3450 - val_loss: 2.2452 - val_accuracy: 0.2249\n",
      "Epoch 12/400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.8705 - accuracy: 0.3888 - val_loss: 2.2282 - val_accuracy: 0.2594\n",
      "Epoch 13/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.7796 - accuracy: 0.4401 - val_loss: 2.2064 - val_accuracy: 0.2302\n",
      "Epoch 14/400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.7774 - accuracy: 0.4437 - val_loss: 2.1688 - val_accuracy: 0.3054\n",
      "Epoch 15/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.6553 - accuracy: 0.5024 - val_loss: 2.1589 - val_accuracy: 0.2880\n",
      "Epoch 16/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.5979 - accuracy: 0.5074 - val_loss: 2.1212 - val_accuracy: 0.3474\n",
      "Epoch 17/400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.5863 - accuracy: 0.4823 - val_loss: 2.0928 - val_accuracy: 0.4054\n",
      "Epoch 18/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.4861 - accuracy: 0.5535 - val_loss: 2.0711 - val_accuracy: 0.4258\n",
      "Epoch 19/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.4668 - accuracy: 0.5735 - val_loss: 2.0482 - val_accuracy: 0.4398\n",
      "Epoch 20/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.4310 - accuracy: 0.5840 - val_loss: 2.0239 - val_accuracy: 0.4706\n",
      "Epoch 21/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.3740 - accuracy: 0.6021 - val_loss: 2.0034 - val_accuracy: 0.4897\n",
      "Epoch 22/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.3505 - accuracy: 0.6060 - val_loss: 1.9754 - val_accuracy: 0.5287\n",
      "Epoch 23/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.3124 - accuracy: 0.6242 - val_loss: 1.9504 - val_accuracy: 0.5466\n",
      "Epoch 24/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.2812 - accuracy: 0.6325 - val_loss: 1.9283 - val_accuracy: 0.5691\n",
      "Epoch 25/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.2557 - accuracy: 0.6448 - val_loss: 1.9067 - val_accuracy: 0.5802\n",
      "Epoch 26/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.2282 - accuracy: 0.6550 - val_loss: 1.8864 - val_accuracy: 0.6027\n",
      "Epoch 27/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.2044 - accuracy: 0.6609 - val_loss: 1.8650 - val_accuracy: 0.6153\n",
      "Epoch 28/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1805 - accuracy: 0.6732 - val_loss: 1.8425 - val_accuracy: 0.6295\n",
      "Epoch 29/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1646 - accuracy: 0.6771 - val_loss: 1.8305 - val_accuracy: 0.6144\n",
      "Epoch 30/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1439 - accuracy: 0.6847 - val_loss: 1.8158 - val_accuracy: 0.6311\n",
      "Epoch 31/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1249 - accuracy: 0.6895 - val_loss: 1.7901 - val_accuracy: 0.6421\n",
      "Epoch 32/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1067 - accuracy: 0.6959 - val_loss: 1.7720 - val_accuracy: 0.6430\n",
      "Epoch 33/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.0950 - accuracy: 0.6945 - val_loss: 1.7563 - val_accuracy: 0.6626\n",
      "Epoch 34/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.0751 - accuracy: 0.7032 - val_loss: 1.7387 - val_accuracy: 0.6671\n",
      "Epoch 35/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.0572 - accuracy: 0.7096 - val_loss: 1.7275 - val_accuracy: 0.6500\n",
      "Epoch 36/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0482 - accuracy: 0.7119 - val_loss: 1.7080 - val_accuracy: 0.6708\n",
      "Epoch 37/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0297 - accuracy: 0.7191 - val_loss: 1.6910 - val_accuracy: 0.6706\n",
      "Epoch 38/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0219 - accuracy: 0.7187 - val_loss: 1.6744 - val_accuracy: 0.6700\n",
      "Epoch 39/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0072 - accuracy: 0.7225 - val_loss: 1.6584 - val_accuracy: 0.6862\n",
      "Epoch 40/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.9933 - accuracy: 0.7296 - val_loss: 1.6459 - val_accuracy: 0.6871\n",
      "Epoch 41/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.9844 - accuracy: 0.7282 - val_loss: 1.6338 - val_accuracy: 0.6894\n",
      "Epoch 42/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.9731 - accuracy: 0.7331 - val_loss: 1.6142 - val_accuracy: 0.6994\n",
      "Epoch 43/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.9608 - accuracy: 0.7359 - val_loss: 1.5988 - val_accuracy: 0.6976\n",
      "Epoch 44/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.9506 - accuracy: 0.7388 - val_loss: 1.5892 - val_accuracy: 0.6949\n",
      "Epoch 45/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.9418 - accuracy: 0.7389 - val_loss: 1.5741 - val_accuracy: 0.7038\n",
      "Epoch 46/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.9331 - accuracy: 0.7406 - val_loss: 1.5582 - val_accuracy: 0.7097\n",
      "Epoch 47/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.9201 - accuracy: 0.7469 - val_loss: 1.5473 - val_accuracy: 0.7077\n",
      "Epoch 48/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.9121 - accuracy: 0.7494 - val_loss: 1.5328 - val_accuracy: 0.7156\n",
      "Epoch 49/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.9034 - accuracy: 0.7517 - val_loss: 1.5211 - val_accuracy: 0.7156\n",
      "Epoch 50/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.8952 - accuracy: 0.7541 - val_loss: 1.5062 - val_accuracy: 0.7181\n",
      "Epoch 51/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.8893 - accuracy: 0.7548 - val_loss: 1.4884 - val_accuracy: 0.7281\n",
      "Epoch 52/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.8778 - accuracy: 0.7587 - val_loss: 1.4801 - val_accuracy: 0.7223\n",
      "Epoch 53/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.8727 - accuracy: 0.7571 - val_loss: 1.4700 - val_accuracy: 0.7210\n",
      "Epoch 54/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.8656 - accuracy: 0.7600 - val_loss: 1.4548 - val_accuracy: 0.7235\n",
      "Epoch 55/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8613 - accuracy: 0.7612 - val_loss: 1.4423 - val_accuracy: 0.7317\n",
      "Epoch 56/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8465 - accuracy: 0.7682 - val_loss: 1.4316 - val_accuracy: 0.7290\n",
      "Epoch 57/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.8401 - accuracy: 0.7696 - val_loss: 1.4185 - val_accuracy: 0.7320\n",
      "Epoch 58/400\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.8359 - accuracy: 0.7674 - val_loss: 1.4055 - val_accuracy: 0.7366\n",
      "Epoch 59/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.8268 - accuracy: 0.7709 - val_loss: 1.3952 - val_accuracy: 0.7354\n",
      "Epoch 60/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.8222 - accuracy: 0.7737 - val_loss: 1.3820 - val_accuracy: 0.7418\n",
      "Epoch 61/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.8120 - accuracy: 0.7773 - val_loss: 1.3707 - val_accuracy: 0.7438\n",
      "Epoch 62/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.8057 - accuracy: 0.7782 - val_loss: 1.3566 - val_accuracy: 0.7481\n",
      "Epoch 63/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7985 - accuracy: 0.7802 - val_loss: 1.3464 - val_accuracy: 0.7491\n",
      "Epoch 64/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7927 - accuracy: 0.7810 - val_loss: 1.3360 - val_accuracy: 0.7506\n",
      "Epoch 65/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.7873 - accuracy: 0.7826 - val_loss: 1.3213 - val_accuracy: 0.7537\n",
      "Epoch 66/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7799 - accuracy: 0.7875 - val_loss: 1.3114 - val_accuracy: 0.7566\n",
      "Epoch 67/400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7741 - accuracy: 0.7889 - val_loss: 1.2996 - val_accuracy: 0.7581\n",
      "Epoch 68/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7681 - accuracy: 0.7901 - val_loss: 1.2916 - val_accuracy: 0.7566\n",
      "Epoch 69/400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7652 - accuracy: 0.7888 - val_loss: 1.2813 - val_accuracy: 0.7558\n",
      "Epoch 70/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7574 - accuracy: 0.7936 - val_loss: 1.2655 - val_accuracy: 0.7605\n",
      "Epoch 71/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7529 - accuracy: 0.7952 - val_loss: 1.2602 - val_accuracy: 0.7588\n",
      "Epoch 72/400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7472 - accuracy: 0.7950 - val_loss: 1.2459 - val_accuracy: 0.7625\n",
      "Epoch 73/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7393 - accuracy: 0.7975 - val_loss: 1.2334 - val_accuracy: 0.7638\n",
      "Epoch 74/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7389 - accuracy: 0.7970 - val_loss: 1.2266 - val_accuracy: 0.7643\n",
      "Epoch 75/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.7324 - accuracy: 0.7988 - val_loss: 1.2162 - val_accuracy: 0.7653\n",
      "Epoch 76/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.7299 - accuracy: 0.7983 - val_loss: 1.2048 - val_accuracy: 0.7678\n",
      "Epoch 77/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7208 - accuracy: 0.8032 - val_loss: 1.1942 - val_accuracy: 0.7709\n",
      "Epoch 78/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7153 - accuracy: 0.8036 - val_loss: 1.1840 - val_accuracy: 0.7664\n",
      "Epoch 79/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.7149 - accuracy: 0.8026 - val_loss: 1.1772 - val_accuracy: 0.7664\n",
      "Epoch 80/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7079 - accuracy: 0.8044 - val_loss: 1.1663 - val_accuracy: 0.7736\n",
      "Epoch 81/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7028 - accuracy: 0.8067 - val_loss: 1.1538 - val_accuracy: 0.7725\n",
      "Epoch 82/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6996 - accuracy: 0.8064 - val_loss: 1.1460 - val_accuracy: 0.7751\n",
      "Epoch 83/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6921 - accuracy: 0.8094 - val_loss: 1.1354 - val_accuracy: 0.7766\n",
      "Epoch 84/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6939 - accuracy: 0.8096 - val_loss: 1.1251 - val_accuracy: 0.7787\n",
      "Epoch 85/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6832 - accuracy: 0.8135 - val_loss: 1.1195 - val_accuracy: 0.7758\n",
      "Epoch 86/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6776 - accuracy: 0.8150 - val_loss: 1.1074 - val_accuracy: 0.7787\n",
      "Epoch 87/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6781 - accuracy: 0.8138 - val_loss: 1.1002 - val_accuracy: 0.7768\n",
      "Epoch 88/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6756 - accuracy: 0.8131 - val_loss: 1.0923 - val_accuracy: 0.7777\n",
      "Epoch 89/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6710 - accuracy: 0.8140 - val_loss: 1.0822 - val_accuracy: 0.7779\n",
      "Epoch 90/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6696 - accuracy: 0.8138 - val_loss: 1.0717 - val_accuracy: 0.7820\n",
      "Epoch 91/400\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6628 - accuracy: 0.8176 - val_loss: 1.0651 - val_accuracy: 0.7819\n",
      "Epoch 92/400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6575 - accuracy: 0.8184 - val_loss: 1.0530 - val_accuracy: 0.7843\n",
      "Epoch 93/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6507 - accuracy: 0.8213 - val_loss: 1.0570 - val_accuracy: 0.7715\n",
      "Epoch 94/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6667 - accuracy: 0.8117 - val_loss: 1.0384 - val_accuracy: 0.7846\n",
      "Epoch 95/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6470 - accuracy: 0.8224 - val_loss: 1.0340 - val_accuracy: 0.7843\n",
      "Epoch 96/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6480 - accuracy: 0.8199 - val_loss: 1.0223 - val_accuracy: 0.7867\n",
      "Epoch 97/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6391 - accuracy: 0.8239 - val_loss: 1.0093 - val_accuracy: 0.7885\n",
      "Epoch 98/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6358 - accuracy: 0.8250 - val_loss: 1.0061 - val_accuracy: 0.7904\n",
      "Epoch 99/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6295 - accuracy: 0.8275 - val_loss: 0.9926 - val_accuracy: 0.7952\n",
      "Epoch 100/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6214 - accuracy: 0.8314 - val_loss: 0.9866 - val_accuracy: 0.7933\n",
      "Epoch 101/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6190 - accuracy: 0.8311 - val_loss: 0.9774 - val_accuracy: 0.7958\n",
      "Epoch 102/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6143 - accuracy: 0.8343 - val_loss: 0.9696 - val_accuracy: 0.7966\n",
      "Epoch 103/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6149 - accuracy: 0.8335 - val_loss: 0.9629 - val_accuracy: 0.7976\n",
      "Epoch 104/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6071 - accuracy: 0.8357 - val_loss: 0.9548 - val_accuracy: 0.7986\n",
      "Epoch 105/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6026 - accuracy: 0.8375 - val_loss: 0.9511 - val_accuracy: 0.7966\n",
      "Epoch 106/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6044 - accuracy: 0.8343 - val_loss: 0.9412 - val_accuracy: 0.7995\n",
      "Epoch 107/400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6001 - accuracy: 0.8355 - val_loss: 0.9327 - val_accuracy: 0.8015\n",
      "Epoch 108/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5971 - accuracy: 0.8373 - val_loss: 0.9243 - val_accuracy: 0.8014\n",
      "Epoch 109/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5911 - accuracy: 0.8386 - val_loss: 0.9181 - val_accuracy: 0.8032\n",
      "Epoch 110/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5859 - accuracy: 0.8415 - val_loss: 0.9099 - val_accuracy: 0.8033\n",
      "Epoch 111/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5850 - accuracy: 0.8415 - val_loss: 0.9060 - val_accuracy: 0.8016\n",
      "Epoch 112/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5850 - accuracy: 0.8400 - val_loss: 0.8980 - val_accuracy: 0.8062\n",
      "Epoch 113/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5775 - accuracy: 0.8444 - val_loss: 0.8908 - val_accuracy: 0.8081\n",
      "Epoch 114/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5730 - accuracy: 0.8463 - val_loss: 0.8873 - val_accuracy: 0.8052\n",
      "Epoch 115/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5726 - accuracy: 0.8451 - val_loss: 0.8779 - val_accuracy: 0.8081\n",
      "Epoch 116/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5715 - accuracy: 0.8430 - val_loss: 0.8764 - val_accuracy: 0.8022\n",
      "Epoch 117/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5737 - accuracy: 0.8432 - val_loss: 0.8674 - val_accuracy: 0.8072\n",
      "Epoch 118/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5636 - accuracy: 0.8472 - val_loss: 0.8610 - val_accuracy: 0.8088\n",
      "Epoch 119/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5603 - accuracy: 0.8479 - val_loss: 0.8538 - val_accuracy: 0.8081\n",
      "Epoch 120/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5588 - accuracy: 0.8489 - val_loss: 0.8488 - val_accuracy: 0.8078\n",
      "Epoch 121/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5550 - accuracy: 0.8491 - val_loss: 0.8409 - val_accuracy: 0.8103\n",
      "Epoch 122/400\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5516 - accuracy: 0.8495 - val_loss: 0.8379 - val_accuracy: 0.8058\n",
      "Epoch 123/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5542 - accuracy: 0.8487 - val_loss: 0.8316 - val_accuracy: 0.8118\n",
      "Epoch 124/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5480 - accuracy: 0.8518 - val_loss: 0.8222 - val_accuracy: 0.8126\n",
      "Epoch 125/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5472 - accuracy: 0.8505 - val_loss: 0.8202 - val_accuracy: 0.8073\n",
      "Epoch 126/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5491 - accuracy: 0.8492 - val_loss: 0.8114 - val_accuracy: 0.8129\n",
      "Epoch 127/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5391 - accuracy: 0.8533 - val_loss: 0.8027 - val_accuracy: 0.8151\n",
      "Epoch 128/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5347 - accuracy: 0.8561 - val_loss: 0.7967 - val_accuracy: 0.8161\n",
      "Epoch 129/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5284 - accuracy: 0.8595 - val_loss: 0.7941 - val_accuracy: 0.8166\n",
      "Epoch 130/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5285 - accuracy: 0.8588 - val_loss: 0.7864 - val_accuracy: 0.8159\n",
      "Epoch 131/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5264 - accuracy: 0.8589 - val_loss: 0.7832 - val_accuracy: 0.8159\n",
      "Epoch 132/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5248 - accuracy: 0.8577 - val_loss: 0.7778 - val_accuracy: 0.8151\n",
      "Epoch 133/400\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5217 - accuracy: 0.8597 - val_loss: 0.7719 - val_accuracy: 0.8188\n",
      "Epoch 134/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5202 - accuracy: 0.8594 - val_loss: 0.7689 - val_accuracy: 0.8192\n",
      "Epoch 135/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5155 - accuracy: 0.8620 - val_loss: 0.7613 - val_accuracy: 0.8210\n",
      "Epoch 136/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5119 - accuracy: 0.8636 - val_loss: 0.7605 - val_accuracy: 0.8196\n",
      "Epoch 137/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5119 - accuracy: 0.8631 - val_loss: 0.7521 - val_accuracy: 0.8240\n",
      "Epoch 138/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5071 - accuracy: 0.8664 - val_loss: 0.7503 - val_accuracy: 0.8215\n",
      "Epoch 139/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5052 - accuracy: 0.8648 - val_loss: 0.7480 - val_accuracy: 0.8211\n",
      "Epoch 140/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5061 - accuracy: 0.8644 - val_loss: 0.7410 - val_accuracy: 0.8231\n",
      "Epoch 141/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5013 - accuracy: 0.8647 - val_loss: 0.7395 - val_accuracy: 0.8208\n",
      "Epoch 142/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5022 - accuracy: 0.8647 - val_loss: 0.7310 - val_accuracy: 0.8242\n",
      "Epoch 143/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4978 - accuracy: 0.8659 - val_loss: 0.7305 - val_accuracy: 0.8207\n",
      "Epoch 144/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4978 - accuracy: 0.8653 - val_loss: 0.7282 - val_accuracy: 0.8205\n",
      "Epoch 145/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5037 - accuracy: 0.8604 - val_loss: 0.7326 - val_accuracy: 0.8136\n",
      "Epoch 146/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5068 - accuracy: 0.8585 - val_loss: 0.7214 - val_accuracy: 0.8209\n",
      "Epoch 147/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5025 - accuracy: 0.8611 - val_loss: 0.7228 - val_accuracy: 0.8156\n",
      "Epoch 148/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5015 - accuracy: 0.8610 - val_loss: 0.7071 - val_accuracy: 0.8242\n",
      "Epoch 149/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4906 - accuracy: 0.8648 - val_loss: 0.7004 - val_accuracy: 0.8274\n",
      "Epoch 150/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4784 - accuracy: 0.8722 - val_loss: 0.7023 - val_accuracy: 0.8231\n",
      "Epoch 151/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4826 - accuracy: 0.8689 - val_loss: 0.6987 - val_accuracy: 0.8233\n",
      "Epoch 152/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4834 - accuracy: 0.8679 - val_loss: 0.7023 - val_accuracy: 0.8218\n",
      "Epoch 153/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4874 - accuracy: 0.8674 - val_loss: 0.6887 - val_accuracy: 0.8263\n",
      "Epoch 154/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4783 - accuracy: 0.8725 - val_loss: 0.6895 - val_accuracy: 0.8267\n",
      "Epoch 155/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4766 - accuracy: 0.8719 - val_loss: 0.6815 - val_accuracy: 0.8279\n",
      "Epoch 156/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4734 - accuracy: 0.8730 - val_loss: 0.6810 - val_accuracy: 0.8281\n",
      "Epoch 157/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4714 - accuracy: 0.8731 - val_loss: 0.6760 - val_accuracy: 0.8299\n",
      "Epoch 158/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4663 - accuracy: 0.8756 - val_loss: 0.6721 - val_accuracy: 0.8296\n",
      "Epoch 159/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4624 - accuracy: 0.8761 - val_loss: 0.6676 - val_accuracy: 0.8310\n",
      "Epoch 160/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4604 - accuracy: 0.8780 - val_loss: 0.6637 - val_accuracy: 0.8312\n",
      "Epoch 161/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4579 - accuracy: 0.8788 - val_loss: 0.6587 - val_accuracy: 0.8341\n",
      "Epoch 162/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4537 - accuracy: 0.8813 - val_loss: 0.6616 - val_accuracy: 0.8297\n",
      "Epoch 163/400\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4599 - accuracy: 0.8756 - val_loss: 0.6591 - val_accuracy: 0.8329\n",
      "Epoch 164/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4573 - accuracy: 0.8778 - val_loss: 0.6575 - val_accuracy: 0.8295\n",
      "Epoch 165/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4616 - accuracy: 0.8736 - val_loss: 0.6580 - val_accuracy: 0.8309\n",
      "Epoch 166/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4583 - accuracy: 0.8752 - val_loss: 0.6483 - val_accuracy: 0.8335\n",
      "Epoch 167/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4498 - accuracy: 0.8797 - val_loss: 0.6445 - val_accuracy: 0.8341\n",
      "Epoch 168/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4467 - accuracy: 0.8808 - val_loss: 0.6442 - val_accuracy: 0.8321\n",
      "Epoch 169/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4469 - accuracy: 0.8805 - val_loss: 0.6416 - val_accuracy: 0.8314\n",
      "Epoch 170/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4445 - accuracy: 0.8797 - val_loss: 0.6386 - val_accuracy: 0.8329\n",
      "Epoch 171/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4440 - accuracy: 0.8802 - val_loss: 0.6338 - val_accuracy: 0.8362\n",
      "Epoch 172/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4365 - accuracy: 0.8853 - val_loss: 0.6306 - val_accuracy: 0.8369\n",
      "Epoch 173/400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4344 - accuracy: 0.8853 - val_loss: 0.6312 - val_accuracy: 0.8354\n",
      "Epoch 174/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4392 - accuracy: 0.8827 - val_loss: 0.6277 - val_accuracy: 0.8363\n",
      "Epoch 175/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4336 - accuracy: 0.8849 - val_loss: 0.6232 - val_accuracy: 0.8362\n",
      "Epoch 176/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4316 - accuracy: 0.8852 - val_loss: 0.6311 - val_accuracy: 0.8330\n",
      "Epoch 177/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4375 - accuracy: 0.8820 - val_loss: 0.6238 - val_accuracy: 0.8357\n",
      "Epoch 178/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4341 - accuracy: 0.8825 - val_loss: 0.6184 - val_accuracy: 0.8378\n",
      "Epoch 179/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4259 - accuracy: 0.8869 - val_loss: 0.6157 - val_accuracy: 0.8382\n",
      "Epoch 180/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4274 - accuracy: 0.8873 - val_loss: 0.6167 - val_accuracy: 0.8376\n",
      "Epoch 181/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4235 - accuracy: 0.8888 - val_loss: 0.6120 - val_accuracy: 0.8389\n",
      "Epoch 182/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4222 - accuracy: 0.8886 - val_loss: 0.6173 - val_accuracy: 0.8350\n",
      "Epoch 183/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4259 - accuracy: 0.8860 - val_loss: 0.6128 - val_accuracy: 0.8364\n",
      "Epoch 184/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4217 - accuracy: 0.8864 - val_loss: 0.6121 - val_accuracy: 0.8368\n",
      "Epoch 185/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4262 - accuracy: 0.8835 - val_loss: 0.6087 - val_accuracy: 0.8367\n",
      "Epoch 186/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4190 - accuracy: 0.8875 - val_loss: 0.6019 - val_accuracy: 0.8415\n",
      "Epoch 187/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4140 - accuracy: 0.8897 - val_loss: 0.6073 - val_accuracy: 0.8376\n",
      "Epoch 188/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4166 - accuracy: 0.8896 - val_loss: 0.6022 - val_accuracy: 0.8385\n",
      "Epoch 189/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4131 - accuracy: 0.8894 - val_loss: 0.6007 - val_accuracy: 0.8404\n",
      "Epoch 190/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4138 - accuracy: 0.8898 - val_loss: 0.6043 - val_accuracy: 0.8334\n",
      "Epoch 191/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4198 - accuracy: 0.8864 - val_loss: 0.5910 - val_accuracy: 0.8423\n",
      "Epoch 192/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4043 - accuracy: 0.8932 - val_loss: 0.5954 - val_accuracy: 0.8376\n",
      "Epoch 193/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4070 - accuracy: 0.8908 - val_loss: 0.5918 - val_accuracy: 0.8403\n",
      "Epoch 194/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4043 - accuracy: 0.8923 - val_loss: 0.5887 - val_accuracy: 0.8411\n",
      "Epoch 195/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4025 - accuracy: 0.8937 - val_loss: 0.5897 - val_accuracy: 0.8411\n",
      "Epoch 196/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4000 - accuracy: 0.8940 - val_loss: 0.5897 - val_accuracy: 0.8407\n",
      "Epoch 197/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4017 - accuracy: 0.8932 - val_loss: 0.5887 - val_accuracy: 0.8387\n",
      "Epoch 198/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.3982 - accuracy: 0.8951 - val_loss: 0.5897 - val_accuracy: 0.8402\n",
      "Epoch 199/400\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4008 - accuracy: 0.8926 - val_loss: 0.5904 - val_accuracy: 0.8392\n",
      "Epoch 200/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4005 - accuracy: 0.8930 - val_loss: 0.5798 - val_accuracy: 0.8436\n",
      "Epoch 201/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3918 - accuracy: 0.8970 - val_loss: 0.5800 - val_accuracy: 0.8429\n",
      "Epoch 202/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3914 - accuracy: 0.8956 - val_loss: 0.5857 - val_accuracy: 0.8385\n",
      "Epoch 203/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3974 - accuracy: 0.8929 - val_loss: 0.5794 - val_accuracy: 0.8407\n",
      "Epoch 204/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.3937 - accuracy: 0.8958 - val_loss: 0.5785 - val_accuracy: 0.8408\n",
      "Epoch 205/400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3903 - accuracy: 0.8961 - val_loss: 0.5811 - val_accuracy: 0.8401\n",
      "Epoch 206/400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3962 - accuracy: 0.8921 - val_loss: 0.5763 - val_accuracy: 0.8429\n",
      "Epoch 207/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.3913 - accuracy: 0.8959 - val_loss: 0.5814 - val_accuracy: 0.8386\n",
      "Epoch 208/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3922 - accuracy: 0.8932 - val_loss: 0.5838 - val_accuracy: 0.8378\n",
      "Epoch 209/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3981 - accuracy: 0.8920 - val_loss: 0.5809 - val_accuracy: 0.8387\n",
      "Epoch 210/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.3894 - accuracy: 0.8946 - val_loss: 0.5865 - val_accuracy: 0.8366\n",
      "Epoch 211/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.3989 - accuracy: 0.8912 - val_loss: 0.5835 - val_accuracy: 0.8372\n",
      "Epoch 00211: early stopping\n",
      "\n",
      "Test loss: 0.583\n",
      "Test accuracy: 0.837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa1fa4bb128>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 40000\n",
    "epochs = 400   # Setting up higher epoch in persuit of finding global moinima,\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)   # Set up early stopping to avoid wastage of computing power\n",
    "                                                                            # Kept patience level to 5 to check for considerable time to get out of local minima if possible\n",
    "    \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [es],\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vE3IOD9GBrzd"
   },
   "source": [
    "Observation:\n",
    "\n",
    "Taking the full batch size took higher number of epochs to stabilize the model as compared to half size of 20000. Also the accuracy is lower.\n",
    "\n",
    "Going for other batch size options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "da4Z_kv-C9G3"
   },
   "source": [
    "### Batch size as 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "qYZHRQsdzf7H",
    "outputId": "af114a06-0794-40d0-bd39-d7c1b6d37c50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_3 (None, 1024) ==> (None, 1024)\n",
      "dense_14 (None, 1024) ==> (None, 1024)\n",
      "dense_15 (None, 1024) ==> (None, 10)\n",
      "\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,063,946\n",
      "Trainable params: 1,061,898\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(1024,))) # Set the batch normalization with input shape 32 x 32\n",
    "model.add(Dense(1024, activation='relu', input_shape=(1024,)))   #First hidden layer of 1024  neurons, each neuron takes input \n",
    "                                                               # vector of size 1024\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))            # Adding a softmax layer for output which contains as many \n",
    "                                                               # neurons as the number of classes (10) which is also the \n",
    "                                                               # the shape of each output vector ( one hot coded)\n",
    "\n",
    "                                                               # output layer also uses softmax. This normalizes the values \n",
    "                                                               # from the ten output nodes such that: \n",
    "                                                               #        all the values are between 0 and 1, and\n",
    "                                                               #        the sum of all ten values is 1.  \n",
    "                                                               # prediction is the lable of the node that gets highest fraction, is \n",
    "        \n",
    "        \n",
    "\n",
    "for l in model.layers:\n",
    "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
    "print()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "oLMORVD60BNk",
    "outputId": "06d12201-0893-4ef8-e58c-6abbf7ba3d9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 3.9757 - accuracy: 0.1120 - val_loss: 3.0747 - val_accuracy: 0.1042\n",
      "Epoch 2/400\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 3.6893 - accuracy: 0.1559 - val_loss: 2.6374 - val_accuracy: 0.1006\n",
      "Epoch 3/400\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 2.6091 - accuracy: 0.2264 - val_loss: 2.7735 - val_accuracy: 0.1154\n",
      "Epoch 4/400\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 2.2544 - accuracy: 0.3204 - val_loss: 2.2979 - val_accuracy: 0.1116\n",
      "Epoch 5/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 2.0203 - accuracy: 0.3660 - val_loss: 2.3205 - val_accuracy: 0.2092\n",
      "Epoch 6/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.8065 - accuracy: 0.4355 - val_loss: 2.1586 - val_accuracy: 0.3288\n",
      "Epoch 7/400\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.6418 - accuracy: 0.4941 - val_loss: 2.1305 - val_accuracy: 0.3497\n",
      "Epoch 8/400\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.5300 - accuracy: 0.5466 - val_loss: 2.0597 - val_accuracy: 0.4407\n",
      "Epoch 9/400\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.4141 - accuracy: 0.5940 - val_loss: 2.0046 - val_accuracy: 0.5286\n",
      "Epoch 10/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.3254 - accuracy: 0.6305 - val_loss: 1.9407 - val_accuracy: 0.5818\n",
      "Epoch 11/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.2501 - accuracy: 0.6581 - val_loss: 1.8901 - val_accuracy: 0.6129\n",
      "Epoch 12/400\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.1904 - accuracy: 0.6779 - val_loss: 1.8375 - val_accuracy: 0.6236\n",
      "Epoch 13/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.1401 - accuracy: 0.6921 - val_loss: 1.7952 - val_accuracy: 0.6403\n",
      "Epoch 14/400\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.0982 - accuracy: 0.7013 - val_loss: 1.7472 - val_accuracy: 0.6695\n",
      "Epoch 15/400\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.0577 - accuracy: 0.7131 - val_loss: 1.7069 - val_accuracy: 0.6784\n",
      "Epoch 16/400\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.0255 - accuracy: 0.7222 - val_loss: 1.6671 - val_accuracy: 0.6861\n",
      "Epoch 17/400\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.9936 - accuracy: 0.7299 - val_loss: 1.6296 - val_accuracy: 0.6901\n",
      "Epoch 18/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.9659 - accuracy: 0.7365 - val_loss: 1.5874 - val_accuracy: 0.7098\n",
      "Epoch 19/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.9399 - accuracy: 0.7437 - val_loss: 1.5510 - val_accuracy: 0.7182\n",
      "Epoch 20/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.9171 - accuracy: 0.7505 - val_loss: 1.5211 - val_accuracy: 0.7174\n",
      "Epoch 21/400\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.8955 - accuracy: 0.7549 - val_loss: 1.4870 - val_accuracy: 0.7288\n",
      "Epoch 22/400\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.8745 - accuracy: 0.7612 - val_loss: 1.4573 - val_accuracy: 0.7290\n",
      "Epoch 23/400\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.8561 - accuracy: 0.7661 - val_loss: 1.4270 - val_accuracy: 0.7365\n",
      "Epoch 24/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.8388 - accuracy: 0.7697 - val_loss: 1.3978 - val_accuracy: 0.7421\n",
      "Epoch 25/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.8212 - accuracy: 0.7756 - val_loss: 1.3662 - val_accuracy: 0.7456\n",
      "Epoch 26/400\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.8034 - accuracy: 0.7803 - val_loss: 1.3380 - val_accuracy: 0.7507\n",
      "Epoch 27/400\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.7882 - accuracy: 0.7850 - val_loss: 1.3077 - val_accuracy: 0.7565\n",
      "Epoch 28/400\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.7731 - accuracy: 0.7881 - val_loss: 1.2832 - val_accuracy: 0.7565\n",
      "Epoch 29/400\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.7591 - accuracy: 0.7922 - val_loss: 1.2582 - val_accuracy: 0.7568\n",
      "Epoch 30/400\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7455 - accuracy: 0.7948 - val_loss: 1.2284 - val_accuracy: 0.7632\n",
      "Epoch 31/400\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7322 - accuracy: 0.7999 - val_loss: 1.2005 - val_accuracy: 0.7713\n",
      "Epoch 32/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7180 - accuracy: 0.8057 - val_loss: 1.1747 - val_accuracy: 0.7773\n",
      "Epoch 33/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.7053 - accuracy: 0.8094 - val_loss: 1.1528 - val_accuracy: 0.7793\n",
      "Epoch 34/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6948 - accuracy: 0.8108 - val_loss: 1.1255 - val_accuracy: 0.7839\n",
      "Epoch 35/400\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6819 - accuracy: 0.8146 - val_loss: 1.1035 - val_accuracy: 0.7836\n",
      "Epoch 36/400\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6730 - accuracy: 0.8167 - val_loss: 1.0831 - val_accuracy: 0.7855\n",
      "Epoch 37/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6629 - accuracy: 0.8206 - val_loss: 1.0612 - val_accuracy: 0.7880\n",
      "Epoch 38/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6526 - accuracy: 0.8233 - val_loss: 1.0434 - val_accuracy: 0.7886\n",
      "Epoch 39/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6460 - accuracy: 0.8242 - val_loss: 1.0198 - val_accuracy: 0.7919\n",
      "Epoch 40/400\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6345 - accuracy: 0.8275 - val_loss: 0.9946 - val_accuracy: 0.7996\n",
      "Epoch 41/400\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6255 - accuracy: 0.8298 - val_loss: 0.9729 - val_accuracy: 0.7997\n",
      "Epoch 42/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6152 - accuracy: 0.8327 - val_loss: 0.9556 - val_accuracy: 0.7996\n",
      "Epoch 43/400\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6039 - accuracy: 0.8371 - val_loss: 0.9357 - val_accuracy: 0.8029\n",
      "Epoch 44/400\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5958 - accuracy: 0.8386 - val_loss: 0.9145 - val_accuracy: 0.8078\n",
      "Epoch 45/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5865 - accuracy: 0.8419 - val_loss: 0.8953 - val_accuracy: 0.8097\n",
      "Epoch 46/400\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5765 - accuracy: 0.8453 - val_loss: 0.8787 - val_accuracy: 0.8126\n",
      "Epoch 47/400\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5658 - accuracy: 0.8496 - val_loss: 0.8625 - val_accuracy: 0.8120\n",
      "Epoch 48/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5603 - accuracy: 0.8504 - val_loss: 0.8554 - val_accuracy: 0.8077\n",
      "Epoch 49/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5582 - accuracy: 0.8494 - val_loss: 0.8370 - val_accuracy: 0.8118\n",
      "Epoch 50/400\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5476 - accuracy: 0.8540 - val_loss: 0.8151 - val_accuracy: 0.8173\n",
      "Epoch 51/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5389 - accuracy: 0.8561 - val_loss: 0.8024 - val_accuracy: 0.8188\n",
      "Epoch 52/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5307 - accuracy: 0.8591 - val_loss: 0.7907 - val_accuracy: 0.8184\n",
      "Epoch 53/400\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5248 - accuracy: 0.8610 - val_loss: 0.7753 - val_accuracy: 0.8195\n",
      "Epoch 54/400\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5192 - accuracy: 0.8624 - val_loss: 0.7617 - val_accuracy: 0.8225\n",
      "Epoch 55/400\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.5124 - accuracy: 0.8638 - val_loss: 0.7524 - val_accuracy: 0.8248\n",
      "Epoch 56/400\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5063 - accuracy: 0.8657 - val_loss: 0.7394 - val_accuracy: 0.8259\n",
      "Epoch 57/400\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4976 - accuracy: 0.8685 - val_loss: 0.7261 - val_accuracy: 0.8273\n",
      "Epoch 58/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4930 - accuracy: 0.8695 - val_loss: 0.7169 - val_accuracy: 0.8272\n",
      "Epoch 59/400\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.4886 - accuracy: 0.8704 - val_loss: 0.7039 - val_accuracy: 0.8321\n",
      "Epoch 60/400\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.4837 - accuracy: 0.8708 - val_loss: 0.7039 - val_accuracy: 0.8237\n",
      "Epoch 61/400\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.4838 - accuracy: 0.8698 - val_loss: 0.6951 - val_accuracy: 0.8284\n",
      "Epoch 62/400\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.4779 - accuracy: 0.8722 - val_loss: 0.6756 - val_accuracy: 0.8349\n",
      "Epoch 63/400\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.4663 - accuracy: 0.8776 - val_loss: 0.6685 - val_accuracy: 0.8353\n",
      "Epoch 64/400\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.4630 - accuracy: 0.8772 - val_loss: 0.6652 - val_accuracy: 0.8321\n",
      "Epoch 65/400\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4627 - accuracy: 0.8746 - val_loss: 0.6565 - val_accuracy: 0.8330\n",
      "Epoch 66/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4541 - accuracy: 0.8795 - val_loss: 0.6514 - val_accuracy: 0.8326\n",
      "Epoch 67/400\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4489 - accuracy: 0.8808 - val_loss: 0.6399 - val_accuracy: 0.8365\n",
      "Epoch 68/400\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4464 - accuracy: 0.8811 - val_loss: 0.6344 - val_accuracy: 0.8375\n",
      "Epoch 69/400\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4419 - accuracy: 0.8818 - val_loss: 0.6294 - val_accuracy: 0.8369\n",
      "Epoch 70/400\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.4337 - accuracy: 0.8844 - val_loss: 0.6231 - val_accuracy: 0.8376\n",
      "Epoch 71/400\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.4280 - accuracy: 0.8870 - val_loss: 0.6111 - val_accuracy: 0.8402\n",
      "Epoch 72/400\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.4220 - accuracy: 0.8897 - val_loss: 0.6057 - val_accuracy: 0.8443\n",
      "Epoch 73/400\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.4178 - accuracy: 0.8901 - val_loss: 0.6020 - val_accuracy: 0.8433\n",
      "Epoch 74/400\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4144 - accuracy: 0.8906 - val_loss: 0.5959 - val_accuracy: 0.8441\n",
      "Epoch 75/400\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4085 - accuracy: 0.8940 - val_loss: 0.5907 - val_accuracy: 0.8449\n",
      "Epoch 76/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4032 - accuracy: 0.8950 - val_loss: 0.5926 - val_accuracy: 0.8426\n",
      "Epoch 77/400\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4004 - accuracy: 0.8945 - val_loss: 0.5835 - val_accuracy: 0.8458\n",
      "Epoch 78/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3975 - accuracy: 0.8953 - val_loss: 0.5774 - val_accuracy: 0.8456\n",
      "Epoch 79/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3935 - accuracy: 0.8957 - val_loss: 0.5778 - val_accuracy: 0.8448\n",
      "Epoch 80/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3927 - accuracy: 0.8969 - val_loss: 0.5771 - val_accuracy: 0.8441\n",
      "Epoch 81/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3895 - accuracy: 0.8967 - val_loss: 0.5652 - val_accuracy: 0.8479\n",
      "Epoch 82/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3819 - accuracy: 0.8992 - val_loss: 0.5639 - val_accuracy: 0.8478\n",
      "Epoch 83/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3801 - accuracy: 0.9012 - val_loss: 0.5604 - val_accuracy: 0.8484\n",
      "Epoch 84/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3760 - accuracy: 0.9023 - val_loss: 0.5618 - val_accuracy: 0.8474\n",
      "Epoch 85/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3740 - accuracy: 0.9021 - val_loss: 0.5577 - val_accuracy: 0.8479\n",
      "Epoch 86/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3673 - accuracy: 0.9053 - val_loss: 0.5581 - val_accuracy: 0.8459\n",
      "Epoch 87/400\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3659 - accuracy: 0.9056 - val_loss: 0.5527 - val_accuracy: 0.8494\n",
      "Epoch 88/400\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3619 - accuracy: 0.9064 - val_loss: 0.5465 - val_accuracy: 0.8497\n",
      "Epoch 89/400\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3597 - accuracy: 0.9064 - val_loss: 0.5539 - val_accuracy: 0.8481\n",
      "Epoch 90/400\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.3573 - accuracy: 0.9069 - val_loss: 0.5416 - val_accuracy: 0.8531\n",
      "Epoch 91/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3537 - accuracy: 0.9084 - val_loss: 0.5442 - val_accuracy: 0.8502\n",
      "Epoch 92/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3491 - accuracy: 0.9093 - val_loss: 0.5407 - val_accuracy: 0.8518\n",
      "Epoch 93/400\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3460 - accuracy: 0.9102 - val_loss: 0.5407 - val_accuracy: 0.8522\n",
      "Epoch 94/400\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.3444 - accuracy: 0.9106 - val_loss: 0.5364 - val_accuracy: 0.8522\n",
      "Epoch 95/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3410 - accuracy: 0.9118 - val_loss: 0.5349 - val_accuracy: 0.8515\n",
      "Epoch 96/400\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3399 - accuracy: 0.9110 - val_loss: 0.5368 - val_accuracy: 0.8536\n",
      "Epoch 97/400\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.3361 - accuracy: 0.9125 - val_loss: 0.5321 - val_accuracy: 0.8554\n",
      "Epoch 98/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3298 - accuracy: 0.9156 - val_loss: 0.5354 - val_accuracy: 0.8524\n",
      "Epoch 99/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3319 - accuracy: 0.9135 - val_loss: 0.5320 - val_accuracy: 0.8537\n",
      "Epoch 100/400\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3238 - accuracy: 0.9169 - val_loss: 0.5323 - val_accuracy: 0.8533\n",
      "Epoch 101/400\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3226 - accuracy: 0.9183 - val_loss: 0.5237 - val_accuracy: 0.8558\n",
      "Epoch 102/400\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.3207 - accuracy: 0.9173 - val_loss: 0.5223 - val_accuracy: 0.8572\n",
      "Epoch 103/400\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3197 - accuracy: 0.9180 - val_loss: 0.5265 - val_accuracy: 0.8552\n",
      "Epoch 104/400\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3169 - accuracy: 0.9187 - val_loss: 0.5222 - val_accuracy: 0.8568\n",
      "Epoch 105/400\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3115 - accuracy: 0.9213 - val_loss: 0.5197 - val_accuracy: 0.8569\n",
      "Epoch 106/400\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3090 - accuracy: 0.9209 - val_loss: 0.5278 - val_accuracy: 0.8545\n",
      "Epoch 107/400\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3071 - accuracy: 0.9209 - val_loss: 0.5256 - val_accuracy: 0.8541\n",
      "Epoch 108/400\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3049 - accuracy: 0.9231 - val_loss: 0.5215 - val_accuracy: 0.8548\n",
      "Epoch 109/400\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3027 - accuracy: 0.9229 - val_loss: 0.5213 - val_accuracy: 0.8564\n",
      "Epoch 110/400\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3032 - accuracy: 0.9209 - val_loss: 0.5259 - val_accuracy: 0.8552\n",
      "Epoch 00110: early stopping\n",
      "\n",
      "Test loss: 0.526\n",
      "Test accuracy: 0.855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa250328978>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "epochs = 400   # Setting up higher epoch in persuit of finding global moinima,\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)   # Set up early stopping to avoid wastage of computing power\n",
    "                                                                            # Kept patience level to 5 to check for considerable time to get out of local minima if possible\n",
    "    \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [es],\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nA96aA6oDdXZ"
   },
   "source": [
    "Observation:\n",
    "\n",
    "Performs better than 20000 batch size as it takes less number of epochs to converge and provides same (slightly higher accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0vL6e8RoGUFY"
   },
   "source": [
    "### Batch size 512 - though not optimal but still checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "Vn4Ud0Sb0sLv",
    "outputId": "ba5b3766-303b-4233-a9c1-bd3d2caa557b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_4 (None, 1024) ==> (None, 1024)\n",
      "dense_16 (None, 1024) ==> (None, 1024)\n",
      "dense_17 (None, 1024) ==> (None, 10)\n",
      "\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_4 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,063,946\n",
      "Trainable params: 1,061,898\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(1024,))) # Set the batch normalization with input shape 32 x 32\n",
    "model.add(Dense(1024, activation='relu', input_shape=(1024,)))   #First hidden layer of 1024  neurons, each neuron takes input \n",
    "                                                               # vector of size 1024\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))            # Adding a softmax layer for output which contains as many \n",
    "                                                               # neurons as the number of classes (10) which is also the \n",
    "                                                               # the shape of each output vector ( one hot coded)\n",
    "\n",
    "                                                               # output layer also uses softmax. This normalizes the values \n",
    "                                                               # from the ten output nodes such that: \n",
    "                                                               #        all the values are between 0 and 1, and\n",
    "                                                               #        the sum of all ten values is 1.  \n",
    "                                                               # prediction is the lable of the node that gets highest fraction, is \n",
    "        \n",
    "        \n",
    "\n",
    "for l in model.layers:\n",
    "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
    "print()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "colab_type": "code",
    "id": "OXWFsdQt0y-9",
    "outputId": "4853b90f-4eb5-4446-af2d-ea6f1ce4c5dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.7867 - accuracy: 0.4719 - val_loss: 1.6933 - val_accuracy: 0.5921\n",
      "Epoch 2/400\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.9795 - accuracy: 0.7056 - val_loss: 1.2630 - val_accuracy: 0.6897\n",
      "Epoch 3/400\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.8356 - accuracy: 0.7474 - val_loss: 0.9587 - val_accuracy: 0.7458\n",
      "Epoch 4/400\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.7381 - accuracy: 0.7807 - val_loss: 0.9380 - val_accuracy: 0.7362\n",
      "Epoch 5/400\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6586 - accuracy: 0.8068 - val_loss: 1.3214 - val_accuracy: 0.6606\n",
      "Epoch 6/400\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6731 - accuracy: 0.8065 - val_loss: 0.7163 - val_accuracy: 0.7906\n",
      "Epoch 7/400\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5754 - accuracy: 0.8301 - val_loss: 0.6937 - val_accuracy: 0.7983\n",
      "Epoch 8/400\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5302 - accuracy: 0.8416 - val_loss: 0.6626 - val_accuracy: 0.8111\n",
      "Epoch 9/400\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5344 - accuracy: 0.8389 - val_loss: 0.6720 - val_accuracy: 0.8109\n",
      "Epoch 10/400\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5412 - accuracy: 0.8397 - val_loss: 0.7285 - val_accuracy: 0.7990\n",
      "Epoch 11/400\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4931 - accuracy: 0.8551 - val_loss: 0.8609 - val_accuracy: 0.7831\n",
      "Epoch 12/400\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4973 - accuracy: 0.8536 - val_loss: 0.9900 - val_accuracy: 0.7504\n",
      "Epoch 13/400\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.5199 - accuracy: 0.8495 - val_loss: 0.7221 - val_accuracy: 0.8045\n",
      "Epoch 00013: early stopping\n",
      "\n",
      "Test loss: 0.722\n",
      "Test accuracy: 0.804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa1ff30b908>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 512\n",
    "epochs = 400   # Setting up higher epoch in persuit of finding global moinima,\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)   # Set up early stopping to avoid wastage of computing power\n",
    "                                                                            # Kept patience level to 5 to check for considerable time to get out of local minima if possible\n",
    "    \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [es],\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-T26uanoHMGF"
   },
   "source": [
    "Observation: The graph shows that the model might be jumping in local mimima and it breaks at a lower epoch. The model seems to be a highly overfitting model and may not perform well as evident from the graph above. Also because of its overfitted nature the model seems to memorize more in training but testing seems to fail miserably so not a good model for production.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xIs6fywwIOKY"
   },
   "source": [
    "### Trying with 1024 batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "iK5Cmr1G3h_1",
    "outputId": "cf81fc26-9d91-45e7-b339-65bf4430edca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_5 (None, 1024) ==> (None, 1024)\n",
      "dense_18 (None, 1024) ==> (None, 1024)\n",
      "dense_19 (None, 1024) ==> (None, 10)\n",
      "\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_5 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,063,946\n",
      "Trainable params: 1,061,898\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(1024,))) # Set the batch normalization with input shape 32 x 32\n",
    "model.add(Dense(1024, activation='relu', input_shape=(1024,)))   #First hidden layer of 1024  neurons, each neuron takes input \n",
    "                                                               # vector of size 1024\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))            # Adding a softmax layer for output which contains as many \n",
    "                                                               # neurons as the number of classes (10) which is also the \n",
    "                                                               # the shape of each output vector ( one hot coded)\n",
    "\n",
    "                                                               # output layer also uses softmax. This normalizes the values \n",
    "                                                               # from the ten output nodes such that: \n",
    "                                                               #        all the values are between 0 and 1, and\n",
    "                                                               #        the sum of all ten values is 1.  \n",
    "                                                               # prediction is the lable of the node that gets highest fraction, is \n",
    "        \n",
    "        \n",
    "\n",
    "for l in model.layers:\n",
    "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
    "print()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 679
    },
    "colab_type": "code",
    "id": "_lHJpZsw3iOB",
    "outputId": "464f3a18-554c-4c0f-fd65-a02ebe8717c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.5580 - accuracy: 0.8541 - val_loss: 0.6295 - val_accuracy: 0.8289\n",
      "Epoch 2/400\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4200 - accuracy: 0.8769 - val_loss: 0.6675 - val_accuracy: 0.8235\n",
      "Epoch 3/400\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3551 - accuracy: 0.8965 - val_loss: 0.5581 - val_accuracy: 0.8491\n",
      "Epoch 4/400\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3413 - accuracy: 0.8982 - val_loss: 0.6965 - val_accuracy: 0.8179\n",
      "Epoch 5/400\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.4122 - accuracy: 0.8790 - val_loss: 0.6630 - val_accuracy: 0.8254\n",
      "Epoch 6/400\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.4473 - accuracy: 0.8700 - val_loss: 0.6738 - val_accuracy: 0.8218\n",
      "Epoch 7/400\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3619 - accuracy: 0.8933 - val_loss: 0.5950 - val_accuracy: 0.8409\n",
      "Epoch 8/400\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3178 - accuracy: 0.9075 - val_loss: 0.9207 - val_accuracy: 0.7826\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "Test loss: 0.921\n",
      "Test accuracy: 0.783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa2500b40f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "epochs = 400   # Setting up higher epoch in persuit of finding global moinima,\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)   # Set up early stopping to avoid wastage of computing power\n",
    "                                                                            # Kept patience level to 5 to check for considerable time to get out of local minima if possible\n",
    "    \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [es],\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9EQ42cAcKdb6"
   },
   "source": [
    "Observations: \n",
    "The model again as model with 512 batch size seems an highly overfitting model with lot of fluctuation in the graph. Also because of its overfitted nature the model seems to memorize more in training but testing seems to fail miserably so not a good model for production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FQuRxHI6LTUA"
   },
   "source": [
    "### Trying with batch size of 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "QVIWsoMt32uH",
    "outputId": "0ac48f36-9a85-423e-b957-8867b6d4df57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_9 (None, 1024) ==> (None, 1024)\n",
      "dense_26 (None, 1024) ==> (None, 1024)\n",
      "dense_27 (None, 1024) ==> (None, 10)\n",
      "\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_9 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,063,946\n",
      "Trainable params: 1,061,898\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(1024,))) # Set the batch normalization with input shape 32 x 32\n",
    "model.add(Dense(1024, activation='relu', input_shape=(1024,)))   #First hidden layer of 1024  neurons, each neuron takes input \n",
    "                                                               # vector of size 1024\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))            # Adding a softmax layer for output which contains as many \n",
    "                                                               # neurons as the number of classes (10) which is also the \n",
    "                                                               # the shape of each output vector ( one hot coded)\n",
    "\n",
    "                                                               # output layer also uses softmax. This normalizes the values \n",
    "                                                               # from the ten output nodes such that: \n",
    "                                                               #        all the values are between 0 and 1, and\n",
    "                                                               #        the sum of all ten values is 1.  \n",
    "                                                               # prediction is the lable of the node that gets highest fraction, is \n",
    "        \n",
    "        \n",
    "\n",
    "for l in model.layers:\n",
    "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
    "print()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uGOp-ffq36K0",
    "outputId": "479280b6-0a5c-4cf9-950e-13b7fed6af92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 3.7712 - accuracy: 0.1413 - val_loss: 2.7047 - val_accuracy: 0.1031\n",
      "Epoch 2/400\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 2.5268 - accuracy: 0.2593 - val_loss: 2.3181 - val_accuracy: 0.1199\n",
      "Epoch 3/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.9449 - accuracy: 0.3756 - val_loss: 2.2092 - val_accuracy: 0.2371\n",
      "Epoch 4/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.6248 - accuracy: 0.4963 - val_loss: 2.0951 - val_accuracy: 0.3147\n",
      "Epoch 5/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.4186 - accuracy: 0.5880 - val_loss: 1.9812 - val_accuracy: 0.5374\n",
      "Epoch 6/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.2762 - accuracy: 0.6459 - val_loss: 1.8899 - val_accuracy: 0.6096\n",
      "Epoch 7/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.1715 - accuracy: 0.6808 - val_loss: 1.8003 - val_accuracy: 0.6503\n",
      "Epoch 8/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0923 - accuracy: 0.7020 - val_loss: 1.7208 - val_accuracy: 0.6777\n",
      "Epoch 9/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0272 - accuracy: 0.7194 - val_loss: 1.6493 - val_accuracy: 0.6977\n",
      "Epoch 10/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9739 - accuracy: 0.7344 - val_loss: 1.5835 - val_accuracy: 0.7091\n",
      "Epoch 11/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9264 - accuracy: 0.7470 - val_loss: 1.5196 - val_accuracy: 0.7222\n",
      "Epoch 12/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8869 - accuracy: 0.7568 - val_loss: 1.4624 - val_accuracy: 0.7321\n",
      "Epoch 13/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8513 - accuracy: 0.7673 - val_loss: 1.4016 - val_accuracy: 0.7426\n",
      "Epoch 14/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8195 - accuracy: 0.7761 - val_loss: 1.3533 - val_accuracy: 0.7461\n",
      "Epoch 15/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.7913 - accuracy: 0.7832 - val_loss: 1.3009 - val_accuracy: 0.7596\n",
      "Epoch 16/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7637 - accuracy: 0.7908 - val_loss: 1.2484 - val_accuracy: 0.7675\n",
      "Epoch 17/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7384 - accuracy: 0.7989 - val_loss: 1.2033 - val_accuracy: 0.7717\n",
      "Epoch 18/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7163 - accuracy: 0.8030 - val_loss: 1.1603 - val_accuracy: 0.7732\n",
      "Epoch 19/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6945 - accuracy: 0.8110 - val_loss: 1.1141 - val_accuracy: 0.7804\n",
      "Epoch 20/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6757 - accuracy: 0.8153 - val_loss: 1.0806 - val_accuracy: 0.7833\n",
      "Epoch 21/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6572 - accuracy: 0.8209 - val_loss: 1.0298 - val_accuracy: 0.7934\n",
      "Epoch 22/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6388 - accuracy: 0.8259 - val_loss: 0.9983 - val_accuracy: 0.7935\n",
      "Epoch 23/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6211 - accuracy: 0.8318 - val_loss: 0.9603 - val_accuracy: 0.7986\n",
      "Epoch 24/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6053 - accuracy: 0.8367 - val_loss: 0.9245 - val_accuracy: 0.8012\n",
      "Epoch 25/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5914 - accuracy: 0.8409 - val_loss: 0.8937 - val_accuracy: 0.8068\n",
      "Epoch 26/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5755 - accuracy: 0.8446 - val_loss: 0.8624 - val_accuracy: 0.8104\n",
      "Epoch 27/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5639 - accuracy: 0.8490 - val_loss: 0.8344 - val_accuracy: 0.8148\n",
      "Epoch 28/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5535 - accuracy: 0.8505 - val_loss: 0.8107 - val_accuracy: 0.8147\n",
      "Epoch 29/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5382 - accuracy: 0.8540 - val_loss: 0.7881 - val_accuracy: 0.8172\n",
      "Epoch 30/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5274 - accuracy: 0.8579 - val_loss: 0.7634 - val_accuracy: 0.8194\n",
      "Epoch 31/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5146 - accuracy: 0.8620 - val_loss: 0.7431 - val_accuracy: 0.8225\n",
      "Epoch 32/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5026 - accuracy: 0.8640 - val_loss: 0.7164 - val_accuracy: 0.8285\n",
      "Epoch 33/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.4942 - accuracy: 0.8667 - val_loss: 0.7085 - val_accuracy: 0.8236\n",
      "Epoch 34/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4870 - accuracy: 0.8679 - val_loss: 0.6833 - val_accuracy: 0.8338\n",
      "Epoch 35/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4716 - accuracy: 0.8739 - val_loss: 0.6673 - val_accuracy: 0.8336\n",
      "Epoch 36/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4629 - accuracy: 0.8760 - val_loss: 0.6584 - val_accuracy: 0.8319\n",
      "Epoch 37/400\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.4557 - accuracy: 0.8782 - val_loss: 0.6426 - val_accuracy: 0.8363\n",
      "Epoch 38/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.4462 - accuracy: 0.8806 - val_loss: 0.6310 - val_accuracy: 0.8379\n",
      "Epoch 39/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4395 - accuracy: 0.8834 - val_loss: 0.6279 - val_accuracy: 0.8346\n",
      "Epoch 40/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.4299 - accuracy: 0.8858 - val_loss: 0.6168 - val_accuracy: 0.8364\n",
      "Epoch 41/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4264 - accuracy: 0.8854 - val_loss: 0.6011 - val_accuracy: 0.8418\n",
      "Epoch 42/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4154 - accuracy: 0.8893 - val_loss: 0.5913 - val_accuracy: 0.8421\n",
      "Epoch 43/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4128 - accuracy: 0.8895 - val_loss: 0.5849 - val_accuracy: 0.8433\n",
      "Epoch 44/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4044 - accuracy: 0.8925 - val_loss: 0.5962 - val_accuracy: 0.8356\n",
      "Epoch 45/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4055 - accuracy: 0.8897 - val_loss: 0.5962 - val_accuracy: 0.8331\n",
      "Epoch 46/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4002 - accuracy: 0.8909 - val_loss: 0.5884 - val_accuracy: 0.8356\n",
      "Epoch 47/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3875 - accuracy: 0.8966 - val_loss: 0.5651 - val_accuracy: 0.8439\n",
      "Epoch 48/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3809 - accuracy: 0.8978 - val_loss: 0.5644 - val_accuracy: 0.8439\n",
      "Epoch 49/400\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3760 - accuracy: 0.8987 - val_loss: 0.5557 - val_accuracy: 0.8451\n",
      "Epoch 50/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3686 - accuracy: 0.9025 - val_loss: 0.5598 - val_accuracy: 0.8451\n",
      "Epoch 51/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3660 - accuracy: 0.9026 - val_loss: 0.5458 - val_accuracy: 0.8502\n",
      "Epoch 52/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3584 - accuracy: 0.9043 - val_loss: 0.5464 - val_accuracy: 0.8486\n",
      "Epoch 53/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3489 - accuracy: 0.9091 - val_loss: 0.5388 - val_accuracy: 0.8508\n",
      "Epoch 54/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3449 - accuracy: 0.9097 - val_loss: 0.5415 - val_accuracy: 0.8483\n",
      "Epoch 55/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3380 - accuracy: 0.9125 - val_loss: 0.5368 - val_accuracy: 0.8517\n",
      "Epoch 56/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3336 - accuracy: 0.9127 - val_loss: 0.5317 - val_accuracy: 0.8523\n",
      "Epoch 57/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3296 - accuracy: 0.9131 - val_loss: 0.5344 - val_accuracy: 0.8511\n",
      "Epoch 58/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3277 - accuracy: 0.9142 - val_loss: 0.5434 - val_accuracy: 0.8477\n",
      "Epoch 59/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3259 - accuracy: 0.9146 - val_loss: 0.5466 - val_accuracy: 0.8467\n",
      "Epoch 60/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3218 - accuracy: 0.9160 - val_loss: 0.5255 - val_accuracy: 0.8545\n",
      "Epoch 61/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3127 - accuracy: 0.9191 - val_loss: 0.5270 - val_accuracy: 0.8544\n",
      "Epoch 62/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3145 - accuracy: 0.9178 - val_loss: 0.5324 - val_accuracy: 0.8516\n",
      "Epoch 63/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3044 - accuracy: 0.9210 - val_loss: 0.5247 - val_accuracy: 0.8561\n",
      "Epoch 64/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2962 - accuracy: 0.9238 - val_loss: 0.5164 - val_accuracy: 0.8594\n",
      "Epoch 65/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2911 - accuracy: 0.9264 - val_loss: 0.5170 - val_accuracy: 0.8576\n",
      "Epoch 66/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2869 - accuracy: 0.9278 - val_loss: 0.5184 - val_accuracy: 0.8569\n",
      "Epoch 67/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2846 - accuracy: 0.9277 - val_loss: 0.5191 - val_accuracy: 0.8556\n",
      "Epoch 68/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2819 - accuracy: 0.9280 - val_loss: 0.5330 - val_accuracy: 0.8508\n",
      "Epoch 69/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2867 - accuracy: 0.9244 - val_loss: 0.5236 - val_accuracy: 0.8539\n",
      "Epoch 00069: early stopping\n",
      "\n",
      "Test loss: 0.524\n",
      "Test accuracy: 0.854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa1fa9a98d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "epochs = 400   # Setting up higher epoch in persuit of finding global moinima,\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)   # Set up early stopping to avoid wastage of computing power\n",
    "                                                                            # Kept patience level to 5 to check for considerable time to get out of local minima if possible\n",
    "    \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [es],\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tvhR6cpmLfTK"
   },
   "source": [
    "Observations: \n",
    "\n",
    "This seems to be the best model with model converging fast and providing a higher test accuracy of about 85.5%. The model took about 69 epochs to reach to global minima.\n",
    "\n",
    "In persuit to check if the early stopping might have stopped from getting up to lower loss and higher accuracy let's try to rerun the test without early stop for about 200 iterations and see if it impacts the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJy-AXFGBxxr"
   },
   "source": [
    "Trying with batch size of 5000 and 200 epochs and no early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "Un6Fjv8XB40A",
    "outputId": "f74f29d0-a020-4fd3-c523-311127e1019b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_11 (None, 1024) ==> (None, 1024)\n",
      "dense_30 (None, 1024) ==> (None, 1024)\n",
      "dense_31 (None, 1024) ==> (None, 10)\n",
      "\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_11 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,063,946\n",
      "Trainable params: 1,061,898\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(1024,))) # Set the batch normalization with input shape 32 x 32\n",
    "model.add(Dense(1024, activation='relu', input_shape=(1024,)))   #First hidden layer of 1024  neurons, each neuron takes input \n",
    "                                                               # vector of size 1024\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))            # Adding a softmax layer for output which contains as many \n",
    "                                                               # neurons as the number of classes (10) which is also the \n",
    "                                                               # the shape of each output vector ( one hot coded)\n",
    "\n",
    "                                                               # output layer also uses softmax. This normalizes the values \n",
    "                                                               # from the ten output nodes such that: \n",
    "                                                               #        all the values are between 0 and 1, and\n",
    "                                                               #        the sum of all ten values is 1.  \n",
    "                                                               # prediction is the lable of the node that gets highest fraction, is \n",
    "        \n",
    "        \n",
    "\n",
    "for l in model.layers:\n",
    "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
    "print()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AD3r8Kr2CKHX",
    "outputId": "0a08a998-18e9-46cf-8360-ecaf9324a4a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 3.3728 - accuracy: 0.1496 - val_loss: 2.6005 - val_accuracy: 0.1009\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 2.3831 - accuracy: 0.2825 - val_loss: 2.3799 - val_accuracy: 0.1041\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.8842 - accuracy: 0.4212 - val_loss: 2.1670 - val_accuracy: 0.2942\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.5838 - accuracy: 0.5173 - val_loss: 2.0671 - val_accuracy: 0.4057\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.3904 - accuracy: 0.5890 - val_loss: 1.9638 - val_accuracy: 0.4937\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.2503 - accuracy: 0.6447 - val_loss: 1.8689 - val_accuracy: 0.5696\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1501 - accuracy: 0.6794 - val_loss: 1.7839 - val_accuracy: 0.6252\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.0739 - accuracy: 0.7032 - val_loss: 1.7146 - val_accuracy: 0.6291\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0108 - accuracy: 0.7196 - val_loss: 1.6279 - val_accuracy: 0.6943\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9527 - accuracy: 0.7371 - val_loss: 1.5657 - val_accuracy: 0.6923\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9093 - accuracy: 0.7491 - val_loss: 1.5058 - val_accuracy: 0.7108\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8699 - accuracy: 0.7579 - val_loss: 1.4413 - val_accuracy: 0.7313\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8323 - accuracy: 0.7713 - val_loss: 1.3846 - val_accuracy: 0.7402\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8030 - accuracy: 0.7784 - val_loss: 1.3382 - val_accuracy: 0.7424\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7748 - accuracy: 0.7867 - val_loss: 1.2818 - val_accuracy: 0.7492\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7460 - accuracy: 0.7961 - val_loss: 1.2343 - val_accuracy: 0.7589\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7205 - accuracy: 0.8025 - val_loss: 1.1825 - val_accuracy: 0.7708\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7001 - accuracy: 0.8072 - val_loss: 1.1378 - val_accuracy: 0.7726\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6806 - accuracy: 0.8123 - val_loss: 1.0981 - val_accuracy: 0.7789\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6611 - accuracy: 0.8180 - val_loss: 1.0580 - val_accuracy: 0.7818\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6397 - accuracy: 0.8240 - val_loss: 1.0178 - val_accuracy: 0.7914\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6227 - accuracy: 0.8295 - val_loss: 0.9805 - val_accuracy: 0.7927\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6090 - accuracy: 0.8325 - val_loss: 0.9425 - val_accuracy: 0.8001\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.5934 - accuracy: 0.8373 - val_loss: 0.9108 - val_accuracy: 0.8013\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5751 - accuracy: 0.8425 - val_loss: 0.8752 - val_accuracy: 0.8073\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.5612 - accuracy: 0.8459 - val_loss: 0.8472 - val_accuracy: 0.8108\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5467 - accuracy: 0.8512 - val_loss: 0.8214 - val_accuracy: 0.8133\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5303 - accuracy: 0.8563 - val_loss: 0.7916 - val_accuracy: 0.8194\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.5178 - accuracy: 0.8602 - val_loss: 0.7717 - val_accuracy: 0.8206\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.5072 - accuracy: 0.8628 - val_loss: 0.7483 - val_accuracy: 0.8243\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.4992 - accuracy: 0.8652 - val_loss: 0.7315 - val_accuracy: 0.8234\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.4896 - accuracy: 0.8676 - val_loss: 0.7109 - val_accuracy: 0.8233\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.4801 - accuracy: 0.8702 - val_loss: 0.6940 - val_accuracy: 0.8261\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4713 - accuracy: 0.8709 - val_loss: 0.6765 - val_accuracy: 0.8293\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4601 - accuracy: 0.8753 - val_loss: 0.6646 - val_accuracy: 0.8311\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4526 - accuracy: 0.8778 - val_loss: 0.6480 - val_accuracy: 0.8341\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4388 - accuracy: 0.8837 - val_loss: 0.6394 - val_accuracy: 0.8332\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4336 - accuracy: 0.8838 - val_loss: 0.6275 - val_accuracy: 0.8356\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4253 - accuracy: 0.8858 - val_loss: 0.6195 - val_accuracy: 0.8346\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4179 - accuracy: 0.8871 - val_loss: 0.6101 - val_accuracy: 0.8368\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4143 - accuracy: 0.8892 - val_loss: 0.6021 - val_accuracy: 0.8366\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4060 - accuracy: 0.8907 - val_loss: 0.5916 - val_accuracy: 0.8401\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4000 - accuracy: 0.8923 - val_loss: 0.5824 - val_accuracy: 0.8414\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3922 - accuracy: 0.8943 - val_loss: 0.5795 - val_accuracy: 0.8438\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3868 - accuracy: 0.8967 - val_loss: 0.5690 - val_accuracy: 0.8461\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3774 - accuracy: 0.9005 - val_loss: 0.5628 - val_accuracy: 0.8452\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3717 - accuracy: 0.9008 - val_loss: 0.5677 - val_accuracy: 0.8419\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3678 - accuracy: 0.9023 - val_loss: 0.5786 - val_accuracy: 0.8380\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3643 - accuracy: 0.9020 - val_loss: 0.5659 - val_accuracy: 0.8440\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3675 - accuracy: 0.8992 - val_loss: 0.5518 - val_accuracy: 0.8464\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3602 - accuracy: 0.9030 - val_loss: 0.5729 - val_accuracy: 0.8411\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3577 - accuracy: 0.9028 - val_loss: 0.5453 - val_accuracy: 0.8497\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3504 - accuracy: 0.9056 - val_loss: 0.5621 - val_accuracy: 0.8419\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3433 - accuracy: 0.9078 - val_loss: 0.5441 - val_accuracy: 0.8481\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3324 - accuracy: 0.9101 - val_loss: 0.5335 - val_accuracy: 0.8532\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3283 - accuracy: 0.9123 - val_loss: 0.5381 - val_accuracy: 0.8522\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3232 - accuracy: 0.9152 - val_loss: 0.5308 - val_accuracy: 0.8532\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3173 - accuracy: 0.9162 - val_loss: 0.5450 - val_accuracy: 0.8482\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3178 - accuracy: 0.9149 - val_loss: 0.5313 - val_accuracy: 0.8519\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3111 - accuracy: 0.9183 - val_loss: 0.5397 - val_accuracy: 0.8510\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3045 - accuracy: 0.9207 - val_loss: 0.5323 - val_accuracy: 0.8543\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.3101 - accuracy: 0.9176 - val_loss: 0.5455 - val_accuracy: 0.8499\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3033 - accuracy: 0.9189 - val_loss: 0.5268 - val_accuracy: 0.8553\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2930 - accuracy: 0.9218 - val_loss: 0.5250 - val_accuracy: 0.8543\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2857 - accuracy: 0.9252 - val_loss: 0.5280 - val_accuracy: 0.8552\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2806 - accuracy: 0.9283 - val_loss: 0.5212 - val_accuracy: 0.8576\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2737 - accuracy: 0.9304 - val_loss: 0.5193 - val_accuracy: 0.8588\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2718 - accuracy: 0.9301 - val_loss: 0.5165 - val_accuracy: 0.8600\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2697 - accuracy: 0.9315 - val_loss: 0.5298 - val_accuracy: 0.8566\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2683 - accuracy: 0.9310 - val_loss: 0.5253 - val_accuracy: 0.8553\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2597 - accuracy: 0.9344 - val_loss: 0.5128 - val_accuracy: 0.8592\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2548 - accuracy: 0.9365 - val_loss: 0.5154 - val_accuracy: 0.8594\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2599 - accuracy: 0.9322 - val_loss: 0.5225 - val_accuracy: 0.8581\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2550 - accuracy: 0.9357 - val_loss: 0.5212 - val_accuracy: 0.8599\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2489 - accuracy: 0.9373 - val_loss: 0.5270 - val_accuracy: 0.8567\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2512 - accuracy: 0.9352 - val_loss: 0.5352 - val_accuracy: 0.8533\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2499 - accuracy: 0.9358 - val_loss: 0.5219 - val_accuracy: 0.8572\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2451 - accuracy: 0.9366 - val_loss: 0.5300 - val_accuracy: 0.8552\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2448 - accuracy: 0.9365 - val_loss: 0.5235 - val_accuracy: 0.8564\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2419 - accuracy: 0.9366 - val_loss: 0.5215 - val_accuracy: 0.8595\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2379 - accuracy: 0.9386 - val_loss: 0.5251 - val_accuracy: 0.8581\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2405 - accuracy: 0.9377 - val_loss: 0.5201 - val_accuracy: 0.8607\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2299 - accuracy: 0.9419 - val_loss: 0.5246 - val_accuracy: 0.8584\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2266 - accuracy: 0.9425 - val_loss: 0.5346 - val_accuracy: 0.8565\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2282 - accuracy: 0.9420 - val_loss: 0.5244 - val_accuracy: 0.8611\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2212 - accuracy: 0.9445 - val_loss: 0.5206 - val_accuracy: 0.8611\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2135 - accuracy: 0.9473 - val_loss: 0.5268 - val_accuracy: 0.8589\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.2150 - accuracy: 0.9456 - val_loss: 0.5305 - val_accuracy: 0.8580\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2120 - accuracy: 0.9473 - val_loss: 0.5238 - val_accuracy: 0.8606\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2111 - accuracy: 0.9478 - val_loss: 0.5441 - val_accuracy: 0.8544\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2187 - accuracy: 0.9444 - val_loss: 0.5223 - val_accuracy: 0.8624\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2085 - accuracy: 0.9491 - val_loss: 0.5258 - val_accuracy: 0.8625\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2013 - accuracy: 0.9504 - val_loss: 0.5327 - val_accuracy: 0.8584\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.1994 - accuracy: 0.9511 - val_loss: 0.5278 - val_accuracy: 0.8609\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1987 - accuracy: 0.9512 - val_loss: 0.5269 - val_accuracy: 0.8633\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1973 - accuracy: 0.9517 - val_loss: 0.5430 - val_accuracy: 0.8563\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2026 - accuracy: 0.9482 - val_loss: 0.5501 - val_accuracy: 0.8564\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.1999 - accuracy: 0.9495 - val_loss: 0.5424 - val_accuracy: 0.8576\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1937 - accuracy: 0.9525 - val_loss: 0.5403 - val_accuracy: 0.8590\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1907 - accuracy: 0.9534 - val_loss: 0.5342 - val_accuracy: 0.8619\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.1914 - accuracy: 0.9525 - val_loss: 0.5526 - val_accuracy: 0.8563\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1864 - accuracy: 0.9543 - val_loss: 0.5462 - val_accuracy: 0.8579\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1833 - accuracy: 0.9555 - val_loss: 0.5428 - val_accuracy: 0.8591\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1788 - accuracy: 0.9571 - val_loss: 0.5415 - val_accuracy: 0.8598\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1767 - accuracy: 0.9571 - val_loss: 0.5322 - val_accuracy: 0.8618\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1746 - accuracy: 0.9579 - val_loss: 0.5523 - val_accuracy: 0.8588\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1784 - accuracy: 0.9566 - val_loss: 0.5507 - val_accuracy: 0.8572\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1755 - accuracy: 0.9574 - val_loss: 0.5456 - val_accuracy: 0.8576\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1692 - accuracy: 0.9596 - val_loss: 0.5447 - val_accuracy: 0.8601\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1701 - accuracy: 0.9580 - val_loss: 0.5494 - val_accuracy: 0.8592\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1714 - accuracy: 0.9568 - val_loss: 0.5489 - val_accuracy: 0.8588\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1760 - accuracy: 0.9555 - val_loss: 0.5442 - val_accuracy: 0.8616\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.1648 - accuracy: 0.9606 - val_loss: 0.5463 - val_accuracy: 0.8606\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1629 - accuracy: 0.9609 - val_loss: 0.5411 - val_accuracy: 0.8638\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1623 - accuracy: 0.9606 - val_loss: 0.5472 - val_accuracy: 0.8617\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1612 - accuracy: 0.9608 - val_loss: 0.5884 - val_accuracy: 0.8516\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1795 - accuracy: 0.9515 - val_loss: 0.5823 - val_accuracy: 0.8534\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1868 - accuracy: 0.9496 - val_loss: 0.5740 - val_accuracy: 0.8548\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1966 - accuracy: 0.9459 - val_loss: 0.5805 - val_accuracy: 0.8562\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1797 - accuracy: 0.9532 - val_loss: 0.5690 - val_accuracy: 0.8558\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1874 - accuracy: 0.9504 - val_loss: 0.5656 - val_accuracy: 0.8588\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1581 - accuracy: 0.9610 - val_loss: 0.5552 - val_accuracy: 0.8611\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1482 - accuracy: 0.9645 - val_loss: 0.5535 - val_accuracy: 0.8624\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1428 - accuracy: 0.9673 - val_loss: 0.5622 - val_accuracy: 0.8597\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1408 - accuracy: 0.9669 - val_loss: 0.5638 - val_accuracy: 0.8609\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1421 - accuracy: 0.9677 - val_loss: 0.5706 - val_accuracy: 0.8588\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.1394 - accuracy: 0.9677 - val_loss: 0.5629 - val_accuracy: 0.8611\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1350 - accuracy: 0.9691 - val_loss: 0.5742 - val_accuracy: 0.8589\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1381 - accuracy: 0.9677 - val_loss: 0.5872 - val_accuracy: 0.8539\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1488 - accuracy: 0.9637 - val_loss: 0.5685 - val_accuracy: 0.8593\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1491 - accuracy: 0.9622 - val_loss: 0.5704 - val_accuracy: 0.8613\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1436 - accuracy: 0.9651 - val_loss: 0.5670 - val_accuracy: 0.8610\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1386 - accuracy: 0.9668 - val_loss: 0.5551 - val_accuracy: 0.8642\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1345 - accuracy: 0.9685 - val_loss: 0.5590 - val_accuracy: 0.8632\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1265 - accuracy: 0.9719 - val_loss: 0.5519 - val_accuracy: 0.8660\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1199 - accuracy: 0.9746 - val_loss: 0.5651 - val_accuracy: 0.8628\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1247 - accuracy: 0.9722 - val_loss: 0.5791 - val_accuracy: 0.8595\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1241 - accuracy: 0.9712 - val_loss: 0.5574 - val_accuracy: 0.8651\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1179 - accuracy: 0.9749 - val_loss: 0.5560 - val_accuracy: 0.8654\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1174 - accuracy: 0.9746 - val_loss: 0.5662 - val_accuracy: 0.8637\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1161 - accuracy: 0.9748 - val_loss: 0.5565 - val_accuracy: 0.8671\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1100 - accuracy: 0.9779 - val_loss: 0.5573 - val_accuracy: 0.8665\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1090 - accuracy: 0.9779 - val_loss: 0.5973 - val_accuracy: 0.8574\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1177 - accuracy: 0.9742 - val_loss: 0.5785 - val_accuracy: 0.8633\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1216 - accuracy: 0.9725 - val_loss: 0.5931 - val_accuracy: 0.8593\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1177 - accuracy: 0.9729 - val_loss: 0.5860 - val_accuracy: 0.8626\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1144 - accuracy: 0.9749 - val_loss: 0.5888 - val_accuracy: 0.8616\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1166 - accuracy: 0.9740 - val_loss: 0.5780 - val_accuracy: 0.8646\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1039 - accuracy: 0.9796 - val_loss: 0.5885 - val_accuracy: 0.8599\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1125 - accuracy: 0.9756 - val_loss: 0.5822 - val_accuracy: 0.8631\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1184 - accuracy: 0.9724 - val_loss: 0.6081 - val_accuracy: 0.8594\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1208 - accuracy: 0.9699 - val_loss: 0.6154 - val_accuracy: 0.8566\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1189 - accuracy: 0.9711 - val_loss: 0.6101 - val_accuracy: 0.8582\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1182 - accuracy: 0.9710 - val_loss: 0.5979 - val_accuracy: 0.8613\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1072 - accuracy: 0.9769 - val_loss: 0.5979 - val_accuracy: 0.8618\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1024 - accuracy: 0.9775 - val_loss: 0.5974 - val_accuracy: 0.8604\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.1019 - accuracy: 0.9784 - val_loss: 0.5757 - val_accuracy: 0.8662\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.0926 - accuracy: 0.9828 - val_loss: 0.5796 - val_accuracy: 0.8659\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0939 - accuracy: 0.9820 - val_loss: 0.5929 - val_accuracy: 0.8632\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.0962 - accuracy: 0.9801 - val_loss: 0.6049 - val_accuracy: 0.8593\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.0953 - accuracy: 0.9801 - val_loss: 0.5959 - val_accuracy: 0.8637\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0966 - accuracy: 0.9805 - val_loss: 0.6443 - val_accuracy: 0.8540\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1122 - accuracy: 0.9725 - val_loss: 0.6116 - val_accuracy: 0.8604\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0991 - accuracy: 0.9791 - val_loss: 0.6173 - val_accuracy: 0.8598\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0927 - accuracy: 0.9812 - val_loss: 0.6042 - val_accuracy: 0.8634\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0887 - accuracy: 0.9830 - val_loss: 0.5979 - val_accuracy: 0.8640\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0841 - accuracy: 0.9850 - val_loss: 0.5883 - val_accuracy: 0.8662\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0823 - accuracy: 0.9857 - val_loss: 0.5982 - val_accuracy: 0.8652\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.0818 - accuracy: 0.9860 - val_loss: 0.6067 - val_accuracy: 0.8628\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0927 - accuracy: 0.9806 - val_loss: 0.6711 - val_accuracy: 0.8497\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0995 - accuracy: 0.9774 - val_loss: 0.6266 - val_accuracy: 0.8571\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1012 - accuracy: 0.9767 - val_loss: 0.6238 - val_accuracy: 0.8606\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0937 - accuracy: 0.9796 - val_loss: 0.6184 - val_accuracy: 0.8604\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0866 - accuracy: 0.9823 - val_loss: 0.6085 - val_accuracy: 0.8663\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0853 - accuracy: 0.9834 - val_loss: 0.6305 - val_accuracy: 0.8591\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.0907 - accuracy: 0.9799 - val_loss: 0.6210 - val_accuracy: 0.8624\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0895 - accuracy: 0.9810 - val_loss: 0.6450 - val_accuracy: 0.8569\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0839 - accuracy: 0.9829 - val_loss: 0.6306 - val_accuracy: 0.8600\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0804 - accuracy: 0.9841 - val_loss: 0.6078 - val_accuracy: 0.8663\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0761 - accuracy: 0.9865 - val_loss: 0.6336 - val_accuracy: 0.8593\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0808 - accuracy: 0.9840 - val_loss: 0.6212 - val_accuracy: 0.8623\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0809 - accuracy: 0.9839 - val_loss: 0.6396 - val_accuracy: 0.8589\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0820 - accuracy: 0.9830 - val_loss: 0.6419 - val_accuracy: 0.8607\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0830 - accuracy: 0.9819 - val_loss: 0.6583 - val_accuracy: 0.8582\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0922 - accuracy: 0.9791 - val_loss: 0.6540 - val_accuracy: 0.8601\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1786 - accuracy: 0.9624 - val_loss: 0.7753 - val_accuracy: 0.8404\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2527 - accuracy: 0.9410 - val_loss: 0.9589 - val_accuracy: 0.8161\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3316 - accuracy: 0.9210 - val_loss: 1.1116 - val_accuracy: 0.8025\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.5082 - accuracy: 0.8930 - val_loss: 1.1366 - val_accuracy: 0.8051\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.7468 - accuracy: 0.8642 - val_loss: 0.9854 - val_accuracy: 0.8191\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1.2255 - accuracy: 0.8250 - val_loss: 2.2813 - val_accuracy: 0.7295\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 2.5417 - accuracy: 0.7557 - val_loss: 3.6599 - val_accuracy: 0.6539\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 3.3362 - accuracy: 0.7168 - val_loss: 4.4091 - val_accuracy: 0.6505\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 2.2896 - accuracy: 0.7547 - val_loss: 2.1585 - val_accuracy: 0.7234\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1.0612 - accuracy: 0.8122 - val_loss: 1.3445 - val_accuracy: 0.7887\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5800 - accuracy: 0.8646 - val_loss: 0.9142 - val_accuracy: 0.8293\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3644 - accuracy: 0.9022 - val_loss: 0.8223 - val_accuracy: 0.8404\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2626 - accuracy: 0.9234 - val_loss: 0.7326 - val_accuracy: 0.8554\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2093 - accuracy: 0.9375 - val_loss: 0.7036 - val_accuracy: 0.8607\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1771 - accuracy: 0.9477 - val_loss: 0.6787 - val_accuracy: 0.8624\n",
      "\n",
      "Test loss: 0.679\n",
      "Test accuracy: 0.862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa20018c2b0>"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "epochs = 200   # Setting up higher epoch in persuit of finding global moinima,\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)   # Set up early stopping to avoid wastage of computing power\n",
    "                                                                            # Kept patience level to 5 to check for considerable time to get out of local minima if possible\n",
    "    \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    # callbacks = [es],\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LoRkwivDDLlo"
   },
   "source": [
    "Observations: There is not much difference to the accuracy results with higher epochs without early stop and it seems with more epochs the model learns more but ultimately the test results are same or fractional improvement. This fractional improvement is not worth the amount of time needed to run the model so we will go with early stop for this model \n",
    "\n",
    "With all other factors like fixed optimzer function and activation function as RELU the model with batch size of 5000 and early stopping epoch seems to be the best model overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FsU1voDb5SCg"
   },
   "source": [
    "## Trying with different optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zaehaIosNBzJ"
   },
   "source": [
    "### Trying with SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "RBIok6zu5jvR",
    "outputId": "476113d5-47e8-4f6f-81d2-9a0d19c8d1c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_12 (None, 1024) ==> (None, 1024)\n",
      "dense_32 (None, 1024) ==> (None, 1024)\n",
      "dense_33 (None, 1024) ==> (None, 10)\n",
      "\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_12 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,063,946\n",
      "Trainable params: 1,061,898\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(1024,))) # Set the batch normalization with input shape 32 x 32\n",
    "model.add(Dense(1024, activation='relu', input_shape=(1024,)))   #First hidden layer of 1024  neurons, each neuron takes input \n",
    "                                                               # vector of size 1024\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))            # Adding a softmax layer for output which contains as many \n",
    "                                                               # neurons as the number of classes (10) which is also the \n",
    "                                                               # the shape of each output vector ( one hot coded)\n",
    "\n",
    "                                                               # output layer also uses softmax. This normalizes the values \n",
    "                                                               # from the ten output nodes such that: \n",
    "                                                               #        all the values are between 0 and 1, and\n",
    "                                                               #        the sum of all ten values is 1.  \n",
    "                                                               # prediction is the lable of the node that gets highest fraction, is \n",
    "        \n",
    "        \n",
    "\n",
    "for l in model.layers:\n",
    "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
    "print()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HEbWrLmc5vPF",
    "outputId": "9f0c3b43-7677-46dd-f8ba-8506bdd53bac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2.5049 - accuracy: 0.1011 - val_loss: 2.3078 - val_accuracy: 0.1055\n",
      "Epoch 2/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 2.3768 - accuracy: 0.1175 - val_loss: 2.3020 - val_accuracy: 0.1153\n",
      "Epoch 3/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 2.3307 - accuracy: 0.1348 - val_loss: 2.2984 - val_accuracy: 0.1152\n",
      "Epoch 4/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 2.2918 - accuracy: 0.1557 - val_loss: 2.2912 - val_accuracy: 0.1489\n",
      "Epoch 5/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 2.2575 - accuracy: 0.1802 - val_loss: 2.2851 - val_accuracy: 0.1563\n",
      "Epoch 6/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 2.2265 - accuracy: 0.2009 - val_loss: 2.2775 - val_accuracy: 0.1729\n",
      "Epoch 7/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 2.1982 - accuracy: 0.2225 - val_loss: 2.2692 - val_accuracy: 0.2013\n",
      "Epoch 8/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 2.1720 - accuracy: 0.2447 - val_loss: 2.2594 - val_accuracy: 0.2135\n",
      "Epoch 9/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 2.1472 - accuracy: 0.2596 - val_loss: 2.2488 - val_accuracy: 0.2447\n",
      "Epoch 10/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 2.1231 - accuracy: 0.2789 - val_loss: 2.2372 - val_accuracy: 0.2740\n",
      "Epoch 11/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 2.1004 - accuracy: 0.2954 - val_loss: 2.2260 - val_accuracy: 0.2836\n",
      "Epoch 12/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 2.0787 - accuracy: 0.3104 - val_loss: 2.2134 - val_accuracy: 0.3054\n",
      "Epoch 13/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 2.0578 - accuracy: 0.3258 - val_loss: 2.2002 - val_accuracy: 0.3249\n",
      "Epoch 14/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 2.0375 - accuracy: 0.3386 - val_loss: 2.1860 - val_accuracy: 0.3423\n",
      "Epoch 15/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 2.0179 - accuracy: 0.3516 - val_loss: 2.1724 - val_accuracy: 0.3518\n",
      "Epoch 16/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.9988 - accuracy: 0.3637 - val_loss: 2.1577 - val_accuracy: 0.3671\n",
      "Epoch 17/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.9799 - accuracy: 0.3756 - val_loss: 2.1429 - val_accuracy: 0.3788\n",
      "Epoch 18/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.9619 - accuracy: 0.3858 - val_loss: 2.1279 - val_accuracy: 0.3893\n",
      "Epoch 19/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.9443 - accuracy: 0.3963 - val_loss: 2.1120 - val_accuracy: 0.4039\n",
      "Epoch 20/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.9270 - accuracy: 0.4055 - val_loss: 2.0955 - val_accuracy: 0.4122\n",
      "Epoch 21/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.9097 - accuracy: 0.4159 - val_loss: 2.0796 - val_accuracy: 0.4200\n",
      "Epoch 22/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.8929 - accuracy: 0.4255 - val_loss: 2.0625 - val_accuracy: 0.4263\n",
      "Epoch 23/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.8763 - accuracy: 0.4341 - val_loss: 2.0456 - val_accuracy: 0.4378\n",
      "Epoch 24/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.8599 - accuracy: 0.4424 - val_loss: 2.0279 - val_accuracy: 0.4475\n",
      "Epoch 25/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.8441 - accuracy: 0.4504 - val_loss: 2.0098 - val_accuracy: 0.4541\n",
      "Epoch 26/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.8280 - accuracy: 0.4579 - val_loss: 1.9923 - val_accuracy: 0.4613\n",
      "Epoch 27/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.8129 - accuracy: 0.4659 - val_loss: 1.9733 - val_accuracy: 0.4673\n",
      "Epoch 28/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.7977 - accuracy: 0.4722 - val_loss: 1.9559 - val_accuracy: 0.4742\n",
      "Epoch 29/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.7828 - accuracy: 0.4799 - val_loss: 1.9370 - val_accuracy: 0.4818\n",
      "Epoch 30/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.7680 - accuracy: 0.4865 - val_loss: 1.9177 - val_accuracy: 0.4855\n",
      "Epoch 31/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.7535 - accuracy: 0.4933 - val_loss: 1.8985 - val_accuracy: 0.4928\n",
      "Epoch 32/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.7392 - accuracy: 0.5007 - val_loss: 1.8799 - val_accuracy: 0.4969\n",
      "Epoch 33/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.7254 - accuracy: 0.5065 - val_loss: 1.8604 - val_accuracy: 0.5036\n",
      "Epoch 34/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.7117 - accuracy: 0.5130 - val_loss: 1.8410 - val_accuracy: 0.5107\n",
      "Epoch 35/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.6977 - accuracy: 0.5194 - val_loss: 1.8232 - val_accuracy: 0.5157\n",
      "Epoch 36/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.6846 - accuracy: 0.5246 - val_loss: 1.8041 - val_accuracy: 0.5207\n",
      "Epoch 37/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.6716 - accuracy: 0.5304 - val_loss: 1.7851 - val_accuracy: 0.5264\n",
      "Epoch 38/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.6585 - accuracy: 0.5352 - val_loss: 1.7670 - val_accuracy: 0.5323\n",
      "Epoch 39/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.6461 - accuracy: 0.5408 - val_loss: 1.7487 - val_accuracy: 0.5375\n",
      "Epoch 40/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.6336 - accuracy: 0.5457 - val_loss: 1.7307 - val_accuracy: 0.5408\n",
      "Epoch 41/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.6213 - accuracy: 0.5504 - val_loss: 1.7142 - val_accuracy: 0.5451\n",
      "Epoch 42/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.6094 - accuracy: 0.5553 - val_loss: 1.6974 - val_accuracy: 0.5469\n",
      "Epoch 43/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.5976 - accuracy: 0.5600 - val_loss: 1.6801 - val_accuracy: 0.5531\n",
      "Epoch 44/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.5857 - accuracy: 0.5640 - val_loss: 1.6631 - val_accuracy: 0.5573\n",
      "Epoch 45/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.5744 - accuracy: 0.5690 - val_loss: 1.6469 - val_accuracy: 0.5601\n",
      "Epoch 46/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.5632 - accuracy: 0.5730 - val_loss: 1.6316 - val_accuracy: 0.5643\n",
      "Epoch 47/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.5523 - accuracy: 0.5775 - val_loss: 1.6167 - val_accuracy: 0.5670\n",
      "Epoch 48/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.5412 - accuracy: 0.5815 - val_loss: 1.6022 - val_accuracy: 0.5724\n",
      "Epoch 49/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.5306 - accuracy: 0.5865 - val_loss: 1.5875 - val_accuracy: 0.5742\n",
      "Epoch 50/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.5201 - accuracy: 0.5888 - val_loss: 1.5731 - val_accuracy: 0.5787\n",
      "Epoch 51/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.5100 - accuracy: 0.5915 - val_loss: 1.5596 - val_accuracy: 0.5819\n",
      "Epoch 52/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.4997 - accuracy: 0.5963 - val_loss: 1.5466 - val_accuracy: 0.5863\n",
      "Epoch 53/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.4897 - accuracy: 0.5999 - val_loss: 1.5335 - val_accuracy: 0.5887\n",
      "Epoch 54/400\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 1.4801 - accuracy: 0.6028 - val_loss: 1.5215 - val_accuracy: 0.5932\n",
      "Epoch 55/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.4708 - accuracy: 0.6052 - val_loss: 1.5089 - val_accuracy: 0.5973\n",
      "Epoch 56/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.4613 - accuracy: 0.6082 - val_loss: 1.4974 - val_accuracy: 0.5996\n",
      "Epoch 57/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.4520 - accuracy: 0.6118 - val_loss: 1.4862 - val_accuracy: 0.6033\n",
      "Epoch 58/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.4431 - accuracy: 0.6144 - val_loss: 1.4751 - val_accuracy: 0.6048\n",
      "Epoch 59/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.4345 - accuracy: 0.6164 - val_loss: 1.4647 - val_accuracy: 0.6061\n",
      "Epoch 60/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.4256 - accuracy: 0.6204 - val_loss: 1.4543 - val_accuracy: 0.6106\n",
      "Epoch 61/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.4173 - accuracy: 0.6234 - val_loss: 1.4441 - val_accuracy: 0.6121\n",
      "Epoch 62/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.4086 - accuracy: 0.6245 - val_loss: 1.4343 - val_accuracy: 0.6151\n",
      "Epoch 63/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.4005 - accuracy: 0.6275 - val_loss: 1.4253 - val_accuracy: 0.6173\n",
      "Epoch 64/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.3927 - accuracy: 0.6294 - val_loss: 1.4157 - val_accuracy: 0.6207\n",
      "Epoch 65/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.3847 - accuracy: 0.6324 - val_loss: 1.4067 - val_accuracy: 0.6214\n",
      "Epoch 66/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.3767 - accuracy: 0.6344 - val_loss: 1.3977 - val_accuracy: 0.6239\n",
      "Epoch 67/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.3692 - accuracy: 0.6376 - val_loss: 1.3891 - val_accuracy: 0.6259\n",
      "Epoch 68/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.3618 - accuracy: 0.6392 - val_loss: 1.3812 - val_accuracy: 0.6286\n",
      "Epoch 69/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.3542 - accuracy: 0.6406 - val_loss: 1.3734 - val_accuracy: 0.6307\n",
      "Epoch 70/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.3470 - accuracy: 0.6443 - val_loss: 1.3652 - val_accuracy: 0.6312\n",
      "Epoch 71/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.3399 - accuracy: 0.6460 - val_loss: 1.3576 - val_accuracy: 0.6342\n",
      "Epoch 72/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.3328 - accuracy: 0.6475 - val_loss: 1.3501 - val_accuracy: 0.6359\n",
      "Epoch 73/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.3261 - accuracy: 0.6494 - val_loss: 1.3427 - val_accuracy: 0.6366\n",
      "Epoch 74/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.3194 - accuracy: 0.6515 - val_loss: 1.3360 - val_accuracy: 0.6398\n",
      "Epoch 75/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.3127 - accuracy: 0.6537 - val_loss: 1.3286 - val_accuracy: 0.6412\n",
      "Epoch 76/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.3060 - accuracy: 0.6545 - val_loss: 1.3218 - val_accuracy: 0.6437\n",
      "Epoch 77/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.2996 - accuracy: 0.6564 - val_loss: 1.3152 - val_accuracy: 0.6450\n",
      "Epoch 78/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.2935 - accuracy: 0.6577 - val_loss: 1.3090 - val_accuracy: 0.6484\n",
      "Epoch 79/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.2872 - accuracy: 0.6605 - val_loss: 1.3028 - val_accuracy: 0.6486\n",
      "Epoch 80/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.2813 - accuracy: 0.6620 - val_loss: 1.2964 - val_accuracy: 0.6509\n",
      "Epoch 81/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.2751 - accuracy: 0.6631 - val_loss: 1.2897 - val_accuracy: 0.6527\n",
      "Epoch 82/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.2691 - accuracy: 0.6646 - val_loss: 1.2837 - val_accuracy: 0.6546\n",
      "Epoch 83/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.2632 - accuracy: 0.6662 - val_loss: 1.2778 - val_accuracy: 0.6544\n",
      "Epoch 84/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.2576 - accuracy: 0.6672 - val_loss: 1.2722 - val_accuracy: 0.6564\n",
      "Epoch 85/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.2521 - accuracy: 0.6695 - val_loss: 1.2670 - val_accuracy: 0.6583\n",
      "Epoch 86/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.2465 - accuracy: 0.6705 - val_loss: 1.2616 - val_accuracy: 0.6581\n",
      "Epoch 87/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.2412 - accuracy: 0.6722 - val_loss: 1.2562 - val_accuracy: 0.6614\n",
      "Epoch 88/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.2357 - accuracy: 0.6728 - val_loss: 1.2506 - val_accuracy: 0.6633\n",
      "Epoch 89/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.2304 - accuracy: 0.6742 - val_loss: 1.2453 - val_accuracy: 0.6634\n",
      "Epoch 90/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.2253 - accuracy: 0.6750 - val_loss: 1.2404 - val_accuracy: 0.6659\n",
      "Epoch 91/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.2203 - accuracy: 0.6764 - val_loss: 1.2350 - val_accuracy: 0.6672\n",
      "Epoch 92/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.2149 - accuracy: 0.6773 - val_loss: 1.2303 - val_accuracy: 0.6676\n",
      "Epoch 93/400\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 1.2102 - accuracy: 0.6788 - val_loss: 1.2255 - val_accuracy: 0.6688\n",
      "Epoch 94/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.2050 - accuracy: 0.6792 - val_loss: 1.2205 - val_accuracy: 0.6711\n",
      "Epoch 95/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.2004 - accuracy: 0.6815 - val_loss: 1.2162 - val_accuracy: 0.6704\n",
      "Epoch 96/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.1959 - accuracy: 0.6820 - val_loss: 1.2112 - val_accuracy: 0.6728\n",
      "Epoch 97/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.1909 - accuracy: 0.6838 - val_loss: 1.2067 - val_accuracy: 0.6736\n",
      "Epoch 98/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1864 - accuracy: 0.6846 - val_loss: 1.2024 - val_accuracy: 0.6758\n",
      "Epoch 99/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1818 - accuracy: 0.6855 - val_loss: 1.1988 - val_accuracy: 0.6749\n",
      "Epoch 100/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.1773 - accuracy: 0.6874 - val_loss: 1.1936 - val_accuracy: 0.6769\n",
      "Epoch 101/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.1729 - accuracy: 0.6889 - val_loss: 1.1896 - val_accuracy: 0.6784\n",
      "Epoch 102/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.1687 - accuracy: 0.6890 - val_loss: 1.1849 - val_accuracy: 0.6798\n",
      "Epoch 103/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.1645 - accuracy: 0.6903 - val_loss: 1.1817 - val_accuracy: 0.6803\n",
      "Epoch 104/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1601 - accuracy: 0.6907 - val_loss: 1.1768 - val_accuracy: 0.6813\n",
      "Epoch 105/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.1559 - accuracy: 0.6915 - val_loss: 1.1732 - val_accuracy: 0.6824\n",
      "Epoch 106/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1518 - accuracy: 0.6927 - val_loss: 1.1692 - val_accuracy: 0.6842\n",
      "Epoch 107/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1479 - accuracy: 0.6941 - val_loss: 1.1655 - val_accuracy: 0.6842\n",
      "Epoch 108/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.1438 - accuracy: 0.6950 - val_loss: 1.1615 - val_accuracy: 0.6863\n",
      "Epoch 109/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1398 - accuracy: 0.6955 - val_loss: 1.1582 - val_accuracy: 0.6859\n",
      "Epoch 110/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.1357 - accuracy: 0.6969 - val_loss: 1.1542 - val_accuracy: 0.6886\n",
      "Epoch 111/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1324 - accuracy: 0.6978 - val_loss: 1.1506 - val_accuracy: 0.6886\n",
      "Epoch 112/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.1286 - accuracy: 0.6982 - val_loss: 1.1473 - val_accuracy: 0.6900\n",
      "Epoch 113/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1243 - accuracy: 0.6997 - val_loss: 1.1432 - val_accuracy: 0.6905\n",
      "Epoch 114/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.1207 - accuracy: 0.6999 - val_loss: 1.1397 - val_accuracy: 0.6923\n",
      "Epoch 115/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1170 - accuracy: 0.7012 - val_loss: 1.1366 - val_accuracy: 0.6922\n",
      "Epoch 116/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.1136 - accuracy: 0.7023 - val_loss: 1.1333 - val_accuracy: 0.6936\n",
      "Epoch 117/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1100 - accuracy: 0.7024 - val_loss: 1.1294 - val_accuracy: 0.6941\n",
      "Epoch 118/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1066 - accuracy: 0.7029 - val_loss: 1.1261 - val_accuracy: 0.6949\n",
      "Epoch 119/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1030 - accuracy: 0.7042 - val_loss: 1.1229 - val_accuracy: 0.6963\n",
      "Epoch 120/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0997 - accuracy: 0.7058 - val_loss: 1.1199 - val_accuracy: 0.6971\n",
      "Epoch 121/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0966 - accuracy: 0.7059 - val_loss: 1.1166 - val_accuracy: 0.6968\n",
      "Epoch 122/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0930 - accuracy: 0.7064 - val_loss: 1.1133 - val_accuracy: 0.6986\n",
      "Epoch 123/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0896 - accuracy: 0.7082 - val_loss: 1.1103 - val_accuracy: 0.6995\n",
      "Epoch 124/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0862 - accuracy: 0.7094 - val_loss: 1.1075 - val_accuracy: 0.7009\n",
      "Epoch 125/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.0829 - accuracy: 0.7085 - val_loss: 1.1043 - val_accuracy: 0.7013\n",
      "Epoch 126/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0798 - accuracy: 0.7101 - val_loss: 1.1012 - val_accuracy: 0.7016\n",
      "Epoch 127/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0767 - accuracy: 0.7115 - val_loss: 1.0981 - val_accuracy: 0.7032\n",
      "Epoch 128/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0735 - accuracy: 0.7122 - val_loss: 1.0953 - val_accuracy: 0.7034\n",
      "Epoch 129/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0707 - accuracy: 0.7125 - val_loss: 1.0925 - val_accuracy: 0.7040\n",
      "Epoch 130/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0677 - accuracy: 0.7137 - val_loss: 1.0898 - val_accuracy: 0.7050\n",
      "Epoch 131/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.0644 - accuracy: 0.7148 - val_loss: 1.0865 - val_accuracy: 0.7064\n",
      "Epoch 132/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0613 - accuracy: 0.7147 - val_loss: 1.0839 - val_accuracy: 0.7070\n",
      "Epoch 133/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.0587 - accuracy: 0.7157 - val_loss: 1.0809 - val_accuracy: 0.7075\n",
      "Epoch 134/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0556 - accuracy: 0.7166 - val_loss: 1.0784 - val_accuracy: 0.7082\n",
      "Epoch 135/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0528 - accuracy: 0.7180 - val_loss: 1.0758 - val_accuracy: 0.7089\n",
      "Epoch 136/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.0499 - accuracy: 0.7180 - val_loss: 1.0729 - val_accuracy: 0.7100\n",
      "Epoch 137/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0471 - accuracy: 0.7193 - val_loss: 1.0708 - val_accuracy: 0.7098\n",
      "Epoch 138/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0442 - accuracy: 0.7190 - val_loss: 1.0680 - val_accuracy: 0.7098\n",
      "Epoch 139/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0412 - accuracy: 0.7208 - val_loss: 1.0653 - val_accuracy: 0.7118\n",
      "Epoch 140/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0387 - accuracy: 0.7212 - val_loss: 1.0630 - val_accuracy: 0.7121\n",
      "Epoch 141/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0359 - accuracy: 0.7210 - val_loss: 1.0606 - val_accuracy: 0.7129\n",
      "Epoch 142/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0335 - accuracy: 0.7215 - val_loss: 1.0581 - val_accuracy: 0.7135\n",
      "Epoch 143/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0308 - accuracy: 0.7228 - val_loss: 1.0555 - val_accuracy: 0.7139\n",
      "Epoch 144/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0280 - accuracy: 0.7235 - val_loss: 1.0529 - val_accuracy: 0.7143\n",
      "Epoch 145/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0258 - accuracy: 0.7232 - val_loss: 1.0509 - val_accuracy: 0.7154\n",
      "Epoch 146/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0231 - accuracy: 0.7260 - val_loss: 1.0482 - val_accuracy: 0.7160\n",
      "Epoch 147/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0203 - accuracy: 0.7256 - val_loss: 1.0459 - val_accuracy: 0.7161\n",
      "Epoch 148/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0178 - accuracy: 0.7259 - val_loss: 1.0438 - val_accuracy: 0.7173\n",
      "Epoch 149/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.0155 - accuracy: 0.7261 - val_loss: 1.0411 - val_accuracy: 0.7179\n",
      "Epoch 150/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0128 - accuracy: 0.7275 - val_loss: 1.0387 - val_accuracy: 0.7181\n",
      "Epoch 151/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0102 - accuracy: 0.7277 - val_loss: 1.0367 - val_accuracy: 0.7182\n",
      "Epoch 152/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0080 - accuracy: 0.7277 - val_loss: 1.0347 - val_accuracy: 0.7185\n",
      "Epoch 153/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0058 - accuracy: 0.7287 - val_loss: 1.0325 - val_accuracy: 0.7178\n",
      "Epoch 154/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.0030 - accuracy: 0.7295 - val_loss: 1.0300 - val_accuracy: 0.7202\n",
      "Epoch 155/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0009 - accuracy: 0.7303 - val_loss: 1.0281 - val_accuracy: 0.7197\n",
      "Epoch 156/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9986 - accuracy: 0.7310 - val_loss: 1.0260 - val_accuracy: 0.7204\n",
      "Epoch 157/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.9960 - accuracy: 0.7315 - val_loss: 1.0237 - val_accuracy: 0.7203\n",
      "Epoch 158/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9936 - accuracy: 0.7320 - val_loss: 1.0220 - val_accuracy: 0.7210\n",
      "Epoch 159/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9914 - accuracy: 0.7314 - val_loss: 1.0196 - val_accuracy: 0.7212\n",
      "Epoch 160/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9893 - accuracy: 0.7334 - val_loss: 1.0174 - val_accuracy: 0.7219\n",
      "Epoch 161/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9868 - accuracy: 0.7339 - val_loss: 1.0153 - val_accuracy: 0.7227\n",
      "Epoch 162/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9844 - accuracy: 0.7343 - val_loss: 1.0136 - val_accuracy: 0.7227\n",
      "Epoch 163/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.9827 - accuracy: 0.7350 - val_loss: 1.0112 - val_accuracy: 0.7234\n",
      "Epoch 164/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9804 - accuracy: 0.7352 - val_loss: 1.0097 - val_accuracy: 0.7233\n",
      "Epoch 165/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9781 - accuracy: 0.7365 - val_loss: 1.0075 - val_accuracy: 0.7236\n",
      "Epoch 166/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9761 - accuracy: 0.7359 - val_loss: 1.0056 - val_accuracy: 0.7249\n",
      "Epoch 167/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.9740 - accuracy: 0.7370 - val_loss: 1.0038 - val_accuracy: 0.7247\n",
      "Epoch 168/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.9718 - accuracy: 0.7375 - val_loss: 1.0016 - val_accuracy: 0.7254\n",
      "Epoch 169/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9696 - accuracy: 0.7379 - val_loss: 0.9999 - val_accuracy: 0.7261\n",
      "Epoch 170/400\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.9676 - accuracy: 0.7385 - val_loss: 0.9982 - val_accuracy: 0.7259\n",
      "Epoch 171/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9654 - accuracy: 0.7383 - val_loss: 0.9964 - val_accuracy: 0.7269\n",
      "Epoch 172/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9634 - accuracy: 0.7397 - val_loss: 0.9943 - val_accuracy: 0.7268\n",
      "Epoch 173/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9616 - accuracy: 0.7402 - val_loss: 0.9924 - val_accuracy: 0.7286\n",
      "Epoch 174/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9596 - accuracy: 0.7403 - val_loss: 0.9906 - val_accuracy: 0.7289\n",
      "Epoch 175/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.9575 - accuracy: 0.7413 - val_loss: 0.9891 - val_accuracy: 0.7291\n",
      "Epoch 176/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.9553 - accuracy: 0.7409 - val_loss: 0.9869 - val_accuracy: 0.7299\n",
      "Epoch 177/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.9529 - accuracy: 0.7422 - val_loss: 0.9856 - val_accuracy: 0.7306\n",
      "Epoch 178/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.9516 - accuracy: 0.7419 - val_loss: 0.9834 - val_accuracy: 0.7307\n",
      "Epoch 179/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.9495 - accuracy: 0.7431 - val_loss: 0.9820 - val_accuracy: 0.7302\n",
      "Epoch 180/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9478 - accuracy: 0.7435 - val_loss: 0.9799 - val_accuracy: 0.7313\n",
      "Epoch 181/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9456 - accuracy: 0.7440 - val_loss: 0.9783 - val_accuracy: 0.7319\n",
      "Epoch 182/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.9438 - accuracy: 0.7441 - val_loss: 0.9769 - val_accuracy: 0.7314\n",
      "Epoch 183/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.9420 - accuracy: 0.7452 - val_loss: 0.9751 - val_accuracy: 0.7319\n",
      "Epoch 184/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.9402 - accuracy: 0.7453 - val_loss: 0.9733 - val_accuracy: 0.7322\n",
      "Epoch 185/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9382 - accuracy: 0.7463 - val_loss: 0.9717 - val_accuracy: 0.7328\n",
      "Epoch 186/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.9362 - accuracy: 0.7469 - val_loss: 0.9701 - val_accuracy: 0.7332\n",
      "Epoch 187/400\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.9347 - accuracy: 0.7467 - val_loss: 0.9686 - val_accuracy: 0.7331\n",
      "Epoch 188/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9328 - accuracy: 0.7475 - val_loss: 0.9669 - val_accuracy: 0.7335\n",
      "Epoch 189/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9310 - accuracy: 0.7477 - val_loss: 0.9652 - val_accuracy: 0.7343\n",
      "Epoch 190/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9291 - accuracy: 0.7477 - val_loss: 0.9638 - val_accuracy: 0.7349\n",
      "Epoch 191/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9272 - accuracy: 0.7492 - val_loss: 0.9620 - val_accuracy: 0.7356\n",
      "Epoch 192/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.9256 - accuracy: 0.7501 - val_loss: 0.9608 - val_accuracy: 0.7348\n",
      "Epoch 193/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9239 - accuracy: 0.7497 - val_loss: 0.9592 - val_accuracy: 0.7359\n",
      "Epoch 194/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9220 - accuracy: 0.7501 - val_loss: 0.9576 - val_accuracy: 0.7367\n",
      "Epoch 195/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.9203 - accuracy: 0.7506 - val_loss: 0.9558 - val_accuracy: 0.7379\n",
      "Epoch 196/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9183 - accuracy: 0.7516 - val_loss: 0.9547 - val_accuracy: 0.7366\n",
      "Epoch 197/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9172 - accuracy: 0.7509 - val_loss: 0.9533 - val_accuracy: 0.7363\n",
      "Epoch 198/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9151 - accuracy: 0.7521 - val_loss: 0.9516 - val_accuracy: 0.7377\n",
      "Epoch 199/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9135 - accuracy: 0.7526 - val_loss: 0.9499 - val_accuracy: 0.7379\n",
      "Epoch 200/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9117 - accuracy: 0.7529 - val_loss: 0.9490 - val_accuracy: 0.7383\n",
      "Epoch 201/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9102 - accuracy: 0.7529 - val_loss: 0.9474 - val_accuracy: 0.7387\n",
      "Epoch 202/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.9083 - accuracy: 0.7537 - val_loss: 0.9456 - val_accuracy: 0.7393\n",
      "Epoch 203/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.9070 - accuracy: 0.7540 - val_loss: 0.9441 - val_accuracy: 0.7392\n",
      "Epoch 204/400\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.9052 - accuracy: 0.7542 - val_loss: 0.9430 - val_accuracy: 0.7392\n",
      "Epoch 205/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.9037 - accuracy: 0.7550 - val_loss: 0.9414 - val_accuracy: 0.7407\n",
      "Epoch 206/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9020 - accuracy: 0.7555 - val_loss: 0.9399 - val_accuracy: 0.7412\n",
      "Epoch 207/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9004 - accuracy: 0.7559 - val_loss: 0.9386 - val_accuracy: 0.7401\n",
      "Epoch 208/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8988 - accuracy: 0.7560 - val_loss: 0.9371 - val_accuracy: 0.7413\n",
      "Epoch 209/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8972 - accuracy: 0.7563 - val_loss: 0.9359 - val_accuracy: 0.7417\n",
      "Epoch 210/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8956 - accuracy: 0.7569 - val_loss: 0.9346 - val_accuracy: 0.7416\n",
      "Epoch 211/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8940 - accuracy: 0.7575 - val_loss: 0.9331 - val_accuracy: 0.7423\n",
      "Epoch 212/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8926 - accuracy: 0.7578 - val_loss: 0.9319 - val_accuracy: 0.7419\n",
      "Epoch 213/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8908 - accuracy: 0.7578 - val_loss: 0.9302 - val_accuracy: 0.7428\n",
      "Epoch 214/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8899 - accuracy: 0.7585 - val_loss: 0.9288 - val_accuracy: 0.7432\n",
      "Epoch 215/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8878 - accuracy: 0.7591 - val_loss: 0.9278 - val_accuracy: 0.7436\n",
      "Epoch 216/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8865 - accuracy: 0.7595 - val_loss: 0.9263 - val_accuracy: 0.7433\n",
      "Epoch 217/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8848 - accuracy: 0.7597 - val_loss: 0.9252 - val_accuracy: 0.7437\n",
      "Epoch 218/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8833 - accuracy: 0.7600 - val_loss: 0.9240 - val_accuracy: 0.7442\n",
      "Epoch 219/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.8817 - accuracy: 0.7616 - val_loss: 0.9223 - val_accuracy: 0.7448\n",
      "Epoch 220/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8802 - accuracy: 0.7609 - val_loss: 0.9209 - val_accuracy: 0.7452\n",
      "Epoch 221/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8788 - accuracy: 0.7614 - val_loss: 0.9198 - val_accuracy: 0.7455\n",
      "Epoch 222/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8773 - accuracy: 0.7618 - val_loss: 0.9187 - val_accuracy: 0.7459\n",
      "Epoch 223/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8760 - accuracy: 0.7613 - val_loss: 0.9173 - val_accuracy: 0.7467\n",
      "Epoch 224/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.8746 - accuracy: 0.7621 - val_loss: 0.9161 - val_accuracy: 0.7468\n",
      "Epoch 225/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8730 - accuracy: 0.7626 - val_loss: 0.9152 - val_accuracy: 0.7470\n",
      "Epoch 226/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8717 - accuracy: 0.7618 - val_loss: 0.9142 - val_accuracy: 0.7468\n",
      "Epoch 227/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.8703 - accuracy: 0.7640 - val_loss: 0.9124 - val_accuracy: 0.7476\n",
      "Epoch 228/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8686 - accuracy: 0.7646 - val_loss: 0.9114 - val_accuracy: 0.7478\n",
      "Epoch 229/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8675 - accuracy: 0.7642 - val_loss: 0.9102 - val_accuracy: 0.7487\n",
      "Epoch 230/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.8660 - accuracy: 0.7645 - val_loss: 0.9089 - val_accuracy: 0.7484\n",
      "Epoch 231/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8641 - accuracy: 0.7654 - val_loss: 0.9079 - val_accuracy: 0.7489\n",
      "Epoch 232/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8630 - accuracy: 0.7651 - val_loss: 0.9066 - val_accuracy: 0.7490\n",
      "Epoch 233/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8619 - accuracy: 0.7659 - val_loss: 0.9053 - val_accuracy: 0.7491\n",
      "Epoch 234/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8602 - accuracy: 0.7666 - val_loss: 0.9041 - val_accuracy: 0.7493\n",
      "Epoch 235/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8587 - accuracy: 0.7667 - val_loss: 0.9029 - val_accuracy: 0.7501\n",
      "Epoch 236/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8576 - accuracy: 0.7669 - val_loss: 0.9019 - val_accuracy: 0.7504\n",
      "Epoch 237/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.8563 - accuracy: 0.7668 - val_loss: 0.9008 - val_accuracy: 0.7504\n",
      "Epoch 238/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8552 - accuracy: 0.7681 - val_loss: 0.8994 - val_accuracy: 0.7506\n",
      "Epoch 239/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8535 - accuracy: 0.7681 - val_loss: 0.8990 - val_accuracy: 0.7511\n",
      "Epoch 240/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8524 - accuracy: 0.7684 - val_loss: 0.8971 - val_accuracy: 0.7514\n",
      "Epoch 241/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8508 - accuracy: 0.7690 - val_loss: 0.8959 - val_accuracy: 0.7505\n",
      "Epoch 242/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8497 - accuracy: 0.7685 - val_loss: 0.8949 - val_accuracy: 0.7518\n",
      "Epoch 243/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8485 - accuracy: 0.7692 - val_loss: 0.8938 - val_accuracy: 0.7522\n",
      "Epoch 244/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8471 - accuracy: 0.7696 - val_loss: 0.8930 - val_accuracy: 0.7520\n",
      "Epoch 245/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8457 - accuracy: 0.7701 - val_loss: 0.8916 - val_accuracy: 0.7521\n",
      "Epoch 246/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8442 - accuracy: 0.7708 - val_loss: 0.8905 - val_accuracy: 0.7528\n",
      "Epoch 247/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8429 - accuracy: 0.7703 - val_loss: 0.8895 - val_accuracy: 0.7529\n",
      "Epoch 248/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8414 - accuracy: 0.7715 - val_loss: 0.8883 - val_accuracy: 0.7532\n",
      "Epoch 249/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8405 - accuracy: 0.7713 - val_loss: 0.8873 - val_accuracy: 0.7536\n",
      "Epoch 250/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.8392 - accuracy: 0.7718 - val_loss: 0.8863 - val_accuracy: 0.7540\n",
      "Epoch 251/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8381 - accuracy: 0.7729 - val_loss: 0.8849 - val_accuracy: 0.7542\n",
      "Epoch 252/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.8369 - accuracy: 0.7731 - val_loss: 0.8840 - val_accuracy: 0.7542\n",
      "Epoch 253/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8355 - accuracy: 0.7730 - val_loss: 0.8828 - val_accuracy: 0.7550\n",
      "Epoch 254/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8341 - accuracy: 0.7743 - val_loss: 0.8820 - val_accuracy: 0.7543\n",
      "Epoch 255/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8331 - accuracy: 0.7739 - val_loss: 0.8808 - val_accuracy: 0.7550\n",
      "Epoch 256/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8318 - accuracy: 0.7732 - val_loss: 0.8797 - val_accuracy: 0.7553\n",
      "Epoch 257/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8310 - accuracy: 0.7741 - val_loss: 0.8791 - val_accuracy: 0.7561\n",
      "Epoch 258/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8294 - accuracy: 0.7744 - val_loss: 0.8775 - val_accuracy: 0.7559\n",
      "Epoch 259/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8280 - accuracy: 0.7752 - val_loss: 0.8767 - val_accuracy: 0.7562\n",
      "Epoch 260/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8269 - accuracy: 0.7751 - val_loss: 0.8757 - val_accuracy: 0.7564\n",
      "Epoch 261/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8259 - accuracy: 0.7753 - val_loss: 0.8755 - val_accuracy: 0.7557\n",
      "Epoch 262/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8245 - accuracy: 0.7772 - val_loss: 0.8738 - val_accuracy: 0.7561\n",
      "Epoch 263/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8234 - accuracy: 0.7763 - val_loss: 0.8725 - val_accuracy: 0.7564\n",
      "Epoch 264/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.8220 - accuracy: 0.7766 - val_loss: 0.8715 - val_accuracy: 0.7568\n",
      "Epoch 265/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8208 - accuracy: 0.7774 - val_loss: 0.8710 - val_accuracy: 0.7583\n",
      "Epoch 266/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8197 - accuracy: 0.7775 - val_loss: 0.8698 - val_accuracy: 0.7578\n",
      "Epoch 267/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8186 - accuracy: 0.7778 - val_loss: 0.8692 - val_accuracy: 0.7582\n",
      "Epoch 268/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8177 - accuracy: 0.7776 - val_loss: 0.8679 - val_accuracy: 0.7576\n",
      "Epoch 269/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8162 - accuracy: 0.7778 - val_loss: 0.8668 - val_accuracy: 0.7584\n",
      "Epoch 270/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.8149 - accuracy: 0.7788 - val_loss: 0.8655 - val_accuracy: 0.7586\n",
      "Epoch 271/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8137 - accuracy: 0.7793 - val_loss: 0.8649 - val_accuracy: 0.7584\n",
      "Epoch 272/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8130 - accuracy: 0.7792 - val_loss: 0.8635 - val_accuracy: 0.7587\n",
      "Epoch 273/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8117 - accuracy: 0.7800 - val_loss: 0.8629 - val_accuracy: 0.7592\n",
      "Epoch 274/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8105 - accuracy: 0.7795 - val_loss: 0.8621 - val_accuracy: 0.7591\n",
      "Epoch 275/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8093 - accuracy: 0.7803 - val_loss: 0.8612 - val_accuracy: 0.7599\n",
      "Epoch 276/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8085 - accuracy: 0.7808 - val_loss: 0.8603 - val_accuracy: 0.7594\n",
      "Epoch 277/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8073 - accuracy: 0.7804 - val_loss: 0.8591 - val_accuracy: 0.7601\n",
      "Epoch 278/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8057 - accuracy: 0.7810 - val_loss: 0.8582 - val_accuracy: 0.7609\n",
      "Epoch 279/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8047 - accuracy: 0.7819 - val_loss: 0.8570 - val_accuracy: 0.7611\n",
      "Epoch 280/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8036 - accuracy: 0.7822 - val_loss: 0.8561 - val_accuracy: 0.7611\n",
      "Epoch 281/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8028 - accuracy: 0.7824 - val_loss: 0.8555 - val_accuracy: 0.7612\n",
      "Epoch 282/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8016 - accuracy: 0.7827 - val_loss: 0.8548 - val_accuracy: 0.7623\n",
      "Epoch 283/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8001 - accuracy: 0.7834 - val_loss: 0.8538 - val_accuracy: 0.7623\n",
      "Epoch 284/400\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.7988 - accuracy: 0.7832 - val_loss: 0.8527 - val_accuracy: 0.7625\n",
      "Epoch 285/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7981 - accuracy: 0.7831 - val_loss: 0.8519 - val_accuracy: 0.7623\n",
      "Epoch 286/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7974 - accuracy: 0.7844 - val_loss: 0.8508 - val_accuracy: 0.7624\n",
      "Epoch 287/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7963 - accuracy: 0.7838 - val_loss: 0.8499 - val_accuracy: 0.7626\n",
      "Epoch 288/400\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.7951 - accuracy: 0.7848 - val_loss: 0.8493 - val_accuracy: 0.7628\n",
      "Epoch 289/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7936 - accuracy: 0.7840 - val_loss: 0.8479 - val_accuracy: 0.7638\n",
      "Epoch 290/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7927 - accuracy: 0.7850 - val_loss: 0.8478 - val_accuracy: 0.7632\n",
      "Epoch 291/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.7915 - accuracy: 0.7849 - val_loss: 0.8466 - val_accuracy: 0.7634\n",
      "Epoch 292/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7907 - accuracy: 0.7862 - val_loss: 0.8456 - val_accuracy: 0.7638\n",
      "Epoch 293/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7898 - accuracy: 0.7864 - val_loss: 0.8448 - val_accuracy: 0.7642\n",
      "Epoch 294/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7884 - accuracy: 0.7865 - val_loss: 0.8439 - val_accuracy: 0.7649\n",
      "Epoch 295/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7872 - accuracy: 0.7867 - val_loss: 0.8433 - val_accuracy: 0.7643\n",
      "Epoch 296/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7866 - accuracy: 0.7872 - val_loss: 0.8419 - val_accuracy: 0.7656\n",
      "Epoch 297/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.7854 - accuracy: 0.7867 - val_loss: 0.8412 - val_accuracy: 0.7651\n",
      "Epoch 298/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.7844 - accuracy: 0.7878 - val_loss: 0.8403 - val_accuracy: 0.7655\n",
      "Epoch 299/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7834 - accuracy: 0.7883 - val_loss: 0.8396 - val_accuracy: 0.7649\n",
      "Epoch 300/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7823 - accuracy: 0.7878 - val_loss: 0.8389 - val_accuracy: 0.7656\n",
      "Epoch 301/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7812 - accuracy: 0.7885 - val_loss: 0.8377 - val_accuracy: 0.7657\n",
      "Epoch 302/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7802 - accuracy: 0.7888 - val_loss: 0.8374 - val_accuracy: 0.7671\n",
      "Epoch 303/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7792 - accuracy: 0.7886 - val_loss: 0.8363 - val_accuracy: 0.7669\n",
      "Epoch 304/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.7783 - accuracy: 0.7893 - val_loss: 0.8359 - val_accuracy: 0.7672\n",
      "Epoch 305/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7772 - accuracy: 0.7894 - val_loss: 0.8344 - val_accuracy: 0.7679\n",
      "Epoch 306/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7762 - accuracy: 0.7900 - val_loss: 0.8340 - val_accuracy: 0.7673\n",
      "Epoch 307/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7753 - accuracy: 0.7900 - val_loss: 0.8330 - val_accuracy: 0.7675\n",
      "Epoch 308/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7740 - accuracy: 0.7911 - val_loss: 0.8320 - val_accuracy: 0.7672\n",
      "Epoch 309/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7732 - accuracy: 0.7899 - val_loss: 0.8316 - val_accuracy: 0.7678\n",
      "Epoch 310/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7723 - accuracy: 0.7911 - val_loss: 0.8305 - val_accuracy: 0.7676\n",
      "Epoch 311/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7710 - accuracy: 0.7919 - val_loss: 0.8299 - val_accuracy: 0.7686\n",
      "Epoch 312/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7705 - accuracy: 0.7915 - val_loss: 0.8290 - val_accuracy: 0.7687\n",
      "Epoch 313/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7692 - accuracy: 0.7919 - val_loss: 0.8283 - val_accuracy: 0.7693\n",
      "Epoch 314/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7683 - accuracy: 0.7922 - val_loss: 0.8272 - val_accuracy: 0.7692\n",
      "Epoch 315/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7673 - accuracy: 0.7929 - val_loss: 0.8270 - val_accuracy: 0.7691\n",
      "Epoch 316/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7664 - accuracy: 0.7923 - val_loss: 0.8260 - val_accuracy: 0.7691\n",
      "Epoch 317/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7656 - accuracy: 0.7936 - val_loss: 0.8255 - val_accuracy: 0.7693\n",
      "Epoch 318/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7647 - accuracy: 0.7930 - val_loss: 0.8245 - val_accuracy: 0.7697\n",
      "Epoch 319/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7635 - accuracy: 0.7932 - val_loss: 0.8236 - val_accuracy: 0.7699\n",
      "Epoch 320/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7625 - accuracy: 0.7944 - val_loss: 0.8232 - val_accuracy: 0.7693\n",
      "Epoch 321/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7618 - accuracy: 0.7944 - val_loss: 0.8221 - val_accuracy: 0.7704\n",
      "Epoch 322/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.7606 - accuracy: 0.7938 - val_loss: 0.8218 - val_accuracy: 0.7699\n",
      "Epoch 323/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7596 - accuracy: 0.7948 - val_loss: 0.8204 - val_accuracy: 0.7712\n",
      "Epoch 324/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7591 - accuracy: 0.7953 - val_loss: 0.8199 - val_accuracy: 0.7707\n",
      "Epoch 325/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7577 - accuracy: 0.7953 - val_loss: 0.8188 - val_accuracy: 0.7710\n",
      "Epoch 326/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7571 - accuracy: 0.7956 - val_loss: 0.8181 - val_accuracy: 0.7714\n",
      "Epoch 327/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7564 - accuracy: 0.7960 - val_loss: 0.8175 - val_accuracy: 0.7714\n",
      "Epoch 328/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7556 - accuracy: 0.7959 - val_loss: 0.8170 - val_accuracy: 0.7716\n",
      "Epoch 329/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7542 - accuracy: 0.7964 - val_loss: 0.8160 - val_accuracy: 0.7710\n",
      "Epoch 330/400\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.7536 - accuracy: 0.7962 - val_loss: 0.8151 - val_accuracy: 0.7723\n",
      "Epoch 331/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7526 - accuracy: 0.7971 - val_loss: 0.8145 - val_accuracy: 0.7724\n",
      "Epoch 332/400\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.7515 - accuracy: 0.7965 - val_loss: 0.8137 - val_accuracy: 0.7727\n",
      "Epoch 333/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7508 - accuracy: 0.7969 - val_loss: 0.8130 - val_accuracy: 0.7724\n",
      "Epoch 334/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7494 - accuracy: 0.7975 - val_loss: 0.8127 - val_accuracy: 0.7730\n",
      "Epoch 335/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7488 - accuracy: 0.7975 - val_loss: 0.8113 - val_accuracy: 0.7738\n",
      "Epoch 336/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7476 - accuracy: 0.7984 - val_loss: 0.8109 - val_accuracy: 0.7738\n",
      "Epoch 337/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7468 - accuracy: 0.7985 - val_loss: 0.8108 - val_accuracy: 0.7732\n",
      "Epoch 338/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7464 - accuracy: 0.7975 - val_loss: 0.8094 - val_accuracy: 0.7741\n",
      "Epoch 339/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7451 - accuracy: 0.7992 - val_loss: 0.8086 - val_accuracy: 0.7742\n",
      "Epoch 340/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.7445 - accuracy: 0.7988 - val_loss: 0.8080 - val_accuracy: 0.7738\n",
      "Epoch 341/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7433 - accuracy: 0.7998 - val_loss: 0.8073 - val_accuracy: 0.7744\n",
      "Epoch 342/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7426 - accuracy: 0.7993 - val_loss: 0.8066 - val_accuracy: 0.7751\n",
      "Epoch 343/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7416 - accuracy: 0.7993 - val_loss: 0.8058 - val_accuracy: 0.7751\n",
      "Epoch 344/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7409 - accuracy: 0.7994 - val_loss: 0.8051 - val_accuracy: 0.7744\n",
      "Epoch 345/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7398 - accuracy: 0.8003 - val_loss: 0.8046 - val_accuracy: 0.7756\n",
      "Epoch 346/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.7393 - accuracy: 0.8000 - val_loss: 0.8036 - val_accuracy: 0.7756\n",
      "Epoch 347/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7386 - accuracy: 0.8010 - val_loss: 0.8036 - val_accuracy: 0.7757\n",
      "Epoch 348/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7373 - accuracy: 0.8015 - val_loss: 0.8029 - val_accuracy: 0.7754\n",
      "Epoch 349/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.7363 - accuracy: 0.8020 - val_loss: 0.8016 - val_accuracy: 0.7759\n",
      "Epoch 350/400\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.7361 - accuracy: 0.8006 - val_loss: 0.8012 - val_accuracy: 0.7756\n",
      "Epoch 351/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.7346 - accuracy: 0.8016 - val_loss: 0.8002 - val_accuracy: 0.7771\n",
      "Epoch 352/400\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.7340 - accuracy: 0.8023 - val_loss: 0.8001 - val_accuracy: 0.7762\n",
      "Epoch 353/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.7331 - accuracy: 0.8021 - val_loss: 0.7992 - val_accuracy: 0.7764\n",
      "Epoch 354/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7323 - accuracy: 0.8034 - val_loss: 0.7986 - val_accuracy: 0.7769\n",
      "Epoch 355/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7314 - accuracy: 0.8027 - val_loss: 0.7979 - val_accuracy: 0.7766\n",
      "Epoch 356/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7307 - accuracy: 0.8032 - val_loss: 0.7970 - val_accuracy: 0.7779\n",
      "Epoch 357/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7297 - accuracy: 0.8038 - val_loss: 0.7969 - val_accuracy: 0.7778\n",
      "Epoch 358/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7290 - accuracy: 0.8040 - val_loss: 0.7957 - val_accuracy: 0.7774\n",
      "Epoch 359/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7282 - accuracy: 0.8040 - val_loss: 0.7950 - val_accuracy: 0.7779\n",
      "Epoch 360/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7273 - accuracy: 0.8040 - val_loss: 0.7942 - val_accuracy: 0.7787\n",
      "Epoch 361/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7265 - accuracy: 0.8044 - val_loss: 0.7939 - val_accuracy: 0.7784\n",
      "Epoch 362/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7257 - accuracy: 0.8044 - val_loss: 0.7928 - val_accuracy: 0.7792\n",
      "Epoch 363/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7249 - accuracy: 0.8041 - val_loss: 0.7925 - val_accuracy: 0.7791\n",
      "Epoch 364/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7238 - accuracy: 0.8055 - val_loss: 0.7914 - val_accuracy: 0.7794\n",
      "Epoch 365/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7230 - accuracy: 0.8050 - val_loss: 0.7910 - val_accuracy: 0.7798\n",
      "Epoch 366/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7222 - accuracy: 0.8057 - val_loss: 0.7906 - val_accuracy: 0.7798\n",
      "Epoch 367/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7220 - accuracy: 0.8054 - val_loss: 0.7896 - val_accuracy: 0.7798\n",
      "Epoch 368/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7206 - accuracy: 0.8068 - val_loss: 0.7890 - val_accuracy: 0.7797\n",
      "Epoch 369/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7199 - accuracy: 0.8067 - val_loss: 0.7885 - val_accuracy: 0.7806\n",
      "Epoch 370/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7192 - accuracy: 0.8066 - val_loss: 0.7880 - val_accuracy: 0.7799\n",
      "Epoch 371/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.7184 - accuracy: 0.8065 - val_loss: 0.7874 - val_accuracy: 0.7799\n",
      "Epoch 372/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7174 - accuracy: 0.8072 - val_loss: 0.7870 - val_accuracy: 0.7802\n",
      "Epoch 373/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7167 - accuracy: 0.8075 - val_loss: 0.7858 - val_accuracy: 0.7811\n",
      "Epoch 374/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7159 - accuracy: 0.8077 - val_loss: 0.7853 - val_accuracy: 0.7807\n",
      "Epoch 375/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7152 - accuracy: 0.8079 - val_loss: 0.7853 - val_accuracy: 0.7808\n",
      "Epoch 376/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7142 - accuracy: 0.8083 - val_loss: 0.7842 - val_accuracy: 0.7806\n",
      "Epoch 377/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7136 - accuracy: 0.8076 - val_loss: 0.7834 - val_accuracy: 0.7807\n",
      "Epoch 378/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7131 - accuracy: 0.8074 - val_loss: 0.7830 - val_accuracy: 0.7814\n",
      "Epoch 379/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7122 - accuracy: 0.8083 - val_loss: 0.7823 - val_accuracy: 0.7819\n",
      "Epoch 380/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.7111 - accuracy: 0.8088 - val_loss: 0.7816 - val_accuracy: 0.7816\n",
      "Epoch 381/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7106 - accuracy: 0.8084 - val_loss: 0.7808 - val_accuracy: 0.7822\n",
      "Epoch 382/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7094 - accuracy: 0.8091 - val_loss: 0.7810 - val_accuracy: 0.7808\n",
      "Epoch 383/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7094 - accuracy: 0.8086 - val_loss: 0.7802 - val_accuracy: 0.7818\n",
      "Epoch 384/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7083 - accuracy: 0.8094 - val_loss: 0.7796 - val_accuracy: 0.7817\n",
      "Epoch 385/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7072 - accuracy: 0.8098 - val_loss: 0.7787 - val_accuracy: 0.7822\n",
      "Epoch 386/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7065 - accuracy: 0.8103 - val_loss: 0.7783 - val_accuracy: 0.7820\n",
      "Epoch 387/400\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.7058 - accuracy: 0.8105 - val_loss: 0.7777 - val_accuracy: 0.7828\n",
      "Epoch 388/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.7049 - accuracy: 0.8106 - val_loss: 0.7769 - val_accuracy: 0.7831\n",
      "Epoch 389/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.7043 - accuracy: 0.8108 - val_loss: 0.7763 - val_accuracy: 0.7834\n",
      "Epoch 390/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.7036 - accuracy: 0.8108 - val_loss: 0.7761 - val_accuracy: 0.7827\n",
      "Epoch 391/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.7028 - accuracy: 0.8104 - val_loss: 0.7751 - val_accuracy: 0.7839\n",
      "Epoch 392/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.7020 - accuracy: 0.8112 - val_loss: 0.7745 - val_accuracy: 0.7832\n",
      "Epoch 393/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.7012 - accuracy: 0.8112 - val_loss: 0.7738 - val_accuracy: 0.7837\n",
      "Epoch 394/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.7005 - accuracy: 0.8110 - val_loss: 0.7734 - val_accuracy: 0.7837\n",
      "Epoch 395/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6998 - accuracy: 0.8115 - val_loss: 0.7730 - val_accuracy: 0.7839\n",
      "Epoch 396/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.6990 - accuracy: 0.8117 - val_loss: 0.7724 - val_accuracy: 0.7842\n",
      "Epoch 397/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6984 - accuracy: 0.8124 - val_loss: 0.7716 - val_accuracy: 0.7849\n",
      "Epoch 398/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6976 - accuracy: 0.8129 - val_loss: 0.7713 - val_accuracy: 0.7847\n",
      "Epoch 399/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6968 - accuracy: 0.8123 - val_loss: 0.7708 - val_accuracy: 0.7848\n",
      "Epoch 400/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6961 - accuracy: 0.8137 - val_loss: 0.7700 - val_accuracy: 0.7845\n",
      "\n",
      "Test loss: 0.77\n",
      "Test accuracy: 0.785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa1fb505cc0>"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "epochs = 400   # Setting up higher epoch in persuit of finding global moinima,\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)   # Set up early stopping to avoid wastage of computing power\n",
    "                                                                            # Kept patience level to 5 to check for considerable time to get out of local minima if possible\n",
    "    \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [es],\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZLd5ZmTDNPjL"
   },
   "source": [
    "Observations: The model descends very gradually and even at 400 epochs still does not seem to have reached the optimal point. We can try for more epochs but it might be wastage of resource and time so will drop this model option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gKExV6ZzOb_C"
   },
   "source": [
    "### Trying adagrad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "54qCqzdk6ZaK",
    "outputId": "8b307b7c-8a3b-406e-ddb3-c9e4f96076b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_13 (None, 1024) ==> (None, 1024)\n",
      "dense_34 (None, 1024) ==> (None, 1024)\n",
      "dense_35 (None, 1024) ==> (None, 10)\n",
      "\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_13 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,063,946\n",
      "Trainable params: 1,061,898\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(1024,))) # Set the batch normalization with input shape 32 x 32\n",
    "model.add(Dense(1024, activation='relu', input_shape=(1024,)))   #First hidden layer of 1024  neurons, each neuron takes input \n",
    "                                                               # vector of size 1024\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))            # Adding a softmax layer for output which contains as many \n",
    "                                                               # neurons as the number of classes (10) which is also the \n",
    "                                                               # the shape of each output vector ( one hot coded)\n",
    "\n",
    "                                                               # output layer also uses softmax. This normalizes the values \n",
    "                                                               # from the ten output nodes such that: \n",
    "                                                               #        all the values are between 0 and 1, and\n",
    "                                                               #        the sum of all ten values is 1.  \n",
    "                                                               # prediction is the lable of the node that gets highest fraction, is \n",
    "        \n",
    "        \n",
    "\n",
    "for l in model.layers:\n",
    "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
    "print()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Tiw8whlb6lfL",
    "outputId": "5ef0e09a-877f-41cb-babd-38fe41ebc22d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 3.1072 - accuracy: 0.1410 - val_loss: 2.4173 - val_accuracy: 0.1184\n",
      "Epoch 2/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 2.1516 - accuracy: 0.2676 - val_loss: 2.2887 - val_accuracy: 0.1237\n",
      "Epoch 3/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.9995 - accuracy: 0.3420 - val_loss: 2.2390 - val_accuracy: 0.1763\n",
      "Epoch 4/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.8732 - accuracy: 0.4149 - val_loss: 2.2068 - val_accuracy: 0.2553\n",
      "Epoch 5/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.7815 - accuracy: 0.4715 - val_loss: 2.1678 - val_accuracy: 0.3594\n",
      "Epoch 6/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.7125 - accuracy: 0.5078 - val_loss: 2.1309 - val_accuracy: 0.4101\n",
      "Epoch 7/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.6538 - accuracy: 0.5323 - val_loss: 2.0968 - val_accuracy: 0.4453\n",
      "Epoch 8/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.5981 - accuracy: 0.5600 - val_loss: 2.0608 - val_accuracy: 0.4738\n",
      "Epoch 9/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.5530 - accuracy: 0.5768 - val_loss: 2.0225 - val_accuracy: 0.5238\n",
      "Epoch 10/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.5074 - accuracy: 0.5945 - val_loss: 1.9854 - val_accuracy: 0.5628\n",
      "Epoch 11/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.4650 - accuracy: 0.6106 - val_loss: 1.9503 - val_accuracy: 0.5793\n",
      "Epoch 12/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.4285 - accuracy: 0.6250 - val_loss: 1.9122 - val_accuracy: 0.6042\n",
      "Epoch 13/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1.3951 - accuracy: 0.6378 - val_loss: 1.8754 - val_accuracy: 0.6081\n",
      "Epoch 14/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.3653 - accuracy: 0.6452 - val_loss: 1.8397 - val_accuracy: 0.6275\n",
      "Epoch 15/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.3355 - accuracy: 0.6559 - val_loss: 1.8032 - val_accuracy: 0.6402\n",
      "Epoch 16/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.3112 - accuracy: 0.6629 - val_loss: 1.7686 - val_accuracy: 0.6529\n",
      "Epoch 17/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.2846 - accuracy: 0.6723 - val_loss: 1.7349 - val_accuracy: 0.6501\n",
      "Epoch 18/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.2640 - accuracy: 0.6769 - val_loss: 1.6979 - val_accuracy: 0.6646\n",
      "Epoch 19/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.2432 - accuracy: 0.6824 - val_loss: 1.6656 - val_accuracy: 0.6661\n",
      "Epoch 20/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.2234 - accuracy: 0.6868 - val_loss: 1.6315 - val_accuracy: 0.6717\n",
      "Epoch 21/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.2056 - accuracy: 0.6910 - val_loss: 1.5980 - val_accuracy: 0.6777\n",
      "Epoch 22/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.1882 - accuracy: 0.6964 - val_loss: 1.5636 - val_accuracy: 0.6803\n",
      "Epoch 23/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.1726 - accuracy: 0.7003 - val_loss: 1.5326 - val_accuracy: 0.6836\n",
      "Epoch 24/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1565 - accuracy: 0.7050 - val_loss: 1.4997 - val_accuracy: 0.6925\n",
      "Epoch 25/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.1413 - accuracy: 0.7099 - val_loss: 1.4712 - val_accuracy: 0.6949\n",
      "Epoch 26/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.1284 - accuracy: 0.7121 - val_loss: 1.4411 - val_accuracy: 0.6964\n",
      "Epoch 27/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.1156 - accuracy: 0.7145 - val_loss: 1.4112 - val_accuracy: 0.7031\n",
      "Epoch 28/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.1027 - accuracy: 0.7184 - val_loss: 1.3825 - val_accuracy: 0.7044\n",
      "Epoch 29/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0911 - accuracy: 0.7208 - val_loss: 1.3567 - val_accuracy: 0.7036\n",
      "Epoch 30/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.0804 - accuracy: 0.7233 - val_loss: 1.3339 - val_accuracy: 0.7048\n",
      "Epoch 31/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0700 - accuracy: 0.7248 - val_loss: 1.3066 - val_accuracy: 0.7086\n",
      "Epoch 32/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.0593 - accuracy: 0.7276 - val_loss: 1.2798 - val_accuracy: 0.7104\n",
      "Epoch 33/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0492 - accuracy: 0.7301 - val_loss: 1.2571 - val_accuracy: 0.7159\n",
      "Epoch 34/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0396 - accuracy: 0.7324 - val_loss: 1.2344 - val_accuracy: 0.7165\n",
      "Epoch 35/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0303 - accuracy: 0.7350 - val_loss: 1.2143 - val_accuracy: 0.7186\n",
      "Epoch 36/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0218 - accuracy: 0.7371 - val_loss: 1.1934 - val_accuracy: 0.7203\n",
      "Epoch 37/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0130 - accuracy: 0.7398 - val_loss: 1.1764 - val_accuracy: 0.7212\n",
      "Epoch 38/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0055 - accuracy: 0.7411 - val_loss: 1.1569 - val_accuracy: 0.7237\n",
      "Epoch 39/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.9977 - accuracy: 0.7427 - val_loss: 1.1394 - val_accuracy: 0.7241\n",
      "Epoch 40/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.9896 - accuracy: 0.7440 - val_loss: 1.1230 - val_accuracy: 0.7287\n",
      "Epoch 41/400\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.9821 - accuracy: 0.7460 - val_loss: 1.1086 - val_accuracy: 0.7283\n",
      "Epoch 42/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.9763 - accuracy: 0.7459 - val_loss: 1.0922 - val_accuracy: 0.7298\n",
      "Epoch 43/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.9683 - accuracy: 0.7487 - val_loss: 1.0797 - val_accuracy: 0.7300\n",
      "Epoch 44/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9623 - accuracy: 0.7499 - val_loss: 1.0653 - val_accuracy: 0.7349\n",
      "Epoch 45/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9553 - accuracy: 0.7523 - val_loss: 1.0533 - val_accuracy: 0.7356\n",
      "Epoch 46/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.9485 - accuracy: 0.7534 - val_loss: 1.0408 - val_accuracy: 0.7364\n",
      "Epoch 47/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.9425 - accuracy: 0.7550 - val_loss: 1.0300 - val_accuracy: 0.7371\n",
      "Epoch 48/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9372 - accuracy: 0.7564 - val_loss: 1.0193 - val_accuracy: 0.7389\n",
      "Epoch 49/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9307 - accuracy: 0.7581 - val_loss: 1.0098 - val_accuracy: 0.7377\n",
      "Epoch 50/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9247 - accuracy: 0.7596 - val_loss: 1.0017 - val_accuracy: 0.7391\n",
      "Epoch 51/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9195 - accuracy: 0.7616 - val_loss: 0.9933 - val_accuracy: 0.7416\n",
      "Epoch 52/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9146 - accuracy: 0.7609 - val_loss: 0.9832 - val_accuracy: 0.7435\n",
      "Epoch 53/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9093 - accuracy: 0.7630 - val_loss: 0.9754 - val_accuracy: 0.7451\n",
      "Epoch 54/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9037 - accuracy: 0.7645 - val_loss: 0.9678 - val_accuracy: 0.7446\n",
      "Epoch 55/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.8993 - accuracy: 0.7658 - val_loss: 0.9635 - val_accuracy: 0.7446\n",
      "Epoch 56/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.8947 - accuracy: 0.7666 - val_loss: 0.9548 - val_accuracy: 0.7479\n",
      "Epoch 57/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8896 - accuracy: 0.7682 - val_loss: 0.9480 - val_accuracy: 0.7489\n",
      "Epoch 58/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8848 - accuracy: 0.7695 - val_loss: 0.9419 - val_accuracy: 0.7501\n",
      "Epoch 59/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8805 - accuracy: 0.7704 - val_loss: 0.9357 - val_accuracy: 0.7521\n",
      "Epoch 60/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8757 - accuracy: 0.7719 - val_loss: 0.9306 - val_accuracy: 0.7532\n",
      "Epoch 61/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8713 - accuracy: 0.7728 - val_loss: 0.9276 - val_accuracy: 0.7491\n",
      "Epoch 62/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8674 - accuracy: 0.7736 - val_loss: 0.9203 - val_accuracy: 0.7530\n",
      "Epoch 63/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8629 - accuracy: 0.7749 - val_loss: 0.9153 - val_accuracy: 0.7551\n",
      "Epoch 64/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8585 - accuracy: 0.7758 - val_loss: 0.9109 - val_accuracy: 0.7527\n",
      "Epoch 65/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8546 - accuracy: 0.7772 - val_loss: 0.9078 - val_accuracy: 0.7538\n",
      "Epoch 66/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8515 - accuracy: 0.7784 - val_loss: 0.9025 - val_accuracy: 0.7562\n",
      "Epoch 67/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8476 - accuracy: 0.7783 - val_loss: 0.8970 - val_accuracy: 0.7569\n",
      "Epoch 68/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.8431 - accuracy: 0.7791 - val_loss: 0.8958 - val_accuracy: 0.7576\n",
      "Epoch 69/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8396 - accuracy: 0.7800 - val_loss: 0.8894 - val_accuracy: 0.7587\n",
      "Epoch 70/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8357 - accuracy: 0.7810 - val_loss: 0.8856 - val_accuracy: 0.7608\n",
      "Epoch 71/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8319 - accuracy: 0.7822 - val_loss: 0.8841 - val_accuracy: 0.7591\n",
      "Epoch 72/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.8287 - accuracy: 0.7825 - val_loss: 0.8787 - val_accuracy: 0.7606\n",
      "Epoch 73/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8247 - accuracy: 0.7845 - val_loss: 0.8767 - val_accuracy: 0.7623\n",
      "Epoch 74/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8216 - accuracy: 0.7851 - val_loss: 0.8710 - val_accuracy: 0.7623\n",
      "Epoch 75/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8182 - accuracy: 0.7861 - val_loss: 0.8685 - val_accuracy: 0.7626\n",
      "Epoch 76/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8151 - accuracy: 0.7863 - val_loss: 0.8688 - val_accuracy: 0.7619\n",
      "Epoch 77/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8115 - accuracy: 0.7881 - val_loss: 0.8625 - val_accuracy: 0.7640\n",
      "Epoch 78/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8080 - accuracy: 0.7885 - val_loss: 0.8596 - val_accuracy: 0.7643\n",
      "Epoch 79/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8058 - accuracy: 0.7898 - val_loss: 0.8562 - val_accuracy: 0.7646\n",
      "Epoch 80/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.8023 - accuracy: 0.7896 - val_loss: 0.8528 - val_accuracy: 0.7659\n",
      "Epoch 81/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7987 - accuracy: 0.7908 - val_loss: 0.8508 - val_accuracy: 0.7677\n",
      "Epoch 82/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7961 - accuracy: 0.7920 - val_loss: 0.8498 - val_accuracy: 0.7677\n",
      "Epoch 83/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7929 - accuracy: 0.7928 - val_loss: 0.8456 - val_accuracy: 0.7697\n",
      "Epoch 84/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7900 - accuracy: 0.7935 - val_loss: 0.8442 - val_accuracy: 0.7692\n",
      "Epoch 85/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7870 - accuracy: 0.7945 - val_loss: 0.8395 - val_accuracy: 0.7709\n",
      "Epoch 86/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7842 - accuracy: 0.7953 - val_loss: 0.8383 - val_accuracy: 0.7706\n",
      "Epoch 87/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7813 - accuracy: 0.7952 - val_loss: 0.8358 - val_accuracy: 0.7712\n",
      "Epoch 88/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7783 - accuracy: 0.7973 - val_loss: 0.8329 - val_accuracy: 0.7713\n",
      "Epoch 89/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7761 - accuracy: 0.7967 - val_loss: 0.8304 - val_accuracy: 0.7718\n",
      "Epoch 90/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7728 - accuracy: 0.7978 - val_loss: 0.8271 - val_accuracy: 0.7737\n",
      "Epoch 91/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.7705 - accuracy: 0.7990 - val_loss: 0.8269 - val_accuracy: 0.7740\n",
      "Epoch 92/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7679 - accuracy: 0.7987 - val_loss: 0.8255 - val_accuracy: 0.7715\n",
      "Epoch 93/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7655 - accuracy: 0.8000 - val_loss: 0.8232 - val_accuracy: 0.7723\n",
      "Epoch 94/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7627 - accuracy: 0.8010 - val_loss: 0.8185 - val_accuracy: 0.7756\n",
      "Epoch 95/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7599 - accuracy: 0.8018 - val_loss: 0.8164 - val_accuracy: 0.7749\n",
      "Epoch 96/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7576 - accuracy: 0.8023 - val_loss: 0.8155 - val_accuracy: 0.7761\n",
      "Epoch 97/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7559 - accuracy: 0.8021 - val_loss: 0.8123 - val_accuracy: 0.7764\n",
      "Epoch 98/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7530 - accuracy: 0.8043 - val_loss: 0.8106 - val_accuracy: 0.7777\n",
      "Epoch 99/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7501 - accuracy: 0.8047 - val_loss: 0.8084 - val_accuracy: 0.7779\n",
      "Epoch 100/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7476 - accuracy: 0.8042 - val_loss: 0.8064 - val_accuracy: 0.7789\n",
      "Epoch 101/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7454 - accuracy: 0.8059 - val_loss: 0.8050 - val_accuracy: 0.7794\n",
      "Epoch 102/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7429 - accuracy: 0.8065 - val_loss: 0.8027 - val_accuracy: 0.7801\n",
      "Epoch 103/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7409 - accuracy: 0.8070 - val_loss: 0.8013 - val_accuracy: 0.7811\n",
      "Epoch 104/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7387 - accuracy: 0.8077 - val_loss: 0.7994 - val_accuracy: 0.7800\n",
      "Epoch 105/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7361 - accuracy: 0.8087 - val_loss: 0.7982 - val_accuracy: 0.7798\n",
      "Epoch 106/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7340 - accuracy: 0.8091 - val_loss: 0.7981 - val_accuracy: 0.7805\n",
      "Epoch 107/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7321 - accuracy: 0.8092 - val_loss: 0.7935 - val_accuracy: 0.7804\n",
      "Epoch 108/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7298 - accuracy: 0.8101 - val_loss: 0.7915 - val_accuracy: 0.7837\n",
      "Epoch 109/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7275 - accuracy: 0.8110 - val_loss: 0.7914 - val_accuracy: 0.7813\n",
      "Epoch 110/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7257 - accuracy: 0.8107 - val_loss: 0.7904 - val_accuracy: 0.7819\n",
      "Epoch 111/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7233 - accuracy: 0.8112 - val_loss: 0.7865 - val_accuracy: 0.7842\n",
      "Epoch 112/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7211 - accuracy: 0.8124 - val_loss: 0.7858 - val_accuracy: 0.7834\n",
      "Epoch 113/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7194 - accuracy: 0.8134 - val_loss: 0.7831 - val_accuracy: 0.7858\n",
      "Epoch 114/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7170 - accuracy: 0.8135 - val_loss: 0.7830 - val_accuracy: 0.7842\n",
      "Epoch 115/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7150 - accuracy: 0.8142 - val_loss: 0.7800 - val_accuracy: 0.7851\n",
      "Epoch 116/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7130 - accuracy: 0.8139 - val_loss: 0.7784 - val_accuracy: 0.7858\n",
      "Epoch 117/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7113 - accuracy: 0.8152 - val_loss: 0.7772 - val_accuracy: 0.7874\n",
      "Epoch 118/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.7089 - accuracy: 0.8157 - val_loss: 0.7754 - val_accuracy: 0.7870\n",
      "Epoch 119/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.7073 - accuracy: 0.8166 - val_loss: 0.7729 - val_accuracy: 0.7881\n",
      "Epoch 120/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7051 - accuracy: 0.8164 - val_loss: 0.7720 - val_accuracy: 0.7876\n",
      "Epoch 121/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7036 - accuracy: 0.8172 - val_loss: 0.7728 - val_accuracy: 0.7883\n",
      "Epoch 122/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7023 - accuracy: 0.8173 - val_loss: 0.7709 - val_accuracy: 0.7879\n",
      "Epoch 123/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6998 - accuracy: 0.8182 - val_loss: 0.7682 - val_accuracy: 0.7891\n",
      "Epoch 124/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6978 - accuracy: 0.8185 - val_loss: 0.7664 - val_accuracy: 0.7898\n",
      "Epoch 125/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6962 - accuracy: 0.8194 - val_loss: 0.7652 - val_accuracy: 0.7909\n",
      "Epoch 126/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6945 - accuracy: 0.8191 - val_loss: 0.7629 - val_accuracy: 0.7897\n",
      "Epoch 127/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6930 - accuracy: 0.8197 - val_loss: 0.7630 - val_accuracy: 0.7896\n",
      "Epoch 128/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6907 - accuracy: 0.8206 - val_loss: 0.7604 - val_accuracy: 0.7915\n",
      "Epoch 129/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6888 - accuracy: 0.8211 - val_loss: 0.7597 - val_accuracy: 0.7913\n",
      "Epoch 130/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6875 - accuracy: 0.8215 - val_loss: 0.7588 - val_accuracy: 0.7924\n",
      "Epoch 131/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.6855 - accuracy: 0.8221 - val_loss: 0.7582 - val_accuracy: 0.7895\n",
      "Epoch 132/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6838 - accuracy: 0.8221 - val_loss: 0.7552 - val_accuracy: 0.7931\n",
      "Epoch 133/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6819 - accuracy: 0.8221 - val_loss: 0.7547 - val_accuracy: 0.7913\n",
      "Epoch 134/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6802 - accuracy: 0.8233 - val_loss: 0.7524 - val_accuracy: 0.7935\n",
      "Epoch 135/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6793 - accuracy: 0.8232 - val_loss: 0.7520 - val_accuracy: 0.7921\n",
      "Epoch 136/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6770 - accuracy: 0.8239 - val_loss: 0.7508 - val_accuracy: 0.7926\n",
      "Epoch 137/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6754 - accuracy: 0.8245 - val_loss: 0.7491 - val_accuracy: 0.7938\n",
      "Epoch 138/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6734 - accuracy: 0.8250 - val_loss: 0.7482 - val_accuracy: 0.7947\n",
      "Epoch 139/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6718 - accuracy: 0.8254 - val_loss: 0.7462 - val_accuracy: 0.7962\n",
      "Epoch 140/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6704 - accuracy: 0.8254 - val_loss: 0.7459 - val_accuracy: 0.7947\n",
      "Epoch 141/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.6691 - accuracy: 0.8260 - val_loss: 0.7433 - val_accuracy: 0.7965\n",
      "Epoch 142/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6672 - accuracy: 0.8265 - val_loss: 0.7422 - val_accuracy: 0.7956\n",
      "Epoch 143/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6658 - accuracy: 0.8270 - val_loss: 0.7421 - val_accuracy: 0.7963\n",
      "Epoch 144/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6643 - accuracy: 0.8267 - val_loss: 0.7392 - val_accuracy: 0.7970\n",
      "Epoch 145/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6624 - accuracy: 0.8285 - val_loss: 0.7388 - val_accuracy: 0.7974\n",
      "Epoch 146/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6613 - accuracy: 0.8285 - val_loss: 0.7378 - val_accuracy: 0.7981\n",
      "Epoch 147/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6597 - accuracy: 0.8287 - val_loss: 0.7372 - val_accuracy: 0.7970\n",
      "Epoch 148/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6581 - accuracy: 0.8293 - val_loss: 0.7365 - val_accuracy: 0.7979\n",
      "Epoch 149/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6572 - accuracy: 0.8292 - val_loss: 0.7343 - val_accuracy: 0.7990\n",
      "Epoch 150/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6554 - accuracy: 0.8291 - val_loss: 0.7327 - val_accuracy: 0.7989\n",
      "Epoch 151/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6539 - accuracy: 0.8300 - val_loss: 0.7319 - val_accuracy: 0.7999\n",
      "Epoch 152/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6522 - accuracy: 0.8302 - val_loss: 0.7313 - val_accuracy: 0.7997\n",
      "Epoch 153/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.6506 - accuracy: 0.8308 - val_loss: 0.7295 - val_accuracy: 0.7995\n",
      "Epoch 154/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6497 - accuracy: 0.8309 - val_loss: 0.7284 - val_accuracy: 0.8004\n",
      "Epoch 155/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6479 - accuracy: 0.8318 - val_loss: 0.7295 - val_accuracy: 0.8002\n",
      "Epoch 156/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6467 - accuracy: 0.8320 - val_loss: 0.7270 - val_accuracy: 0.8016\n",
      "Epoch 157/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6451 - accuracy: 0.8325 - val_loss: 0.7260 - val_accuracy: 0.8011\n",
      "Epoch 158/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6436 - accuracy: 0.8334 - val_loss: 0.7256 - val_accuracy: 0.8021\n",
      "Epoch 159/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.6431 - accuracy: 0.8327 - val_loss: 0.7252 - val_accuracy: 0.8004\n",
      "Epoch 160/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6417 - accuracy: 0.8335 - val_loss: 0.7221 - val_accuracy: 0.8023\n",
      "Epoch 161/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.6395 - accuracy: 0.8340 - val_loss: 0.7220 - val_accuracy: 0.8014\n",
      "Epoch 162/400\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.6385 - accuracy: 0.8348 - val_loss: 0.7219 - val_accuracy: 0.8015\n",
      "Epoch 163/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6372 - accuracy: 0.8341 - val_loss: 0.7187 - val_accuracy: 0.8040\n",
      "Epoch 164/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.6357 - accuracy: 0.8356 - val_loss: 0.7185 - val_accuracy: 0.8031\n",
      "Epoch 165/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6342 - accuracy: 0.8352 - val_loss: 0.7181 - val_accuracy: 0.8036\n",
      "Epoch 166/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6334 - accuracy: 0.8356 - val_loss: 0.7170 - val_accuracy: 0.8047\n",
      "Epoch 167/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.6323 - accuracy: 0.8364 - val_loss: 0.7153 - val_accuracy: 0.8056\n",
      "Epoch 168/400\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.6308 - accuracy: 0.8365 - val_loss: 0.7145 - val_accuracy: 0.8053\n",
      "Epoch 169/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.6292 - accuracy: 0.8367 - val_loss: 0.7133 - val_accuracy: 0.8053\n",
      "Epoch 170/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6279 - accuracy: 0.8380 - val_loss: 0.7126 - val_accuracy: 0.8051\n",
      "Epoch 171/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.6267 - accuracy: 0.8380 - val_loss: 0.7124 - val_accuracy: 0.8053\n",
      "Epoch 172/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.6258 - accuracy: 0.8379 - val_loss: 0.7103 - val_accuracy: 0.8068\n",
      "Epoch 173/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6242 - accuracy: 0.8381 - val_loss: 0.7111 - val_accuracy: 0.8064\n",
      "Epoch 174/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6230 - accuracy: 0.8385 - val_loss: 0.7107 - val_accuracy: 0.8066\n",
      "Epoch 175/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6214 - accuracy: 0.8390 - val_loss: 0.7075 - val_accuracy: 0.8071\n",
      "Epoch 176/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6203 - accuracy: 0.8393 - val_loss: 0.7080 - val_accuracy: 0.8064\n",
      "Epoch 177/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6193 - accuracy: 0.8397 - val_loss: 0.7058 - val_accuracy: 0.8070\n",
      "Epoch 178/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6184 - accuracy: 0.8397 - val_loss: 0.7059 - val_accuracy: 0.8081\n",
      "Epoch 179/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6169 - accuracy: 0.8402 - val_loss: 0.7045 - val_accuracy: 0.8080\n",
      "Epoch 180/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.6153 - accuracy: 0.8406 - val_loss: 0.7028 - val_accuracy: 0.8084\n",
      "Epoch 181/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6143 - accuracy: 0.8413 - val_loss: 0.7022 - val_accuracy: 0.8078\n",
      "Epoch 182/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.6136 - accuracy: 0.8409 - val_loss: 0.7033 - val_accuracy: 0.8077\n",
      "Epoch 183/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6124 - accuracy: 0.8413 - val_loss: 0.7007 - val_accuracy: 0.8086\n",
      "Epoch 184/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6108 - accuracy: 0.8408 - val_loss: 0.6995 - val_accuracy: 0.8098\n",
      "Epoch 185/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6097 - accuracy: 0.8423 - val_loss: 0.6992 - val_accuracy: 0.8086\n",
      "Epoch 186/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6086 - accuracy: 0.8421 - val_loss: 0.6986 - val_accuracy: 0.8090\n",
      "Epoch 187/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6078 - accuracy: 0.8427 - val_loss: 0.6970 - val_accuracy: 0.8109\n",
      "Epoch 188/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.6065 - accuracy: 0.8432 - val_loss: 0.6961 - val_accuracy: 0.8107\n",
      "Epoch 189/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.6051 - accuracy: 0.8436 - val_loss: 0.6958 - val_accuracy: 0.8096\n",
      "Epoch 190/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6045 - accuracy: 0.8434 - val_loss: 0.6953 - val_accuracy: 0.8087\n",
      "Epoch 191/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6030 - accuracy: 0.8446 - val_loss: 0.6934 - val_accuracy: 0.8112\n",
      "Epoch 192/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6019 - accuracy: 0.8444 - val_loss: 0.6943 - val_accuracy: 0.8104\n",
      "Epoch 193/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6008 - accuracy: 0.8444 - val_loss: 0.6922 - val_accuracy: 0.8118\n",
      "Epoch 194/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6004 - accuracy: 0.8445 - val_loss: 0.6921 - val_accuracy: 0.8102\n",
      "Epoch 195/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5984 - accuracy: 0.8450 - val_loss: 0.6917 - val_accuracy: 0.8113\n",
      "Epoch 196/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.5977 - accuracy: 0.8455 - val_loss: 0.6898 - val_accuracy: 0.8118\n",
      "Epoch 197/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.5965 - accuracy: 0.8457 - val_loss: 0.6886 - val_accuracy: 0.8124\n",
      "Epoch 198/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.5956 - accuracy: 0.8457 - val_loss: 0.6883 - val_accuracy: 0.8122\n",
      "Epoch 199/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.5945 - accuracy: 0.8457 - val_loss: 0.6889 - val_accuracy: 0.8111\n",
      "Epoch 200/400\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.5936 - accuracy: 0.8460 - val_loss: 0.6874 - val_accuracy: 0.8125\n",
      "Epoch 201/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.5926 - accuracy: 0.8464 - val_loss: 0.6863 - val_accuracy: 0.8122\n",
      "Epoch 202/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5912 - accuracy: 0.8469 - val_loss: 0.6849 - val_accuracy: 0.8130\n",
      "Epoch 203/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.5903 - accuracy: 0.8475 - val_loss: 0.6856 - val_accuracy: 0.8126\n",
      "Epoch 204/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5891 - accuracy: 0.8469 - val_loss: 0.6834 - val_accuracy: 0.8135\n",
      "Epoch 205/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5882 - accuracy: 0.8480 - val_loss: 0.6823 - val_accuracy: 0.8143\n",
      "Epoch 206/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5873 - accuracy: 0.8480 - val_loss: 0.6836 - val_accuracy: 0.8121\n",
      "Epoch 207/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5865 - accuracy: 0.8478 - val_loss: 0.6828 - val_accuracy: 0.8149\n",
      "Epoch 208/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5854 - accuracy: 0.8480 - val_loss: 0.6814 - val_accuracy: 0.8132\n",
      "Epoch 209/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5839 - accuracy: 0.8486 - val_loss: 0.6808 - val_accuracy: 0.8138\n",
      "Epoch 210/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.5829 - accuracy: 0.8492 - val_loss: 0.6796 - val_accuracy: 0.8153\n",
      "Epoch 211/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5824 - accuracy: 0.8489 - val_loss: 0.6796 - val_accuracy: 0.8138\n",
      "Epoch 212/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.5811 - accuracy: 0.8498 - val_loss: 0.6786 - val_accuracy: 0.8141\n",
      "Epoch 213/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5806 - accuracy: 0.8493 - val_loss: 0.6774 - val_accuracy: 0.8153\n",
      "Epoch 214/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5793 - accuracy: 0.8492 - val_loss: 0.6758 - val_accuracy: 0.8157\n",
      "Epoch 215/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5784 - accuracy: 0.8499 - val_loss: 0.6768 - val_accuracy: 0.8144\n",
      "Epoch 216/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5773 - accuracy: 0.8505 - val_loss: 0.6770 - val_accuracy: 0.8137\n",
      "Epoch 217/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5765 - accuracy: 0.8499 - val_loss: 0.6743 - val_accuracy: 0.8154\n",
      "Epoch 218/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5755 - accuracy: 0.8505 - val_loss: 0.6749 - val_accuracy: 0.8152\n",
      "Epoch 219/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5748 - accuracy: 0.8506 - val_loss: 0.6729 - val_accuracy: 0.8162\n",
      "Epoch 220/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.5737 - accuracy: 0.8503 - val_loss: 0.6720 - val_accuracy: 0.8164\n",
      "Epoch 221/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5727 - accuracy: 0.8510 - val_loss: 0.6718 - val_accuracy: 0.8163\n",
      "Epoch 222/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5716 - accuracy: 0.8520 - val_loss: 0.6713 - val_accuracy: 0.8168\n",
      "Epoch 223/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5713 - accuracy: 0.8513 - val_loss: 0.6708 - val_accuracy: 0.8165\n",
      "Epoch 224/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5697 - accuracy: 0.8519 - val_loss: 0.6692 - val_accuracy: 0.8178\n",
      "Epoch 225/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5690 - accuracy: 0.8525 - val_loss: 0.6695 - val_accuracy: 0.8167\n",
      "Epoch 226/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5680 - accuracy: 0.8521 - val_loss: 0.6688 - val_accuracy: 0.8171\n",
      "Epoch 227/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5673 - accuracy: 0.8524 - val_loss: 0.6690 - val_accuracy: 0.8163\n",
      "Epoch 228/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.5662 - accuracy: 0.8528 - val_loss: 0.6679 - val_accuracy: 0.8177\n",
      "Epoch 229/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5655 - accuracy: 0.8530 - val_loss: 0.6669 - val_accuracy: 0.8179\n",
      "Epoch 230/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5644 - accuracy: 0.8534 - val_loss: 0.6653 - val_accuracy: 0.8189\n",
      "Epoch 231/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5637 - accuracy: 0.8532 - val_loss: 0.6653 - val_accuracy: 0.8189\n",
      "Epoch 232/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5626 - accuracy: 0.8533 - val_loss: 0.6657 - val_accuracy: 0.8176\n",
      "Epoch 233/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5621 - accuracy: 0.8542 - val_loss: 0.6636 - val_accuracy: 0.8186\n",
      "Epoch 234/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5611 - accuracy: 0.8538 - val_loss: 0.6636 - val_accuracy: 0.8188\n",
      "Epoch 235/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.5603 - accuracy: 0.8536 - val_loss: 0.6633 - val_accuracy: 0.8183\n",
      "Epoch 236/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5592 - accuracy: 0.8550 - val_loss: 0.6633 - val_accuracy: 0.8183\n",
      "Epoch 237/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5587 - accuracy: 0.8555 - val_loss: 0.6619 - val_accuracy: 0.8189\n",
      "Epoch 238/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5577 - accuracy: 0.8544 - val_loss: 0.6607 - val_accuracy: 0.8198\n",
      "Epoch 239/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5569 - accuracy: 0.8555 - val_loss: 0.6604 - val_accuracy: 0.8196\n",
      "Epoch 240/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5560 - accuracy: 0.8553 - val_loss: 0.6602 - val_accuracy: 0.8199\n",
      "Epoch 241/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5552 - accuracy: 0.8558 - val_loss: 0.6591 - val_accuracy: 0.8193\n",
      "Epoch 242/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5539 - accuracy: 0.8565 - val_loss: 0.6588 - val_accuracy: 0.8189\n",
      "Epoch 243/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5534 - accuracy: 0.8556 - val_loss: 0.6579 - val_accuracy: 0.8207\n",
      "Epoch 244/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5527 - accuracy: 0.8566 - val_loss: 0.6598 - val_accuracy: 0.8189\n",
      "Epoch 245/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5519 - accuracy: 0.8565 - val_loss: 0.6582 - val_accuracy: 0.8189\n",
      "Epoch 246/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5510 - accuracy: 0.8572 - val_loss: 0.6573 - val_accuracy: 0.8198\n",
      "Epoch 247/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5501 - accuracy: 0.8571 - val_loss: 0.6556 - val_accuracy: 0.8212\n",
      "Epoch 248/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5495 - accuracy: 0.8575 - val_loss: 0.6559 - val_accuracy: 0.8205\n",
      "Epoch 249/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5486 - accuracy: 0.8576 - val_loss: 0.6549 - val_accuracy: 0.8209\n",
      "Epoch 250/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5478 - accuracy: 0.8570 - val_loss: 0.6544 - val_accuracy: 0.8215\n",
      "Epoch 251/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5471 - accuracy: 0.8583 - val_loss: 0.6529 - val_accuracy: 0.8217\n",
      "Epoch 252/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5460 - accuracy: 0.8584 - val_loss: 0.6531 - val_accuracy: 0.8213\n",
      "Epoch 253/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5452 - accuracy: 0.8589 - val_loss: 0.6525 - val_accuracy: 0.8223\n",
      "Epoch 254/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5448 - accuracy: 0.8581 - val_loss: 0.6527 - val_accuracy: 0.8212\n",
      "Epoch 255/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.5441 - accuracy: 0.8586 - val_loss: 0.6515 - val_accuracy: 0.8211\n",
      "Epoch 256/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.5434 - accuracy: 0.8592 - val_loss: 0.6515 - val_accuracy: 0.8209\n",
      "Epoch 257/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5424 - accuracy: 0.8589 - val_loss: 0.6504 - val_accuracy: 0.8214\n",
      "Epoch 258/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5414 - accuracy: 0.8593 - val_loss: 0.6496 - val_accuracy: 0.8225\n",
      "Epoch 259/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5411 - accuracy: 0.8594 - val_loss: 0.6492 - val_accuracy: 0.8227\n",
      "Epoch 260/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5392 - accuracy: 0.8600 - val_loss: 0.6485 - val_accuracy: 0.8228\n",
      "Epoch 261/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5392 - accuracy: 0.8604 - val_loss: 0.6489 - val_accuracy: 0.8222\n",
      "Epoch 262/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5385 - accuracy: 0.8608 - val_loss: 0.6475 - val_accuracy: 0.8233\n",
      "Epoch 263/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5378 - accuracy: 0.8603 - val_loss: 0.6475 - val_accuracy: 0.8235\n",
      "Epoch 264/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.5368 - accuracy: 0.8611 - val_loss: 0.6468 - val_accuracy: 0.8226\n",
      "Epoch 265/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5357 - accuracy: 0.8611 - val_loss: 0.6463 - val_accuracy: 0.8224\n",
      "Epoch 266/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5354 - accuracy: 0.8620 - val_loss: 0.6455 - val_accuracy: 0.8237\n",
      "Epoch 267/400\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.5349 - accuracy: 0.8610 - val_loss: 0.6446 - val_accuracy: 0.8236\n",
      "Epoch 268/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5336 - accuracy: 0.8619 - val_loss: 0.6444 - val_accuracy: 0.8246\n",
      "Epoch 269/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5331 - accuracy: 0.8618 - val_loss: 0.6457 - val_accuracy: 0.8233\n",
      "Epoch 270/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5324 - accuracy: 0.8625 - val_loss: 0.6436 - val_accuracy: 0.8238\n",
      "Epoch 271/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5317 - accuracy: 0.8626 - val_loss: 0.6428 - val_accuracy: 0.8246\n",
      "Epoch 272/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5308 - accuracy: 0.8629 - val_loss: 0.6435 - val_accuracy: 0.8235\n",
      "Epoch 273/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.5300 - accuracy: 0.8627 - val_loss: 0.6436 - val_accuracy: 0.8230\n",
      "Epoch 274/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5295 - accuracy: 0.8626 - val_loss: 0.6411 - val_accuracy: 0.8242\n",
      "Epoch 275/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5287 - accuracy: 0.8633 - val_loss: 0.6418 - val_accuracy: 0.8236\n",
      "Epoch 276/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5279 - accuracy: 0.8632 - val_loss: 0.6418 - val_accuracy: 0.8238\n",
      "Epoch 277/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5275 - accuracy: 0.8640 - val_loss: 0.6400 - val_accuracy: 0.8247\n",
      "Epoch 278/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5266 - accuracy: 0.8640 - val_loss: 0.6398 - val_accuracy: 0.8241\n",
      "Epoch 279/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.5260 - accuracy: 0.8639 - val_loss: 0.6398 - val_accuracy: 0.8246\n",
      "Epoch 280/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.5249 - accuracy: 0.8638 - val_loss: 0.6383 - val_accuracy: 0.8241\n",
      "Epoch 281/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.5245 - accuracy: 0.8647 - val_loss: 0.6376 - val_accuracy: 0.8255\n",
      "Epoch 282/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5239 - accuracy: 0.8640 - val_loss: 0.6381 - val_accuracy: 0.8236\n",
      "Epoch 283/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5233 - accuracy: 0.8654 - val_loss: 0.6368 - val_accuracy: 0.8253\n",
      "Epoch 284/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5221 - accuracy: 0.8653 - val_loss: 0.6378 - val_accuracy: 0.8244\n",
      "Epoch 285/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5221 - accuracy: 0.8651 - val_loss: 0.6357 - val_accuracy: 0.8256\n",
      "Epoch 286/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5212 - accuracy: 0.8647 - val_loss: 0.6360 - val_accuracy: 0.8246\n",
      "Epoch 287/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5200 - accuracy: 0.8659 - val_loss: 0.6352 - val_accuracy: 0.8256\n",
      "Epoch 288/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5195 - accuracy: 0.8664 - val_loss: 0.6351 - val_accuracy: 0.8254\n",
      "Epoch 289/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5191 - accuracy: 0.8660 - val_loss: 0.6346 - val_accuracy: 0.8260\n",
      "Epoch 290/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5182 - accuracy: 0.8659 - val_loss: 0.6352 - val_accuracy: 0.8246\n",
      "Epoch 291/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5176 - accuracy: 0.8667 - val_loss: 0.6338 - val_accuracy: 0.8266\n",
      "Epoch 292/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5166 - accuracy: 0.8664 - val_loss: 0.6327 - val_accuracy: 0.8269\n",
      "Epoch 293/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5160 - accuracy: 0.8666 - val_loss: 0.6324 - val_accuracy: 0.8264\n",
      "Epoch 294/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5158 - accuracy: 0.8668 - val_loss: 0.6330 - val_accuracy: 0.8249\n",
      "Epoch 295/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5152 - accuracy: 0.8677 - val_loss: 0.6317 - val_accuracy: 0.8267\n",
      "Epoch 296/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5142 - accuracy: 0.8679 - val_loss: 0.6314 - val_accuracy: 0.8267\n",
      "Epoch 297/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5135 - accuracy: 0.8679 - val_loss: 0.6311 - val_accuracy: 0.8258\n",
      "Epoch 298/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5131 - accuracy: 0.8679 - val_loss: 0.6304 - val_accuracy: 0.8272\n",
      "Epoch 299/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5124 - accuracy: 0.8682 - val_loss: 0.6299 - val_accuracy: 0.8268\n",
      "Epoch 300/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5123 - accuracy: 0.8680 - val_loss: 0.6300 - val_accuracy: 0.8259\n",
      "Epoch 301/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5112 - accuracy: 0.8685 - val_loss: 0.6291 - val_accuracy: 0.8279\n",
      "Epoch 302/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5102 - accuracy: 0.8685 - val_loss: 0.6299 - val_accuracy: 0.8260\n",
      "Epoch 303/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5098 - accuracy: 0.8689 - val_loss: 0.6301 - val_accuracy: 0.8267\n",
      "Epoch 304/400\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.5097 - accuracy: 0.8688 - val_loss: 0.6283 - val_accuracy: 0.8261\n",
      "Epoch 305/400\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.5085 - accuracy: 0.8694 - val_loss: 0.6272 - val_accuracy: 0.8276\n",
      "Epoch 306/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.5077 - accuracy: 0.8696 - val_loss: 0.6271 - val_accuracy: 0.8277\n",
      "Epoch 307/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.5073 - accuracy: 0.8693 - val_loss: 0.6268 - val_accuracy: 0.8279\n",
      "Epoch 308/400\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.5064 - accuracy: 0.8697 - val_loss: 0.6258 - val_accuracy: 0.8281\n",
      "Epoch 309/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.5060 - accuracy: 0.8699 - val_loss: 0.6257 - val_accuracy: 0.8287\n",
      "Epoch 310/400\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.5058 - accuracy: 0.8702 - val_loss: 0.6255 - val_accuracy: 0.8278\n",
      "Epoch 311/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5049 - accuracy: 0.8700 - val_loss: 0.6252 - val_accuracy: 0.8287\n",
      "Epoch 312/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5040 - accuracy: 0.8703 - val_loss: 0.6255 - val_accuracy: 0.8277\n",
      "Epoch 313/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.5034 - accuracy: 0.8706 - val_loss: 0.6250 - val_accuracy: 0.8269\n",
      "Epoch 314/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5029 - accuracy: 0.8705 - val_loss: 0.6242 - val_accuracy: 0.8286\n",
      "Epoch 315/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5024 - accuracy: 0.8708 - val_loss: 0.6232 - val_accuracy: 0.8292\n",
      "Epoch 316/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5017 - accuracy: 0.8712 - val_loss: 0.6231 - val_accuracy: 0.8298\n",
      "Epoch 317/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5009 - accuracy: 0.8711 - val_loss: 0.6240 - val_accuracy: 0.8288\n",
      "Epoch 318/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5005 - accuracy: 0.8718 - val_loss: 0.6221 - val_accuracy: 0.8287\n",
      "Epoch 319/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4999 - accuracy: 0.8720 - val_loss: 0.6220 - val_accuracy: 0.8304\n",
      "Epoch 320/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4994 - accuracy: 0.8720 - val_loss: 0.6210 - val_accuracy: 0.8303\n",
      "Epoch 321/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4987 - accuracy: 0.8722 - val_loss: 0.6215 - val_accuracy: 0.8287\n",
      "Epoch 322/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4982 - accuracy: 0.8724 - val_loss: 0.6210 - val_accuracy: 0.8292\n",
      "Epoch 323/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4978 - accuracy: 0.8720 - val_loss: 0.6215 - val_accuracy: 0.8283\n",
      "Epoch 324/400\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4970 - accuracy: 0.8730 - val_loss: 0.6199 - val_accuracy: 0.8296\n",
      "Epoch 325/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.4962 - accuracy: 0.8724 - val_loss: 0.6198 - val_accuracy: 0.8298\n",
      "Epoch 326/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4955 - accuracy: 0.8729 - val_loss: 0.6199 - val_accuracy: 0.8295\n",
      "Epoch 327/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4950 - accuracy: 0.8726 - val_loss: 0.6183 - val_accuracy: 0.8297\n",
      "Epoch 328/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4945 - accuracy: 0.8734 - val_loss: 0.6187 - val_accuracy: 0.8297\n",
      "Epoch 329/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4942 - accuracy: 0.8733 - val_loss: 0.6178 - val_accuracy: 0.8299\n",
      "Epoch 330/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4935 - accuracy: 0.8731 - val_loss: 0.6174 - val_accuracy: 0.8301\n",
      "Epoch 331/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4929 - accuracy: 0.8741 - val_loss: 0.6176 - val_accuracy: 0.8302\n",
      "Epoch 332/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4929 - accuracy: 0.8735 - val_loss: 0.6176 - val_accuracy: 0.8301\n",
      "Epoch 333/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4916 - accuracy: 0.8735 - val_loss: 0.6166 - val_accuracy: 0.8306\n",
      "Epoch 334/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4913 - accuracy: 0.8739 - val_loss: 0.6161 - val_accuracy: 0.8308\n",
      "Epoch 335/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4909 - accuracy: 0.8746 - val_loss: 0.6163 - val_accuracy: 0.8302\n",
      "Epoch 336/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4902 - accuracy: 0.8735 - val_loss: 0.6151 - val_accuracy: 0.8322\n",
      "Epoch 337/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.4897 - accuracy: 0.8746 - val_loss: 0.6160 - val_accuracy: 0.8307\n",
      "Epoch 338/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4892 - accuracy: 0.8748 - val_loss: 0.6143 - val_accuracy: 0.8319\n",
      "Epoch 339/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4882 - accuracy: 0.8743 - val_loss: 0.6139 - val_accuracy: 0.8322\n",
      "Epoch 340/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4878 - accuracy: 0.8748 - val_loss: 0.6141 - val_accuracy: 0.8319\n",
      "Epoch 341/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.4870 - accuracy: 0.8754 - val_loss: 0.6136 - val_accuracy: 0.8315\n",
      "Epoch 342/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4868 - accuracy: 0.8757 - val_loss: 0.6132 - val_accuracy: 0.8319\n",
      "Epoch 343/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4864 - accuracy: 0.8751 - val_loss: 0.6128 - val_accuracy: 0.8317\n",
      "Epoch 344/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4857 - accuracy: 0.8754 - val_loss: 0.6122 - val_accuracy: 0.8322\n",
      "Epoch 345/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4855 - accuracy: 0.8758 - val_loss: 0.6129 - val_accuracy: 0.8319\n",
      "Epoch 346/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4844 - accuracy: 0.8759 - val_loss: 0.6134 - val_accuracy: 0.8298\n",
      "Epoch 347/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4840 - accuracy: 0.8761 - val_loss: 0.6121 - val_accuracy: 0.8306\n",
      "Epoch 348/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4833 - accuracy: 0.8764 - val_loss: 0.6116 - val_accuracy: 0.8312\n",
      "Epoch 349/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4829 - accuracy: 0.8762 - val_loss: 0.6113 - val_accuracy: 0.8316\n",
      "Epoch 350/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.4822 - accuracy: 0.8765 - val_loss: 0.6109 - val_accuracy: 0.8316\n",
      "Epoch 351/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4820 - accuracy: 0.8770 - val_loss: 0.6103 - val_accuracy: 0.8315\n",
      "Epoch 352/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4812 - accuracy: 0.8768 - val_loss: 0.6113 - val_accuracy: 0.8323\n",
      "Epoch 353/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4810 - accuracy: 0.8766 - val_loss: 0.6103 - val_accuracy: 0.8322\n",
      "Epoch 354/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4803 - accuracy: 0.8769 - val_loss: 0.6094 - val_accuracy: 0.8324\n",
      "Epoch 355/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4796 - accuracy: 0.8775 - val_loss: 0.6087 - val_accuracy: 0.8333\n",
      "Epoch 356/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4793 - accuracy: 0.8774 - val_loss: 0.6089 - val_accuracy: 0.8329\n",
      "Epoch 357/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4789 - accuracy: 0.8771 - val_loss: 0.6085 - val_accuracy: 0.8328\n",
      "Epoch 358/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4779 - accuracy: 0.8775 - val_loss: 0.6085 - val_accuracy: 0.8327\n",
      "Epoch 359/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4773 - accuracy: 0.8783 - val_loss: 0.6074 - val_accuracy: 0.8336\n",
      "Epoch 360/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4773 - accuracy: 0.8778 - val_loss: 0.6081 - val_accuracy: 0.8324\n",
      "Epoch 361/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4765 - accuracy: 0.8783 - val_loss: 0.6069 - val_accuracy: 0.8324\n",
      "Epoch 362/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4759 - accuracy: 0.8781 - val_loss: 0.6058 - val_accuracy: 0.8347\n",
      "Epoch 363/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4754 - accuracy: 0.8784 - val_loss: 0.6073 - val_accuracy: 0.8333\n",
      "Epoch 364/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4748 - accuracy: 0.8793 - val_loss: 0.6059 - val_accuracy: 0.8342\n",
      "Epoch 365/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4745 - accuracy: 0.8783 - val_loss: 0.6064 - val_accuracy: 0.8321\n",
      "Epoch 366/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4741 - accuracy: 0.8788 - val_loss: 0.6054 - val_accuracy: 0.8343\n",
      "Epoch 367/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4738 - accuracy: 0.8789 - val_loss: 0.6046 - val_accuracy: 0.8346\n",
      "Epoch 368/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4729 - accuracy: 0.8795 - val_loss: 0.6052 - val_accuracy: 0.8329\n",
      "Epoch 369/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4726 - accuracy: 0.8792 - val_loss: 0.6040 - val_accuracy: 0.8348\n",
      "Epoch 370/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4715 - accuracy: 0.8796 - val_loss: 0.6038 - val_accuracy: 0.8343\n",
      "Epoch 371/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4716 - accuracy: 0.8796 - val_loss: 0.6029 - val_accuracy: 0.8347\n",
      "Epoch 372/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4707 - accuracy: 0.8802 - val_loss: 0.6027 - val_accuracy: 0.8352\n",
      "Epoch 373/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4701 - accuracy: 0.8805 - val_loss: 0.6033 - val_accuracy: 0.8339\n",
      "Epoch 374/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4701 - accuracy: 0.8796 - val_loss: 0.6022 - val_accuracy: 0.8354\n",
      "Epoch 375/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4692 - accuracy: 0.8799 - val_loss: 0.6027 - val_accuracy: 0.8338\n",
      "Epoch 376/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4687 - accuracy: 0.8802 - val_loss: 0.6030 - val_accuracy: 0.8343\n",
      "Epoch 377/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4686 - accuracy: 0.8800 - val_loss: 0.6014 - val_accuracy: 0.8349\n",
      "Epoch 378/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4680 - accuracy: 0.8807 - val_loss: 0.6017 - val_accuracy: 0.8347\n",
      "Epoch 379/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4674 - accuracy: 0.8809 - val_loss: 0.6009 - val_accuracy: 0.8346\n",
      "Epoch 380/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4669 - accuracy: 0.8802 - val_loss: 0.6004 - val_accuracy: 0.8352\n",
      "Epoch 381/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4667 - accuracy: 0.8806 - val_loss: 0.6000 - val_accuracy: 0.8356\n",
      "Epoch 382/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4659 - accuracy: 0.8817 - val_loss: 0.6004 - val_accuracy: 0.8359\n",
      "Epoch 383/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.4660 - accuracy: 0.8810 - val_loss: 0.5996 - val_accuracy: 0.8359\n",
      "Epoch 384/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4650 - accuracy: 0.8819 - val_loss: 0.5997 - val_accuracy: 0.8358\n",
      "Epoch 385/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.4648 - accuracy: 0.8814 - val_loss: 0.5990 - val_accuracy: 0.8357\n",
      "Epoch 386/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4641 - accuracy: 0.8816 - val_loss: 0.5998 - val_accuracy: 0.8348\n",
      "Epoch 387/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4638 - accuracy: 0.8820 - val_loss: 0.5990 - val_accuracy: 0.8358\n",
      "Epoch 388/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4634 - accuracy: 0.8825 - val_loss: 0.5980 - val_accuracy: 0.8363\n",
      "Epoch 389/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4626 - accuracy: 0.8822 - val_loss: 0.5986 - val_accuracy: 0.8358\n",
      "Epoch 390/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4621 - accuracy: 0.8824 - val_loss: 0.5982 - val_accuracy: 0.8363\n",
      "Epoch 391/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4619 - accuracy: 0.8822 - val_loss: 0.5979 - val_accuracy: 0.8359\n",
      "Epoch 392/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4614 - accuracy: 0.8824 - val_loss: 0.5970 - val_accuracy: 0.8368\n",
      "Epoch 393/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4608 - accuracy: 0.8830 - val_loss: 0.5965 - val_accuracy: 0.8364\n",
      "Epoch 394/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.4602 - accuracy: 0.8831 - val_loss: 0.5968 - val_accuracy: 0.8359\n",
      "Epoch 395/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.4596 - accuracy: 0.8832 - val_loss: 0.5958 - val_accuracy: 0.8367\n",
      "Epoch 396/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4593 - accuracy: 0.8830 - val_loss: 0.5961 - val_accuracy: 0.8361\n",
      "Epoch 397/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.4586 - accuracy: 0.8836 - val_loss: 0.5956 - val_accuracy: 0.8372\n",
      "Epoch 398/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4585 - accuracy: 0.8832 - val_loss: 0.5954 - val_accuracy: 0.8362\n",
      "Epoch 399/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4577 - accuracy: 0.8836 - val_loss: 0.5956 - val_accuracy: 0.8367\n",
      "Epoch 400/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.4575 - accuracy: 0.8837 - val_loss: 0.5948 - val_accuracy: 0.8368\n",
      "\n",
      "Test loss: 0.595\n",
      "Test accuracy: 0.837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa1fe9cf908>"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "epochs = 400   # Setting up higher epoch in persuit of finding global moinima,\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adagrad', # With adagrad\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)   # Set up early stopping to avoid wastage of computing power\n",
    "                                                                            # Kept patience level to 5 to check for considerable time to get out of local minima if possible\n",
    "    \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [es],\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1A_K1PvoPJR1"
   },
   "source": [
    "Observations: AS with SGD, adagrad converges slowly but better than SGD, some more epoch could help in better accuracy but no point to check further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P7sXg75WPvUA"
   },
   "source": [
    "### Trying RMSProps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "eY8vr8l47PCp",
    "outputId": "96bd181b-d993-4b3d-b121-04c7e9617386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_14 (None, 1024) ==> (None, 1024)\n",
      "dense_36 (None, 1024) ==> (None, 1024)\n",
      "dense_37 (None, 1024) ==> (None, 10)\n",
      "\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_14 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,063,946\n",
      "Trainable params: 1,061,898\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(1024,))) # Set the batch normalization with input shape 32 x 32\n",
    "model.add(Dense(1024, activation='relu', input_shape=(1024,)))   #First hidden layer of 1024  neurons, each neuron takes input \n",
    "                                                               # vector of size 1024\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))            # Adding a softmax layer for output which contains as many \n",
    "                                                               # neurons as the number of classes (10) which is also the \n",
    "                                                               # the shape of each output vector ( one hot coded)\n",
    "\n",
    "                                                               # output layer also uses softmax. This normalizes the values \n",
    "                                                               # from the ten output nodes such that: \n",
    "                                                               #        all the values are between 0 and 1, and\n",
    "                                                               #        the sum of all ten values is 1.  \n",
    "                                                               # prediction is the lable of the node that gets highest fraction, is \n",
    "        \n",
    "        \n",
    "\n",
    "for l in model.layers:\n",
    "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
    "print()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "obpjq2Kv7bxo",
    "outputId": "dd7e7892-488a-44eb-d364-231ba7608173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 9.1142 - accuracy: 0.1191 - val_loss: 4.9801 - val_accuracy: 0.1084\n",
      "Epoch 2/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 4.6194 - accuracy: 0.1886 - val_loss: 3.5832 - val_accuracy: 0.1002\n",
      "Epoch 3/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 4.0018 - accuracy: 0.2306 - val_loss: 3.6570 - val_accuracy: 0.1428\n",
      "Epoch 4/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 3.5313 - accuracy: 0.2739 - val_loss: 3.2814 - val_accuracy: 0.1896\n",
      "Epoch 5/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 3.8160 - accuracy: 0.2841 - val_loss: 3.4289 - val_accuracy: 0.1659\n",
      "Epoch 6/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 3.4996 - accuracy: 0.3100 - val_loss: 2.8065 - val_accuracy: 0.1694\n",
      "Epoch 7/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 3.0816 - accuracy: 0.3420 - val_loss: 3.0406 - val_accuracy: 0.2166\n",
      "Epoch 8/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 3.1454 - accuracy: 0.3476 - val_loss: 2.6903 - val_accuracy: 0.3056\n",
      "Epoch 9/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 3.0585 - accuracy: 0.3513 - val_loss: 3.0138 - val_accuracy: 0.2602\n",
      "Epoch 10/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 3.0761 - accuracy: 0.3698 - val_loss: 2.8448 - val_accuracy: 0.3542\n",
      "Epoch 11/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 2.4898 - accuracy: 0.4189 - val_loss: 2.5487 - val_accuracy: 0.3361\n",
      "Epoch 12/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 2.4958 - accuracy: 0.4214 - val_loss: 2.4666 - val_accuracy: 0.3626\n",
      "Epoch 13/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 2.6200 - accuracy: 0.4212 - val_loss: 2.5547 - val_accuracy: 0.4027\n",
      "Epoch 14/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 2.4834 - accuracy: 0.4440 - val_loss: 2.2439 - val_accuracy: 0.4283\n",
      "Epoch 15/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 2.0556 - accuracy: 0.4824 - val_loss: 2.1967 - val_accuracy: 0.4288\n",
      "Epoch 16/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 2.4557 - accuracy: 0.4476 - val_loss: 2.0934 - val_accuracy: 0.4943\n",
      "Epoch 17/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 2.0662 - accuracy: 0.4863 - val_loss: 1.9440 - val_accuracy: 0.4978\n",
      "Epoch 18/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.8809 - accuracy: 0.5170 - val_loss: 1.8882 - val_accuracy: 0.5209\n",
      "Epoch 19/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.9259 - accuracy: 0.5201 - val_loss: 1.7946 - val_accuracy: 0.5365\n",
      "Epoch 20/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.7227 - accuracy: 0.5504 - val_loss: 1.8059 - val_accuracy: 0.5312\n",
      "Epoch 21/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.8473 - accuracy: 0.5347 - val_loss: 1.7770 - val_accuracy: 0.5299\n",
      "Epoch 22/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1.7333 - accuracy: 0.5459 - val_loss: 1.6597 - val_accuracy: 0.5611\n",
      "Epoch 23/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.4977 - accuracy: 0.5895 - val_loss: 1.4401 - val_accuracy: 0.6256\n",
      "Epoch 24/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.7148 - accuracy: 0.5605 - val_loss: 1.6177 - val_accuracy: 0.5584\n",
      "Epoch 25/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.4725 - accuracy: 0.5980 - val_loss: 1.5216 - val_accuracy: 0.5886\n",
      "Epoch 26/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.5738 - accuracy: 0.5916 - val_loss: 1.4607 - val_accuracy: 0.6022\n",
      "Epoch 27/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.3281 - accuracy: 0.6256 - val_loss: 1.4200 - val_accuracy: 0.5998\n",
      "Epoch 28/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.5291 - accuracy: 0.5967 - val_loss: 1.3581 - val_accuracy: 0.6282\n",
      "Epoch 29/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.3052 - accuracy: 0.6393 - val_loss: 1.4797 - val_accuracy: 0.5832\n",
      "Epoch 30/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.5099 - accuracy: 0.6018 - val_loss: 1.1769 - val_accuracy: 0.6857\n",
      "Epoch 31/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.3169 - accuracy: 0.6386 - val_loss: 1.2868 - val_accuracy: 0.6736\n",
      "Epoch 32/400\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1.1017 - accuracy: 0.6823 - val_loss: 1.3480 - val_accuracy: 0.6153\n",
      "Epoch 33/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1.4869 - accuracy: 0.6086 - val_loss: 1.2649 - val_accuracy: 0.6615\n",
      "Epoch 34/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1.0452 - accuracy: 0.6975 - val_loss: 1.1188 - val_accuracy: 0.6808\n",
      "Epoch 35/400\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1.2892 - accuracy: 0.6500 - val_loss: 1.3984 - val_accuracy: 0.6119\n",
      "Epoch 36/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1.1535 - accuracy: 0.6722 - val_loss: 1.0613 - val_accuracy: 0.7013\n",
      "Epoch 37/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1.2832 - accuracy: 0.6560 - val_loss: 1.0243 - val_accuracy: 0.7204\n",
      "Epoch 38/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9560 - accuracy: 0.7221 - val_loss: 1.4105 - val_accuracy: 0.6117\n",
      "Epoch 39/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.2324 - accuracy: 0.6595 - val_loss: 1.1322 - val_accuracy: 0.6687\n",
      "Epoch 40/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0292 - accuracy: 0.6966 - val_loss: 1.0016 - val_accuracy: 0.7287\n",
      "Epoch 41/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9990 - accuracy: 0.7151 - val_loss: 1.0659 - val_accuracy: 0.6893\n",
      "Epoch 42/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1.1420 - accuracy: 0.6796 - val_loss: 1.0310 - val_accuracy: 0.6939\n",
      "Epoch 43/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1.0129 - accuracy: 0.7059 - val_loss: 1.3248 - val_accuracy: 0.6663\n",
      "Epoch 44/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.9834 - accuracy: 0.7309 - val_loss: 0.8692 - val_accuracy: 0.7698\n",
      "Epoch 45/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.9577 - accuracy: 0.7275 - val_loss: 1.1548 - val_accuracy: 0.6861\n",
      "Epoch 46/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1.0732 - accuracy: 0.7020 - val_loss: 0.8717 - val_accuracy: 0.7608\n",
      "Epoch 47/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.9700 - accuracy: 0.7245 - val_loss: 1.0480 - val_accuracy: 0.6896\n",
      "Epoch 48/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.7962 - accuracy: 0.7748 - val_loss: 0.8484 - val_accuracy: 0.7611\n",
      "Epoch 49/400\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1.0132 - accuracy: 0.7195 - val_loss: 0.9974 - val_accuracy: 0.6975\n",
      "Epoch 50/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9909 - accuracy: 0.7200 - val_loss: 1.0226 - val_accuracy: 0.7016\n",
      "Epoch 51/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8709 - accuracy: 0.7498 - val_loss: 0.8197 - val_accuracy: 0.7684\n",
      "Epoch 52/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9785 - accuracy: 0.7322 - val_loss: 0.8656 - val_accuracy: 0.7526\n",
      "Epoch 53/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8398 - accuracy: 0.7583 - val_loss: 0.9178 - val_accuracy: 0.7214\n",
      "Epoch 54/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9426 - accuracy: 0.7300 - val_loss: 0.9630 - val_accuracy: 0.7309\n",
      "Epoch 55/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7472 - accuracy: 0.7854 - val_loss: 0.8956 - val_accuracy: 0.7329\n",
      "Epoch 56/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9958 - accuracy: 0.7277 - val_loss: 0.7730 - val_accuracy: 0.7855\n",
      "Epoch 57/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7268 - accuracy: 0.7900 - val_loss: 1.0777 - val_accuracy: 0.6970\n",
      "Epoch 58/400\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1.0480 - accuracy: 0.7207 - val_loss: 0.7695 - val_accuracy: 0.7840\n",
      "Epoch 59/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.6836 - accuracy: 0.8057 - val_loss: 1.1238 - val_accuracy: 0.6955\n",
      "Epoch 60/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.8034 - accuracy: 0.7711 - val_loss: 0.8650 - val_accuracy: 0.7541\n",
      "Epoch 61/400\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.8296 - accuracy: 0.7622 - val_loss: 0.9364 - val_accuracy: 0.7314\n",
      "Epoch 62/400\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.8125 - accuracy: 0.7625 - val_loss: 0.9787 - val_accuracy: 0.7306\n",
      "Epoch 63/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.6903 - accuracy: 0.8052 - val_loss: 0.8455 - val_accuracy: 0.7516\n",
      "Epoch 00063: early stopping\n",
      "\n",
      "Test loss: 0.845\n",
      "Test accuracy: 0.752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa1fa769f98>"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "epochs = 400   # Setting up higher epoch in persuit of finding global moinima,\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)   # Set up early stopping to avoid wastage of computing power\n",
    "                                                                            # Kept patience level to 5 to check for considerable time to get out of local minima if possible\n",
    "    \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [es],\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jral0EgNP3Hf"
   },
   "source": [
    "Observations: \n",
    "\n",
    "The graph is having a lot of fluctuations meaning the model is not stable. It seems to be getting stuck within local minima a lot. Though it converges faster but the overall performance is lower with giving test accuracy of only 76.5. We could try without early stops but that could mean that the model might get stuck more in local mimimas taking more time to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ks7k2l2QyK0"
   },
   "source": [
    "### Trying adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "vkM3FuNe7wBg",
    "outputId": "886e00a5-cb70-4611-ad6d-4e9e0eb84e6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_15 (None, 1024) ==> (None, 1024)\n",
      "dense_38 (None, 1024) ==> (None, 1024)\n",
      "dense_39 (None, 1024) ==> (None, 10)\n",
      "\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_15 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,063,946\n",
      "Trainable params: 1,061,898\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(1024,))) # Set the batch normalization with input shape 32 x 32\n",
    "model.add(Dense(1024, activation='relu', input_shape=(1024,)))   #First hidden layer of 1024  neurons, each neuron takes input \n",
    "                                                               # vector of size 1024\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))            # Adding a softmax layer for output which contains as many \n",
    "                                                               # neurons as the number of classes (10) which is also the \n",
    "                                                               # the shape of each output vector ( one hot coded)\n",
    "\n",
    "                                                               # output layer also uses softmax. This normalizes the values \n",
    "                                                               # from the ten output nodes such that: \n",
    "                                                               #        all the values are between 0 and 1, and\n",
    "                                                               #        the sum of all ten values is 1.  \n",
    "                                                               # prediction is the lable of the node that gets highest fraction, is \n",
    "        \n",
    "        \n",
    "\n",
    "for l in model.layers:\n",
    "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
    "print()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZUHapSaW70WQ",
    "outputId": "fb2533a5-67e6-4356-cb4f-8c753b41ae78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 3.4184 - accuracy: 0.1352 - val_loss: 2.4773 - val_accuracy: 0.0959\n",
      "Epoch 2/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 2.3601 - accuracy: 0.2432 - val_loss: 2.2798 - val_accuracy: 0.1761\n",
      "Epoch 3/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.9913 - accuracy: 0.3466 - val_loss: 2.2559 - val_accuracy: 0.1879\n",
      "Epoch 4/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.7913 - accuracy: 0.4401 - val_loss: 2.1705 - val_accuracy: 0.3104\n",
      "Epoch 5/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.6526 - accuracy: 0.5058 - val_loss: 2.1133 - val_accuracy: 0.3965\n",
      "Epoch 6/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.5479 - accuracy: 0.5577 - val_loss: 2.0521 - val_accuracy: 0.5168\n",
      "Epoch 7/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.4614 - accuracy: 0.6002 - val_loss: 1.9973 - val_accuracy: 0.5606\n",
      "Epoch 8/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.3890 - accuracy: 0.6284 - val_loss: 1.9434 - val_accuracy: 0.5932\n",
      "Epoch 9/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.3277 - accuracy: 0.6492 - val_loss: 1.8917 - val_accuracy: 0.6153\n",
      "Epoch 10/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.2743 - accuracy: 0.6657 - val_loss: 1.8407 - val_accuracy: 0.6373\n",
      "Epoch 11/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.2274 - accuracy: 0.6798 - val_loss: 1.7881 - val_accuracy: 0.6558\n",
      "Epoch 12/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.1867 - accuracy: 0.6900 - val_loss: 1.7379 - val_accuracy: 0.6711\n",
      "Epoch 13/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.1509 - accuracy: 0.6992 - val_loss: 1.6904 - val_accuracy: 0.6798\n",
      "Epoch 14/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1177 - accuracy: 0.7077 - val_loss: 1.6432 - val_accuracy: 0.6885\n",
      "Epoch 15/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0886 - accuracy: 0.7152 - val_loss: 1.5989 - val_accuracy: 0.6963\n",
      "Epoch 16/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.0625 - accuracy: 0.7205 - val_loss: 1.5539 - val_accuracy: 0.7035\n",
      "Epoch 17/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0376 - accuracy: 0.7259 - val_loss: 1.5113 - val_accuracy: 0.7083\n",
      "Epoch 18/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0148 - accuracy: 0.7333 - val_loss: 1.4698 - val_accuracy: 0.7166\n",
      "Epoch 19/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9940 - accuracy: 0.7375 - val_loss: 1.4285 - val_accuracy: 0.7243\n",
      "Epoch 20/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9750 - accuracy: 0.7421 - val_loss: 1.3894 - val_accuracy: 0.7270\n",
      "Epoch 21/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9571 - accuracy: 0.7454 - val_loss: 1.3520 - val_accuracy: 0.7313\n",
      "Epoch 22/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9405 - accuracy: 0.7497 - val_loss: 1.3158 - val_accuracy: 0.7354\n",
      "Epoch 23/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9239 - accuracy: 0.7543 - val_loss: 1.2824 - val_accuracy: 0.7381\n",
      "Epoch 24/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9090 - accuracy: 0.7580 - val_loss: 1.2476 - val_accuracy: 0.7432\n",
      "Epoch 25/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8943 - accuracy: 0.7614 - val_loss: 1.2135 - val_accuracy: 0.7449\n",
      "Epoch 26/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8822 - accuracy: 0.7637 - val_loss: 1.1828 - val_accuracy: 0.7474\n",
      "Epoch 27/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8683 - accuracy: 0.7671 - val_loss: 1.1544 - val_accuracy: 0.7502\n",
      "Epoch 28/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8547 - accuracy: 0.7721 - val_loss: 1.1250 - val_accuracy: 0.7525\n",
      "Epoch 29/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8432 - accuracy: 0.7759 - val_loss: 1.0991 - val_accuracy: 0.7534\n",
      "Epoch 30/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8325 - accuracy: 0.7766 - val_loss: 1.0723 - val_accuracy: 0.7560\n",
      "Epoch 31/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8209 - accuracy: 0.7809 - val_loss: 1.0476 - val_accuracy: 0.7596\n",
      "Epoch 32/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8101 - accuracy: 0.7835 - val_loss: 1.0241 - val_accuracy: 0.7624\n",
      "Epoch 33/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7994 - accuracy: 0.7877 - val_loss: 1.0011 - val_accuracy: 0.7648\n",
      "Epoch 34/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.7899 - accuracy: 0.7900 - val_loss: 0.9802 - val_accuracy: 0.7660\n",
      "Epoch 35/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7800 - accuracy: 0.7914 - val_loss: 0.9624 - val_accuracy: 0.7665\n",
      "Epoch 36/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7713 - accuracy: 0.7948 - val_loss: 0.9414 - val_accuracy: 0.7693\n",
      "Epoch 37/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7614 - accuracy: 0.7974 - val_loss: 0.9244 - val_accuracy: 0.7726\n",
      "Epoch 38/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.7527 - accuracy: 0.8001 - val_loss: 0.9081 - val_accuracy: 0.7731\n",
      "Epoch 39/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7446 - accuracy: 0.8019 - val_loss: 0.8915 - val_accuracy: 0.7744\n",
      "Epoch 40/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7353 - accuracy: 0.8043 - val_loss: 0.8766 - val_accuracy: 0.7782\n",
      "Epoch 41/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7277 - accuracy: 0.8054 - val_loss: 0.8621 - val_accuracy: 0.7797\n",
      "Epoch 42/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7204 - accuracy: 0.8082 - val_loss: 0.8490 - val_accuracy: 0.7820\n",
      "Epoch 43/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.7109 - accuracy: 0.8105 - val_loss: 0.8370 - val_accuracy: 0.7833\n",
      "Epoch 44/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.7043 - accuracy: 0.8128 - val_loss: 0.8257 - val_accuracy: 0.7850\n",
      "Epoch 45/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6972 - accuracy: 0.8147 - val_loss: 0.8147 - val_accuracy: 0.7886\n",
      "Epoch 46/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6900 - accuracy: 0.8164 - val_loss: 0.8055 - val_accuracy: 0.7879\n",
      "Epoch 47/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6837 - accuracy: 0.8180 - val_loss: 0.7943 - val_accuracy: 0.7899\n",
      "Epoch 48/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6762 - accuracy: 0.8205 - val_loss: 0.7848 - val_accuracy: 0.7924\n",
      "Epoch 49/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.6684 - accuracy: 0.8233 - val_loss: 0.7763 - val_accuracy: 0.7934\n",
      "Epoch 50/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6618 - accuracy: 0.8245 - val_loss: 0.7683 - val_accuracy: 0.7942\n",
      "Epoch 51/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6554 - accuracy: 0.8253 - val_loss: 0.7608 - val_accuracy: 0.7962\n",
      "Epoch 52/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6494 - accuracy: 0.8289 - val_loss: 0.7533 - val_accuracy: 0.7964\n",
      "Epoch 53/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6430 - accuracy: 0.8295 - val_loss: 0.7471 - val_accuracy: 0.7981\n",
      "Epoch 54/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6376 - accuracy: 0.8305 - val_loss: 0.7384 - val_accuracy: 0.8013\n",
      "Epoch 55/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6304 - accuracy: 0.8329 - val_loss: 0.7334 - val_accuracy: 0.8006\n",
      "Epoch 56/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6251 - accuracy: 0.8341 - val_loss: 0.7263 - val_accuracy: 0.8043\n",
      "Epoch 57/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6195 - accuracy: 0.8354 - val_loss: 0.7213 - val_accuracy: 0.8048\n",
      "Epoch 58/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6134 - accuracy: 0.8388 - val_loss: 0.7156 - val_accuracy: 0.8045\n",
      "Epoch 59/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6080 - accuracy: 0.8386 - val_loss: 0.7099 - val_accuracy: 0.8072\n",
      "Epoch 60/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6030 - accuracy: 0.8410 - val_loss: 0.7041 - val_accuracy: 0.8083\n",
      "Epoch 61/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.5960 - accuracy: 0.8427 - val_loss: 0.6987 - val_accuracy: 0.8090\n",
      "Epoch 62/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5909 - accuracy: 0.8441 - val_loss: 0.6931 - val_accuracy: 0.8117\n",
      "Epoch 63/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5859 - accuracy: 0.8456 - val_loss: 0.6879 - val_accuracy: 0.8124\n",
      "Epoch 64/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5800 - accuracy: 0.8474 - val_loss: 0.6840 - val_accuracy: 0.8129\n",
      "Epoch 65/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5749 - accuracy: 0.8487 - val_loss: 0.6789 - val_accuracy: 0.8147\n",
      "Epoch 66/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5711 - accuracy: 0.8489 - val_loss: 0.6749 - val_accuracy: 0.8146\n",
      "Epoch 67/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.5658 - accuracy: 0.8503 - val_loss: 0.6702 - val_accuracy: 0.8183\n",
      "Epoch 68/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5604 - accuracy: 0.8511 - val_loss: 0.6677 - val_accuracy: 0.8173\n",
      "Epoch 69/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.5564 - accuracy: 0.8538 - val_loss: 0.6649 - val_accuracy: 0.8167\n",
      "Epoch 70/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5512 - accuracy: 0.8546 - val_loss: 0.6634 - val_accuracy: 0.8169\n",
      "Epoch 71/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5480 - accuracy: 0.8552 - val_loss: 0.6581 - val_accuracy: 0.8183\n",
      "Epoch 72/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5435 - accuracy: 0.8560 - val_loss: 0.6551 - val_accuracy: 0.8195\n",
      "Epoch 73/400\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.5391 - accuracy: 0.8567 - val_loss: 0.6523 - val_accuracy: 0.8202\n",
      "Epoch 74/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5331 - accuracy: 0.8601 - val_loss: 0.6487 - val_accuracy: 0.8216\n",
      "Epoch 75/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.5291 - accuracy: 0.8610 - val_loss: 0.6429 - val_accuracy: 0.8248\n",
      "Epoch 76/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5241 - accuracy: 0.8627 - val_loss: 0.6389 - val_accuracy: 0.8252\n",
      "Epoch 77/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5194 - accuracy: 0.8634 - val_loss: 0.6344 - val_accuracy: 0.8266\n",
      "Epoch 78/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5140 - accuracy: 0.8648 - val_loss: 0.6332 - val_accuracy: 0.8273\n",
      "Epoch 79/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5107 - accuracy: 0.8668 - val_loss: 0.6287 - val_accuracy: 0.8273\n",
      "Epoch 80/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5069 - accuracy: 0.8669 - val_loss: 0.6263 - val_accuracy: 0.8288\n",
      "Epoch 81/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5019 - accuracy: 0.8683 - val_loss: 0.6231 - val_accuracy: 0.8310\n",
      "Epoch 82/400\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.4982 - accuracy: 0.8701 - val_loss: 0.6221 - val_accuracy: 0.8299\n",
      "Epoch 83/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4952 - accuracy: 0.8700 - val_loss: 0.6196 - val_accuracy: 0.8297\n",
      "Epoch 84/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4912 - accuracy: 0.8715 - val_loss: 0.6158 - val_accuracy: 0.8313\n",
      "Epoch 85/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4879 - accuracy: 0.8705 - val_loss: 0.6125 - val_accuracy: 0.8317\n",
      "Epoch 86/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4823 - accuracy: 0.8739 - val_loss: 0.6106 - val_accuracy: 0.8325\n",
      "Epoch 87/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4781 - accuracy: 0.8744 - val_loss: 0.6073 - val_accuracy: 0.8339\n",
      "Epoch 88/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4741 - accuracy: 0.8771 - val_loss: 0.6070 - val_accuracy: 0.8329\n",
      "Epoch 89/400\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.4717 - accuracy: 0.8768 - val_loss: 0.6019 - val_accuracy: 0.8352\n",
      "Epoch 90/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.4683 - accuracy: 0.8781 - val_loss: 0.5997 - val_accuracy: 0.8358\n",
      "Epoch 91/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4639 - accuracy: 0.8795 - val_loss: 0.5986 - val_accuracy: 0.8357\n",
      "Epoch 92/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4608 - accuracy: 0.8794 - val_loss: 0.5961 - val_accuracy: 0.8360\n",
      "Epoch 93/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.4571 - accuracy: 0.8807 - val_loss: 0.5939 - val_accuracy: 0.8362\n",
      "Epoch 94/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4539 - accuracy: 0.8816 - val_loss: 0.5925 - val_accuracy: 0.8354\n",
      "Epoch 95/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4495 - accuracy: 0.8833 - val_loss: 0.5886 - val_accuracy: 0.8383\n",
      "Epoch 96/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4456 - accuracy: 0.8844 - val_loss: 0.5868 - val_accuracy: 0.8392\n",
      "Epoch 97/400\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4424 - accuracy: 0.8854 - val_loss: 0.5851 - val_accuracy: 0.8384\n",
      "Epoch 98/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4385 - accuracy: 0.8857 - val_loss: 0.5842 - val_accuracy: 0.8411\n",
      "Epoch 99/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.4360 - accuracy: 0.8856 - val_loss: 0.5807 - val_accuracy: 0.8419\n",
      "Epoch 100/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4314 - accuracy: 0.8886 - val_loss: 0.5777 - val_accuracy: 0.8417\n",
      "Epoch 101/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4285 - accuracy: 0.8896 - val_loss: 0.5788 - val_accuracy: 0.8403\n",
      "Epoch 102/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4267 - accuracy: 0.8896 - val_loss: 0.5748 - val_accuracy: 0.8412\n",
      "Epoch 103/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4232 - accuracy: 0.8909 - val_loss: 0.5724 - val_accuracy: 0.8430\n",
      "Epoch 104/400\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4198 - accuracy: 0.8914 - val_loss: 0.5738 - val_accuracy: 0.8424\n",
      "Epoch 105/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4171 - accuracy: 0.8910 - val_loss: 0.5690 - val_accuracy: 0.8442\n",
      "Epoch 106/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4142 - accuracy: 0.8924 - val_loss: 0.5689 - val_accuracy: 0.8430\n",
      "Epoch 107/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4105 - accuracy: 0.8933 - val_loss: 0.5663 - val_accuracy: 0.8433\n",
      "Epoch 108/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4070 - accuracy: 0.8946 - val_loss: 0.5645 - val_accuracy: 0.8447\n",
      "Epoch 109/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4042 - accuracy: 0.8961 - val_loss: 0.5626 - val_accuracy: 0.8444\n",
      "Epoch 110/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4015 - accuracy: 0.8967 - val_loss: 0.5641 - val_accuracy: 0.8441\n",
      "Epoch 111/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3990 - accuracy: 0.8970 - val_loss: 0.5633 - val_accuracy: 0.8451\n",
      "Epoch 112/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3957 - accuracy: 0.8983 - val_loss: 0.5602 - val_accuracy: 0.8457\n",
      "Epoch 113/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3930 - accuracy: 0.8990 - val_loss: 0.5549 - val_accuracy: 0.8473\n",
      "Epoch 114/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3890 - accuracy: 0.8995 - val_loss: 0.5556 - val_accuracy: 0.8458\n",
      "Epoch 115/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.3869 - accuracy: 0.9010 - val_loss: 0.5535 - val_accuracy: 0.8467\n",
      "Epoch 116/400\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3833 - accuracy: 0.9020 - val_loss: 0.5520 - val_accuracy: 0.8477\n",
      "Epoch 117/400\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3806 - accuracy: 0.9025 - val_loss: 0.5505 - val_accuracy: 0.8483\n",
      "Epoch 118/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3773 - accuracy: 0.9027 - val_loss: 0.5487 - val_accuracy: 0.8491\n",
      "Epoch 119/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.3757 - accuracy: 0.9053 - val_loss: 0.5494 - val_accuracy: 0.8482\n",
      "Epoch 120/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3728 - accuracy: 0.9040 - val_loss: 0.5457 - val_accuracy: 0.8492\n",
      "Epoch 121/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3688 - accuracy: 0.9052 - val_loss: 0.5445 - val_accuracy: 0.8501\n",
      "Epoch 122/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3669 - accuracy: 0.9069 - val_loss: 0.5446 - val_accuracy: 0.8496\n",
      "Epoch 123/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3645 - accuracy: 0.9067 - val_loss: 0.5451 - val_accuracy: 0.8496\n",
      "Epoch 124/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3644 - accuracy: 0.9062 - val_loss: 0.5468 - val_accuracy: 0.8481\n",
      "Epoch 125/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3604 - accuracy: 0.9067 - val_loss: 0.5400 - val_accuracy: 0.8509\n",
      "Epoch 126/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3559 - accuracy: 0.9098 - val_loss: 0.5416 - val_accuracy: 0.8509\n",
      "Epoch 127/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3534 - accuracy: 0.9104 - val_loss: 0.5401 - val_accuracy: 0.8497\n",
      "Epoch 128/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3509 - accuracy: 0.9107 - val_loss: 0.5372 - val_accuracy: 0.8519\n",
      "Epoch 129/400\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3484 - accuracy: 0.9116 - val_loss: 0.5367 - val_accuracy: 0.8519\n",
      "Epoch 130/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3461 - accuracy: 0.9123 - val_loss: 0.5373 - val_accuracy: 0.8517\n",
      "Epoch 131/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3461 - accuracy: 0.9121 - val_loss: 0.5353 - val_accuracy: 0.8543\n",
      "Epoch 132/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3410 - accuracy: 0.9141 - val_loss: 0.5314 - val_accuracy: 0.8532\n",
      "Epoch 133/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3379 - accuracy: 0.9155 - val_loss: 0.5354 - val_accuracy: 0.8532\n",
      "Epoch 134/400\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3361 - accuracy: 0.9155 - val_loss: 0.5309 - val_accuracy: 0.8548\n",
      "Epoch 135/400\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3341 - accuracy: 0.9160 - val_loss: 0.5302 - val_accuracy: 0.8538\n",
      "Epoch 136/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3320 - accuracy: 0.9163 - val_loss: 0.5317 - val_accuracy: 0.8539\n",
      "Epoch 137/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3300 - accuracy: 0.9167 - val_loss: 0.5312 - val_accuracy: 0.8518\n",
      "Epoch 138/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3267 - accuracy: 0.9173 - val_loss: 0.5298 - val_accuracy: 0.8529\n",
      "Epoch 139/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3244 - accuracy: 0.9198 - val_loss: 0.5277 - val_accuracy: 0.8554\n",
      "Epoch 140/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3236 - accuracy: 0.9186 - val_loss: 0.5243 - val_accuracy: 0.8552\n",
      "Epoch 141/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3198 - accuracy: 0.9200 - val_loss: 0.5276 - val_accuracy: 0.8534\n",
      "Epoch 142/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3191 - accuracy: 0.9203 - val_loss: 0.5257 - val_accuracy: 0.8544\n",
      "Epoch 143/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3159 - accuracy: 0.9223 - val_loss: 0.5304 - val_accuracy: 0.8556\n",
      "Epoch 144/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3143 - accuracy: 0.9205 - val_loss: 0.5234 - val_accuracy: 0.8558\n",
      "Epoch 145/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3126 - accuracy: 0.9216 - val_loss: 0.5285 - val_accuracy: 0.8530\n",
      "Epoch 146/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3089 - accuracy: 0.9228 - val_loss: 0.5216 - val_accuracy: 0.8569\n",
      "Epoch 147/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3064 - accuracy: 0.9242 - val_loss: 0.5221 - val_accuracy: 0.8574\n",
      "Epoch 148/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3051 - accuracy: 0.9248 - val_loss: 0.5241 - val_accuracy: 0.8557\n",
      "Epoch 149/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3028 - accuracy: 0.9248 - val_loss: 0.5227 - val_accuracy: 0.8563\n",
      "Epoch 150/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3006 - accuracy: 0.9255 - val_loss: 0.5206 - val_accuracy: 0.8567\n",
      "Epoch 151/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2970 - accuracy: 0.9268 - val_loss: 0.5207 - val_accuracy: 0.8576\n",
      "Epoch 152/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2954 - accuracy: 0.9275 - val_loss: 0.5224 - val_accuracy: 0.8574\n",
      "Epoch 153/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2953 - accuracy: 0.9260 - val_loss: 0.5196 - val_accuracy: 0.8555\n",
      "Epoch 154/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2924 - accuracy: 0.9284 - val_loss: 0.5199 - val_accuracy: 0.8572\n",
      "Epoch 155/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2914 - accuracy: 0.9277 - val_loss: 0.5188 - val_accuracy: 0.8576\n",
      "Epoch 156/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2908 - accuracy: 0.9265 - val_loss: 0.5186 - val_accuracy: 0.8569\n",
      "Epoch 157/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2867 - accuracy: 0.9286 - val_loss: 0.5174 - val_accuracy: 0.8583\n",
      "Epoch 158/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2840 - accuracy: 0.9304 - val_loss: 0.5141 - val_accuracy: 0.8595\n",
      "Epoch 159/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2809 - accuracy: 0.9303 - val_loss: 0.5119 - val_accuracy: 0.8614\n",
      "Epoch 160/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2780 - accuracy: 0.9320 - val_loss: 0.5180 - val_accuracy: 0.8584\n",
      "Epoch 161/400\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2764 - accuracy: 0.9326 - val_loss: 0.5138 - val_accuracy: 0.8596\n",
      "Epoch 162/400\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2746 - accuracy: 0.9329 - val_loss: 0.5133 - val_accuracy: 0.8598\n",
      "Epoch 163/400\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2730 - accuracy: 0.9335 - val_loss: 0.5137 - val_accuracy: 0.8599\n",
      "Epoch 164/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2699 - accuracy: 0.9353 - val_loss: 0.5126 - val_accuracy: 0.8611\n",
      "Epoch 00164: early stopping\n",
      "\n",
      "Test loss: 0.513\n",
      "Test accuracy: 0.861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa1fa3d72b0>"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "epochs = 400   # Setting up higher epoch in persuit of finding global moinima,\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adamax',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)   # Set up early stopping to avoid wastage of computing power\n",
    "                                                                            # Kept patience level to 5 to check for considerable time to get out of local minima if possible\n",
    "    \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [es],\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfmUpNHgQ4xL"
   },
   "source": [
    "Observations:\n",
    "\n",
    "The model converges steadily and reaches the minima with early stopping at about 164 epochs. The model has the highest accuracy of about 86% which is a bit higher than adam\n",
    "\n",
    "Though this performs better but adam reaches the lowest minima quicker hence taking the benefit of epoch count the optimizer with \"ADAM\" should be preferred for a very small loss in accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dTREZ-zFSgju"
   },
   "source": [
    "## Build the final model with ADAM optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t418-N2TG3bI"
   },
   "source": [
    "Use the following as model:\n",
    "\n",
    "Optimizer: ADAM\n",
    "\n",
    "Aactivation: RELU\n",
    "\n",
    "BATCH_SIZE: 5000\n",
    "\n",
    "EPOCHS: 400 (with early stopping)\n",
    "\n",
    "with batchNormailization enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "WCqNaxXN8a-4",
    "outputId": "95f8c961-d624-434f-fc8d-5292dfaaa549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_16 (None, 1024) ==> (None, 1024)\n",
      "dense_40 (None, 1024) ==> (None, 1024)\n",
      "dense_41 (None, 1024) ==> (None, 10)\n",
      "\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_16 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,063,946\n",
      "Trainable params: 1,061,898\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(1024,))) # Set the batch normalization with input shape 32 x 32\n",
    "model.add(Dense(1024, activation='relu', input_shape=(1024,)))   #First hidden layer of 1024  neurons, each neuron takes input \n",
    "                                                               # vector of size 1024\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))            # Adding a softmax layer for output which contains as many \n",
    "                                                               # neurons as the number of classes (10) which is also the \n",
    "                                                               # the shape of each output vector ( one hot coded)\n",
    "\n",
    "                                                               # output layer also uses softmax. This normalizes the values \n",
    "                                                               # from the ten output nodes such that: \n",
    "                                                               #        all the values are between 0 and 1, and\n",
    "                                                               #        the sum of all ten values is 1.  \n",
    "                                                               # prediction is the lable of the node that gets highest fraction, is \n",
    "        \n",
    "        \n",
    "\n",
    "for l in model.layers:\n",
    "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
    "print()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "03rBFn978bPD",
    "outputId": "9f8395be-ff8a-41ae-bd68-9588a444603e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 3.8055 - accuracy: 0.1310 - val_loss: 2.5908 - val_accuracy: 0.1219\n",
      "Epoch 2/400\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 2.4853 - accuracy: 0.2575 - val_loss: 2.3409 - val_accuracy: 0.1997\n",
      "Epoch 3/400\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.9758 - accuracy: 0.3730 - val_loss: 2.2110 - val_accuracy: 0.3312\n",
      "Epoch 4/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.6497 - accuracy: 0.4913 - val_loss: 2.1063 - val_accuracy: 0.2880\n",
      "Epoch 5/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.4480 - accuracy: 0.5677 - val_loss: 1.9861 - val_accuracy: 0.5086\n",
      "Epoch 6/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.2995 - accuracy: 0.6224 - val_loss: 1.8918 - val_accuracy: 0.5504\n",
      "Epoch 7/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.1864 - accuracy: 0.6680 - val_loss: 1.8040 - val_accuracy: 0.6265\n",
      "Epoch 8/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.1045 - accuracy: 0.6924 - val_loss: 1.7260 - val_accuracy: 0.6467\n",
      "Epoch 9/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0407 - accuracy: 0.7096 - val_loss: 1.6542 - val_accuracy: 0.6767\n",
      "Epoch 10/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9860 - accuracy: 0.7269 - val_loss: 1.5823 - val_accuracy: 0.7003\n",
      "Epoch 11/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.9404 - accuracy: 0.7400 - val_loss: 1.5289 - val_accuracy: 0.6926\n",
      "Epoch 12/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8996 - accuracy: 0.7495 - val_loss: 1.4676 - val_accuracy: 0.7235\n",
      "Epoch 13/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.8622 - accuracy: 0.7604 - val_loss: 1.4087 - val_accuracy: 0.7325\n",
      "Epoch 14/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.8298 - accuracy: 0.7688 - val_loss: 1.3565 - val_accuracy: 0.7436\n",
      "Epoch 15/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7971 - accuracy: 0.7812 - val_loss: 1.3057 - val_accuracy: 0.7484\n",
      "Epoch 16/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.7694 - accuracy: 0.7879 - val_loss: 1.2528 - val_accuracy: 0.7568\n",
      "Epoch 17/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7443 - accuracy: 0.7955 - val_loss: 1.2060 - val_accuracy: 0.7681\n",
      "Epoch 18/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7210 - accuracy: 0.8016 - val_loss: 1.1573 - val_accuracy: 0.7728\n",
      "Epoch 19/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6987 - accuracy: 0.8088 - val_loss: 1.1207 - val_accuracy: 0.7743\n",
      "Epoch 20/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6775 - accuracy: 0.8139 - val_loss: 1.0734 - val_accuracy: 0.7810\n",
      "Epoch 21/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6593 - accuracy: 0.8201 - val_loss: 1.0339 - val_accuracy: 0.7903\n",
      "Epoch 22/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6419 - accuracy: 0.8253 - val_loss: 0.9969 - val_accuracy: 0.7872\n",
      "Epoch 23/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6248 - accuracy: 0.8298 - val_loss: 0.9606 - val_accuracy: 0.7971\n",
      "Epoch 24/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6138 - accuracy: 0.8311 - val_loss: 0.9273 - val_accuracy: 0.8007\n",
      "Epoch 25/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.5989 - accuracy: 0.8342 - val_loss: 0.8938 - val_accuracy: 0.8001\n",
      "Epoch 26/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5790 - accuracy: 0.8431 - val_loss: 0.8617 - val_accuracy: 0.8094\n",
      "Epoch 27/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.5631 - accuracy: 0.8465 - val_loss: 0.8384 - val_accuracy: 0.8123\n",
      "Epoch 28/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.5489 - accuracy: 0.8515 - val_loss: 0.8062 - val_accuracy: 0.8185\n",
      "Epoch 29/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5365 - accuracy: 0.8539 - val_loss: 0.7896 - val_accuracy: 0.8157\n",
      "Epoch 30/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5260 - accuracy: 0.8587 - val_loss: 0.7628 - val_accuracy: 0.8183\n",
      "Epoch 31/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5148 - accuracy: 0.8611 - val_loss: 0.7468 - val_accuracy: 0.8189\n",
      "Epoch 32/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.5030 - accuracy: 0.8642 - val_loss: 0.7204 - val_accuracy: 0.8241\n",
      "Epoch 33/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4939 - accuracy: 0.8656 - val_loss: 0.7018 - val_accuracy: 0.8257\n",
      "Epoch 34/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4826 - accuracy: 0.8698 - val_loss: 0.6922 - val_accuracy: 0.8245\n",
      "Epoch 35/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4770 - accuracy: 0.8701 - val_loss: 0.6712 - val_accuracy: 0.8296\n",
      "Epoch 36/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.4656 - accuracy: 0.8737 - val_loss: 0.6644 - val_accuracy: 0.8266\n",
      "Epoch 37/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4572 - accuracy: 0.8760 - val_loss: 0.6488 - val_accuracy: 0.8261\n",
      "Epoch 38/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4542 - accuracy: 0.8765 - val_loss: 0.6413 - val_accuracy: 0.8291\n",
      "Epoch 39/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.4415 - accuracy: 0.8810 - val_loss: 0.6274 - val_accuracy: 0.8344\n",
      "Epoch 40/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4343 - accuracy: 0.8822 - val_loss: 0.6179 - val_accuracy: 0.8359\n",
      "Epoch 41/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4267 - accuracy: 0.8832 - val_loss: 0.6125 - val_accuracy: 0.8350\n",
      "Epoch 42/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4144 - accuracy: 0.8887 - val_loss: 0.5990 - val_accuracy: 0.8374\n",
      "Epoch 43/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4061 - accuracy: 0.8917 - val_loss: 0.5911 - val_accuracy: 0.8404\n",
      "Epoch 44/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3980 - accuracy: 0.8939 - val_loss: 0.5806 - val_accuracy: 0.8436\n",
      "Epoch 45/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3937 - accuracy: 0.8943 - val_loss: 0.5784 - val_accuracy: 0.8419\n",
      "Epoch 46/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3930 - accuracy: 0.8944 - val_loss: 0.5739 - val_accuracy: 0.8431\n",
      "Epoch 47/400\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3801 - accuracy: 0.8986 - val_loss: 0.5640 - val_accuracy: 0.8475\n",
      "Epoch 48/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3735 - accuracy: 0.9006 - val_loss: 0.5727 - val_accuracy: 0.8431\n",
      "Epoch 49/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3741 - accuracy: 0.8996 - val_loss: 0.5587 - val_accuracy: 0.8465\n",
      "Epoch 50/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3652 - accuracy: 0.9020 - val_loss: 0.5572 - val_accuracy: 0.8469\n",
      "Epoch 51/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3605 - accuracy: 0.9037 - val_loss: 0.5427 - val_accuracy: 0.8508\n",
      "Epoch 52/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3527 - accuracy: 0.9063 - val_loss: 0.5466 - val_accuracy: 0.8479\n",
      "Epoch 53/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3470 - accuracy: 0.9085 - val_loss: 0.5452 - val_accuracy: 0.8483\n",
      "Epoch 54/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.3487 - accuracy: 0.9066 - val_loss: 0.5422 - val_accuracy: 0.8488\n",
      "Epoch 55/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.3390 - accuracy: 0.9097 - val_loss: 0.5405 - val_accuracy: 0.8505\n",
      "Epoch 56/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3388 - accuracy: 0.9093 - val_loss: 0.5484 - val_accuracy: 0.8472\n",
      "Epoch 57/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3395 - accuracy: 0.9075 - val_loss: 0.5416 - val_accuracy: 0.8517\n",
      "Epoch 58/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.3291 - accuracy: 0.9113 - val_loss: 0.5375 - val_accuracy: 0.8495\n",
      "Epoch 59/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3182 - accuracy: 0.9150 - val_loss: 0.5334 - val_accuracy: 0.8509\n",
      "Epoch 60/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3126 - accuracy: 0.9175 - val_loss: 0.5295 - val_accuracy: 0.8534\n",
      "Epoch 61/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3088 - accuracy: 0.9192 - val_loss: 0.5279 - val_accuracy: 0.8538\n",
      "Epoch 62/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3043 - accuracy: 0.9200 - val_loss: 0.5215 - val_accuracy: 0.8561\n",
      "Epoch 63/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2968 - accuracy: 0.9232 - val_loss: 0.5275 - val_accuracy: 0.8532\n",
      "Epoch 64/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2967 - accuracy: 0.9221 - val_loss: 0.5301 - val_accuracy: 0.8544\n",
      "Epoch 65/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2895 - accuracy: 0.9254 - val_loss: 0.5213 - val_accuracy: 0.8574\n",
      "Epoch 66/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2869 - accuracy: 0.9256 - val_loss: 0.5324 - val_accuracy: 0.8541\n",
      "Epoch 67/400\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2912 - accuracy: 0.9230 - val_loss: 0.5352 - val_accuracy: 0.8523\n",
      "Epoch 68/400\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2884 - accuracy: 0.9226 - val_loss: 0.5265 - val_accuracy: 0.8543\n",
      "Epoch 69/400\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2819 - accuracy: 0.9256 - val_loss: 0.5266 - val_accuracy: 0.8557\n",
      "Epoch 70/400\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2746 - accuracy: 0.9291 - val_loss: 0.5239 - val_accuracy: 0.8552\n",
      "Epoch 00070: early stopping\n",
      "\n",
      "Test loss: 0.524\n",
      "Test accuracy: 0.855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa1fb76f518>"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "epochs = 400   # Setting up higher epoch in persuit of finding global moinima,\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)   # Set up early stopping to avoid wastage of computing power\n",
    "                                                                            # Kept patience level to 5 to check for considerable time to get out of local minima if possible\n",
    "    \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [es],\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wmNZfC-bHi9q"
   },
   "source": [
    "This looks to ba pity good and stable model with one of the best accuracy and converging much faster reducing the computation time.\n",
    "\n",
    "Use this model for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BqPHjggS7Lhd"
   },
   "source": [
    "# Print the classification accuracy metrics (Print Both Classification report and Confusion Matrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "6ws8ykhbrAdy",
    "outputId": "03c7e778-f1af-4cfb-9f59-446ca006d604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-54-5f71bd52decd>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 0.5239 - accuracy: 0.8552\n",
      "Accuracy Model1 (Dropout): 0.8551666736602783\n"
     ]
    }
   ],
   "source": [
    "Y_pred_cls = model.predict_classes(X_test, batch_size=200, verbose=0)\n",
    "y_true = np.argmax(y_test, axis=1) \n",
    "print('Accuracy Model1 (Dropout): '+ str(model.evaluate(X_test,y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5z2DQQsg6X2q"
   },
   "source": [
    "Model accuracy is 85.40 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzIjNEDjH_19"
   },
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "YsolHbCpUMeE",
    "outputId": "dcdab34c-87b4-413f-987e-1fae2dd5d035"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88      1814\n",
      "           1       0.86      0.86      0.86      1828\n",
      "           2       0.90      0.87      0.89      1803\n",
      "           3       0.80      0.83      0.81      1719\n",
      "           4       0.89      0.89      0.89      1812\n",
      "           5       0.85      0.85      0.85      1768\n",
      "           6       0.83      0.83      0.83      1832\n",
      "           7       0.89      0.89      0.89      1808\n",
      "           8       0.83      0.80      0.82      1812\n",
      "           9       0.85      0.84      0.84      1804\n",
      "\n",
      "    accuracy                           0.86     18000\n",
      "   macro avg       0.86      0.86      0.85     18000\n",
      "weighted avg       0.86      0.86      0.86     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, Y_pred_cls)) # Print the classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wi-liJMoIG1N"
   },
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "id": "Go_WotoYSP1n",
    "outputId": "b0fd1b54-a4d8-4e08-ff30-890adb44b98a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = confusion_matrix(y_true, Y_pred_cls)\n",
    "plt.figure(figsize=(12, 12))\n",
    "# Normalize the confusion matrix\n",
    "conf = conf.astype('float') / conf.sum(axis=1)[:, np.newaxis] * 100.0\n",
    "# Visualize the confusion matrix\n",
    "sn.heatmap(conf, annot=True, cmap='Reds', fmt='.1f', square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V6menwGl39nf"
   },
   "source": [
    "Observations\n",
    "Based on both the classification and confusion matrix we can observer that: \n",
    "1. The model is able to predict value of 0 followed by 7 quite well\n",
    "2. The model has lowest predictability for 3 and 8 which is clearly evident as 3 and 8 resemble closely in texture."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NNDL_R7_Project1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
